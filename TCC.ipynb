{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-lopes29/TCC/blob/main/TCC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importações"
      ],
      "metadata": {
        "id": "jBRBmpjgqaTp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHut5CB_baaD",
        "outputId": "3f96c7aa-4f99-4460-ab87-0eac76e1807b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('rslp')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem.porter import *\n",
        "from nltk.corpus import stopwords\n",
        "!pip install -U gensim\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "from gensim.models.ldamulticore import LdaMulticore\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from gensim.models.doc2vec import Doc2Vec\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
        "from sklearn.metrics import classification_report, make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import time\n",
        "import pickle\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/MyDrive/TCC/Dados\"\n",
        "\n",
        "files = os.listdir(path)"
      ],
      "metadata": {
        "id": "LSXRd1-XeLa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "042514af-5348-4b6f-ac81-cb5240e9ea3b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/TCC/Dados/Doc2Vec/meu_doc2vec\"\n",
        "\n",
        "print(f\"Tamanho do arquivo: {os.path.getsize(file_path)} bytes\")\n",
        "\n",
        "with open(file_path, \"rb\") as f:\n",
        "    first_bytes = f.read(100)\n",
        "    print(\"Primeiros bytes do arquivo:\", first_bytes)\n"
      ],
      "metadata": {
        "id": "9NunewXMf6zR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb5beec9-a195-4b0e-b593-7a4c101a5150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do arquivo: 15667775 bytes\n",
            "Primeiros bytes do arquivo: b'\\x80\\x04\\x95\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x8c\\x15gensim.models.doc2vec\\x94\\x8c\\x07Doc2Vec\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\ndbow_words\\x94K\\x00\\x8c\\tdm_concat\\x94K\\x00\\x8c\\x0cdm_tag_count\\x94K\\x01\\x8c'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregando o Doc2Vec e testando"
      ],
      "metadata": {
        "id": "_d7qsJ_l719B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fname = '/content/drive/MyDrive/TCC/Dados/Doc2Vec/meu_doc2vec'\n",
        "model_dbow = Doc2Vec.load(fname)"
      ],
      "metadata": {
        "id": "U5yl-g_-yW5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar o tamanho dos vetores\n",
        "print(f\"Tamanho dos vetores: {model_dbow.vector_size}\")\n",
        "\n",
        "# Verificar quantos documentos foram treinados\n",
        "print(f\"Quantidade de documentos no vocabulário: {len(model_dbow.dv)}\")\n",
        "\n",
        "# Listar algumas palavras presentes no vocabulário do modelo\n",
        "print(f\"Algumas palavras do vocabulário: {list(model_dbow.wv.index_to_key)[:10]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zxtiu1Y7ScCK",
        "outputId": "c001fc8f-443d-46bb-b16f-c3ed582e449b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho dos vetores: 1000\n",
            "Quantidade de documentos no vocabulário: 116910\n",
            "Algumas palavras do vocabulário: [' ', 'a', 'e', 'o', 'r', 's', 'i', 't', 'n', 'd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegar o vetor do primeiro documento\n",
        "vector = model_dbow.dv[0]\n",
        "print(f\"Vetor do primeiro documento:\\n{vector}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2tauaRQTAV0",
        "outputId": "e85748cb-d500-4a2b-a199-2d2d2029e7dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vetor do primeiro documento:\n",
            "[ 1.67893499e-01 -9.59715769e-02  6.22485578e-02 -7.49798771e-03\n",
            "  1.06030323e-01 -1.66047495e-02  2.95609199e-02  7.14868829e-02\n",
            " -8.19778964e-02 -6.30815998e-02  3.72685716e-02  7.09560066e-02\n",
            "  6.89971447e-02  1.12894781e-01 -3.71208489e-02  7.88825452e-02\n",
            "  1.93823241e-02 -4.32453491e-02  1.46849766e-01 -1.17435090e-01\n",
            "  6.79206685e-04 -4.74756472e-02 -1.63118839e-01  5.59249111e-02\n",
            "  2.65800990e-02  8.36029723e-02  8.49194452e-02 -1.11178465e-01\n",
            "  7.66101256e-02  8.61720070e-02  1.89541832e-01  1.25876456e-01\n",
            "  5.58292717e-02 -1.98832359e-02 -1.11116804e-01 -7.15977922e-02\n",
            " -1.50187612e-01  8.14781785e-02  1.08477749e-01  5.87881505e-02\n",
            " -2.04877257e-02 -1.39233395e-02 -3.65765728e-02 -7.72505477e-02\n",
            " -5.43245971e-02  1.43563747e-02  5.25061712e-02 -1.14970893e-01\n",
            "  4.71415818e-02 -8.92853662e-02 -7.70967337e-04  2.55532353e-03\n",
            "  3.83010507e-02 -3.83300148e-02 -1.31818131e-01  3.27825360e-02\n",
            "  9.19200778e-02  4.86895852e-02  4.02680188e-02  1.35716408e-01\n",
            " -4.08476293e-02 -3.96306589e-02  4.98623066e-02  9.03531089e-02\n",
            "  4.83234301e-02 -5.46052977e-02 -4.58011739e-02 -1.10430136e-01\n",
            " -5.12698926e-02 -3.97323146e-02 -1.22437656e-01 -3.39503288e-02\n",
            " -8.81954134e-02  4.24118759e-03  2.07260926e-03 -5.46449386e-02\n",
            " -8.05938244e-02 -1.90554131e-02  5.81871904e-03  7.18540931e-03\n",
            " -1.09163802e-02 -4.17581201e-03 -3.46079394e-02  4.02433872e-02\n",
            "  3.89371142e-02  2.40999013e-02  4.50743741e-04  5.09205600e-03\n",
            " -1.00356620e-03 -4.98432890e-02 -1.50973778e-02  9.43702587e-04\n",
            " -5.17610088e-02 -5.44012822e-02 -3.62349153e-02  2.37178430e-02\n",
            "  1.72492430e-01  1.46173179e-01 -5.81929088e-02 -3.16913761e-02\n",
            " -4.16954122e-02 -7.49502108e-02  9.01237801e-02 -4.07846943e-02\n",
            "  7.88427517e-03  2.25149076e-02  3.92212383e-02  8.56114030e-02\n",
            " -6.88776001e-02  7.31137618e-02 -2.52228621e-02  1.81470916e-01\n",
            " -1.01813272e-01  5.41253574e-02  2.41560750e-02  3.08627356e-03\n",
            " -5.62608987e-02 -5.48001714e-02 -3.21682915e-02 -1.84406359e-02\n",
            "  2.01489846e-03 -1.53464433e-02  4.75924052e-02 -7.25609660e-02\n",
            "  3.38724479e-02 -1.19374320e-01 -4.16016206e-02  8.14796910e-02\n",
            "  2.23695468e-02 -7.18579516e-02 -1.83165252e-01  3.35589051e-02\n",
            "  4.40721475e-02 -2.76948176e-02 -4.33043614e-02 -5.80717325e-02\n",
            "  1.24395927e-02  6.89438954e-02 -2.98676863e-02  3.67506295e-02\n",
            " -2.00452060e-02  4.11593206e-02 -8.85219255e-04  4.52100299e-02\n",
            " -4.98180613e-02  4.88608442e-02 -2.03209557e-02 -2.87130270e-02\n",
            "  1.37678086e-04 -1.21689215e-01 -8.48115236e-02  3.20938267e-02\n",
            "  3.67180933e-03  3.04398406e-02  2.14719132e-01 -3.73947173e-02\n",
            " -1.28921300e-01  3.04798726e-02  4.92376797e-02 -1.42829359e-01\n",
            "  1.65538892e-01 -1.60415620e-01 -6.30442575e-02  1.38689652e-01\n",
            "  1.04592711e-01 -7.08987750e-03 -8.10511112e-02 -5.64914644e-02\n",
            " -2.34000143e-02 -9.94678363e-02  5.77131845e-03 -8.72106254e-02\n",
            " -1.09812021e-01 -1.25315145e-01  9.31986272e-02 -2.26628128e-02\n",
            "  3.36132534e-02  4.46572080e-02 -1.52132809e-02 -1.34024441e-01\n",
            "  3.79687883e-02 -5.56734018e-02  1.35996621e-02  1.28615107e-02\n",
            " -4.05428447e-02 -5.48849776e-02  5.44306673e-02  4.74868193e-02\n",
            "  8.50214437e-03 -2.66797729e-02 -1.00921907e-01  2.55668126e-02\n",
            "  2.30544638e-02 -4.00642194e-02  1.10769272e-02  5.11285216e-02\n",
            " -5.29921167e-02 -1.28317894e-02 -6.50125742e-02 -5.68065559e-04\n",
            "  1.33249015e-02 -2.18148325e-02 -1.33665744e-02 -5.81811294e-02\n",
            " -2.47225985e-02 -2.50063017e-02  2.88311094e-02  5.00746071e-02\n",
            "  3.12600029e-03  4.46975492e-02 -2.05052476e-02 -3.04147359e-02\n",
            "  5.89303598e-02 -1.18179463e-01  4.67016697e-02  7.11444020e-02\n",
            " -2.23567914e-02 -3.39267924e-02  2.91311126e-02 -5.02518825e-02\n",
            "  1.02721728e-01 -1.94801725e-02  1.00544289e-01  4.25781570e-02\n",
            "  1.03936769e-01 -6.44831033e-03 -9.28621218e-02  5.67812286e-02\n",
            " -5.64683713e-02 -5.10830283e-02 -9.37273167e-03 -1.42629771e-03\n",
            "  8.53768066e-02 -2.29490008e-02  1.54126301e-01 -1.65005773e-01\n",
            "  2.45788321e-02 -3.92552689e-02  4.65323627e-02  2.11766101e-02\n",
            "  1.19113505e-01  2.79650446e-02 -2.53919140e-02 -2.10357439e-02\n",
            " -3.51724178e-02 -4.67117354e-02 -5.69184460e-02  5.10466322e-02\n",
            " -7.60235637e-02  1.67787746e-02 -7.99978245e-03 -1.03979699e-01\n",
            "  7.13636130e-02  6.37569651e-02  9.34601948e-02  4.72754464e-02\n",
            " -2.90909852e-03 -4.04677412e-04  1.05667925e-02  9.63914208e-03\n",
            " -2.31782421e-02 -1.56770706e-01 -5.62146045e-02 -7.09847501e-03\n",
            " -6.00756295e-02 -6.04736479e-03 -4.48314995e-02 -7.50255119e-03\n",
            "  2.12235246e-02 -5.10477088e-02 -2.52686255e-02 -5.38712375e-05\n",
            " -5.58199035e-03 -2.46239584e-02 -3.64595577e-02 -5.98753132e-02\n",
            "  2.80434508e-02 -5.20967916e-02  1.42986700e-02 -3.05258669e-03\n",
            " -4.24713679e-02  1.03584878e-01  9.40026864e-02 -7.08973557e-02\n",
            " -4.27376553e-02  2.12817546e-02 -3.40936631e-02 -7.44573446e-03\n",
            " -4.22651358e-02 -9.48178023e-02 -1.53046576e-02 -9.16516706e-02\n",
            "  1.26850367e-01  3.85552160e-02  1.06634982e-01 -3.73486243e-03\n",
            "  9.46536809e-02  5.71525916e-02  2.13375986e-02 -8.83147214e-03\n",
            " -4.24155481e-02 -1.38880998e-01 -3.74585427e-02 -8.79880786e-02\n",
            "  6.18945584e-02  5.76684289e-02 -9.25643891e-02 -8.66333172e-02\n",
            "  3.71013279e-03 -3.15482244e-02 -6.36945665e-02  1.26403257e-01\n",
            " -1.41443750e-02  5.05073145e-02  6.20500557e-02  2.71793678e-02\n",
            "  9.55471024e-02  3.99466753e-02  6.38393983e-02  7.30916113e-02\n",
            "  1.46464817e-02 -3.05171702e-02  1.08526662e-01 -3.74707766e-03\n",
            "  3.93439047e-02  2.28682030e-02 -4.94355448e-02 -8.91182274e-02\n",
            "  4.52007689e-02 -2.93022171e-02 -2.08961428e-03 -3.01309358e-02\n",
            "  1.02608077e-01 -4.26284559e-02  6.30006120e-02  4.97851797e-05\n",
            " -3.00305337e-02  3.76133025e-02 -2.73455102e-02 -6.39343485e-02\n",
            " -3.19269747e-02 -9.04273018e-02  5.28323799e-02 -3.65930647e-02\n",
            "  2.63319947e-02  2.37260964e-02 -1.15473635e-01  2.25554034e-02\n",
            " -3.30075249e-02  3.52195799e-02 -1.04027018e-02  5.72038367e-02\n",
            "  1.38096809e-02  1.07204556e-01  4.12785523e-02  1.16632350e-01\n",
            " -3.25329304e-02 -1.12545639e-01 -5.96767515e-02  1.38362050e-01\n",
            "  2.83461288e-02 -2.63791755e-02 -1.13415206e-02  1.01610860e-02\n",
            "  5.75985946e-02  8.78381580e-02 -4.76332568e-02 -7.14804381e-02\n",
            "  7.04188645e-02  1.57405459e-03  1.02710957e-02  1.06937543e-01\n",
            "  8.82283857e-05 -3.46676409e-02 -2.75958031e-02 -4.82285582e-02\n",
            "  2.17395108e-02  7.61876395e-03  4.07431163e-02  2.93518999e-03\n",
            "  1.24278525e-02 -6.34247065e-02  1.84764843e-02  7.85146281e-02\n",
            " -1.00445881e-01  5.89164905e-02  2.25922372e-02  3.15998718e-02\n",
            " -7.50148529e-03  5.02407886e-02  8.88199136e-02  4.41098735e-02\n",
            " -1.23795848e-02  5.43575697e-02 -6.97692158e-04  5.01802079e-02\n",
            " -4.57254872e-02  3.07635050e-02  8.53040628e-03  3.72720435e-02\n",
            " -8.23692158e-02 -8.75880197e-03  5.29259406e-02  9.88069922e-03\n",
            " -1.57515742e-02 -7.77881220e-02  2.65660696e-02 -4.73701255e-03\n",
            "  6.75856769e-02 -8.60935543e-03  4.54285033e-02 -6.58113044e-03\n",
            "  2.13639569e-02 -7.25142434e-02  4.48473282e-02  3.49958278e-02\n",
            "  5.43999001e-02  2.16721874e-02 -2.22730301e-02 -5.36038540e-02\n",
            "  5.18206097e-02 -4.01382893e-02 -8.02588761e-02  7.58087039e-02\n",
            "  7.13543734e-03 -3.29066105e-02  6.42955452e-02 -4.75617126e-02\n",
            " -3.77484262e-02  4.29516211e-02 -3.84228490e-02  7.41190836e-02\n",
            "  7.36106513e-03 -4.22295034e-02  2.70374143e-03  1.07806232e-02\n",
            "  3.13677796e-04 -6.56374097e-02  6.81333244e-02  2.18810365e-02\n",
            "  2.14219168e-02  1.08240195e-01 -3.50379571e-02 -7.55274668e-02\n",
            "  1.28384128e-01  1.49341211e-01 -4.87403385e-03 -1.69902593e-01\n",
            "  1.08339246e-02  1.87997718e-03  6.49651000e-03 -4.83708493e-02\n",
            "  2.40855254e-02  1.95808578e-02 -8.80185887e-02 -3.35542113e-02\n",
            "  6.64798617e-02  1.00820631e-01 -4.14996184e-02  7.23148286e-02\n",
            " -1.88790206e-02 -2.68438663e-02 -4.31859642e-02  5.56209125e-04\n",
            " -6.91542774e-02  1.15513884e-01 -6.47009015e-02  6.01775199e-02\n",
            " -3.05220112e-02 -6.50386959e-02 -5.21170460e-02 -5.04230671e-02\n",
            "  4.02083993e-02 -1.28734615e-02  7.18680322e-02 -9.07591134e-02\n",
            "  4.69906442e-02 -8.60578790e-02 -1.22496998e-02  5.86113296e-02\n",
            " -6.34895265e-02 -9.26759746e-03  6.34679496e-02  8.36133361e-02\n",
            " -7.96580166e-02 -7.22345635e-02 -9.89921615e-02  5.83889745e-02\n",
            " -4.64083813e-02  3.88463810e-02  1.37259830e-02  6.32242635e-02\n",
            "  4.04505320e-02 -5.59382550e-02  9.30939242e-03  1.26575390e-02\n",
            " -5.81885781e-03  4.40824181e-02 -7.43125901e-02  6.09701835e-02\n",
            "  3.42566073e-02  5.58597669e-02 -6.30686642e-04 -1.25074964e-02\n",
            "  4.20680903e-02  9.88931675e-03 -3.74352932e-02  5.01500331e-02\n",
            " -1.00357048e-02 -3.27773020e-02  1.58680398e-02  6.30872697e-02\n",
            "  7.67699853e-02 -1.48080764e-02 -1.94592755e-02 -4.85813245e-02\n",
            " -7.20729232e-02 -3.06263641e-02  1.62064862e-02  7.17317685e-02\n",
            " -1.25940163e-02  1.51817491e-02 -7.82485902e-02 -9.29943025e-02\n",
            "  1.17083430e-01  6.39365688e-02 -1.45441771e-01 -8.02338030e-03\n",
            " -3.24244723e-02  5.76381907e-02  1.53150624e-02 -4.93896334e-03\n",
            "  5.63376285e-02  3.55022065e-02 -6.65957779e-02 -3.07278745e-02\n",
            " -8.94234458e-04 -3.31015587e-02 -1.95864923e-02 -1.43980584e-03\n",
            "  6.02933802e-02 -5.01823835e-02 -5.41390963e-02  1.42064527e-01\n",
            " -7.07814619e-02 -5.26680471e-03 -6.68564886e-02 -5.62168919e-02\n",
            "  2.58816574e-02 -9.39326212e-02 -6.45860210e-02 -5.22301272e-02\n",
            "  1.30613809e-02 -4.60671745e-02 -1.24473413e-02  1.16495885e-01\n",
            "  3.31591852e-02 -5.75953722e-02  2.60783378e-02  4.01026616e-03\n",
            "  1.76311824e-02  8.05739127e-03  3.39092873e-02  8.62812325e-02\n",
            "  4.45927009e-02 -1.08246289e-01 -1.09275490e-01  5.26215769e-02\n",
            " -4.51475121e-02  2.60305088e-02 -4.56770547e-02 -7.20533775e-03\n",
            "  9.21586528e-02 -4.61707786e-02 -6.38715103e-02  2.87161227e-02\n",
            "  6.03704453e-02 -2.02665180e-02  1.69549230e-02  5.58000207e-02\n",
            "  1.51592921e-02  3.84786204e-02 -6.30980134e-02  6.12196885e-02\n",
            "  4.11956795e-02  7.77854398e-02 -1.16368840e-02 -6.05021231e-02\n",
            " -2.26334706e-02 -1.69626661e-02 -4.04738896e-02 -1.50040714e-02\n",
            " -1.55854225e-02 -3.27905156e-02  2.31664777e-02 -4.90360446e-02\n",
            " -3.98579873e-02 -4.79452722e-02  1.70806069e-02 -5.38664013e-02\n",
            " -7.13837370e-02 -4.96156365e-02  5.51636964e-02 -3.77678461e-02\n",
            " -2.34430823e-02 -1.66506805e-02  4.41028886e-02  3.40564735e-02\n",
            "  2.26978473e-02  1.73315667e-02 -3.13829188e-03  7.76260765e-03\n",
            "  7.50839040e-02 -3.30539085e-02 -7.69329816e-02  9.85382721e-02\n",
            " -3.44153903e-02  2.26457231e-03 -7.20388489e-03 -2.86571607e-02\n",
            " -7.20761791e-02  1.53761297e-01  6.03339151e-02  3.57976928e-02\n",
            "  2.39208899e-02  7.96231702e-02 -7.72079006e-02  6.46040812e-02\n",
            "  6.68012816e-03  1.00368455e-01  7.98926130e-03 -4.10975516e-02\n",
            " -2.25058403e-02 -4.30555269e-02  4.98280525e-02  1.09186340e-02\n",
            "  8.85025132e-03 -6.22568978e-03  6.77917572e-03 -8.84962752e-02\n",
            " -2.80726179e-02 -6.40809014e-02  8.83427728e-03  3.54612735e-03\n",
            "  1.46232694e-01 -7.52748847e-02 -2.01123790e-03 -7.91333690e-02\n",
            "  1.70511063e-02 -8.35434347e-02  1.01469057e-02  9.21917185e-02\n",
            "  9.05322358e-02  6.18009130e-03  5.31296283e-02 -7.35015944e-02\n",
            "  1.11177182e-02 -4.95247170e-02  3.36819626e-02 -7.73658007e-02\n",
            " -1.50195599e-01 -7.94126987e-02 -5.09480536e-02 -7.21542686e-02\n",
            "  2.98941750e-02  2.99427360e-02  7.28782937e-02  6.46879105e-03\n",
            "  8.23497847e-02 -1.41748204e-03 -2.50204536e-03  4.38894182e-02\n",
            "  1.45527069e-02 -3.44655663e-02  3.24565172e-02  9.60294623e-04\n",
            " -3.77137698e-02 -3.34541202e-02  6.05042372e-03 -9.11424905e-02\n",
            " -2.97869612e-02  1.56566091e-02  6.46278411e-02 -5.36461500e-03\n",
            "  8.10193457e-03  8.66957977e-02  1.64539441e-02 -1.00332983e-02\n",
            "  5.21840006e-02  2.92577557e-02  7.01850429e-02 -4.87170890e-02\n",
            "  6.60069808e-02 -5.85483275e-02 -6.40485063e-03  7.42723560e-03\n",
            "  1.38698309e-03  9.48265791e-02 -1.58762690e-02  6.49140030e-03\n",
            " -5.62980808e-02  4.48993929e-02 -5.37906140e-02 -1.05725586e-01\n",
            "  2.48881225e-02 -4.85598780e-02 -1.28685767e-02 -2.32119486e-02\n",
            " -8.85208836e-04 -6.05709385e-03 -2.46590772e-03 -2.80613452e-03\n",
            "  4.55277935e-02 -4.73459531e-03  1.07974578e-02 -4.35854048e-02\n",
            " -3.29126678e-02 -4.15044613e-02 -1.87156424e-02  1.34055866e-02\n",
            " -4.34167348e-02 -8.56517628e-03 -7.51680508e-02  4.40079793e-02\n",
            "  3.18027474e-02 -8.13889205e-02 -6.55327865e-04  4.27860096e-02\n",
            "  2.37154700e-02 -3.47118303e-02 -4.44368981e-02 -3.34416740e-02\n",
            " -6.57875743e-03  1.90072972e-02  4.66147140e-02  4.04508859e-02\n",
            " -1.72236245e-02  2.22453345e-02 -7.71155879e-02 -5.53559065e-02\n",
            " -1.46935433e-02 -6.87634647e-02 -1.55717758e-02 -2.27745678e-02\n",
            "  7.44539173e-03  3.62555720e-02  1.02231260e-02  8.28847885e-02\n",
            "  2.59810183e-02  2.42911596e-02  5.82445264e-02  3.42004560e-02\n",
            "  4.01407406e-02 -5.64987287e-02  2.68993620e-02 -5.02403416e-02\n",
            "  6.43021092e-02 -7.43904412e-02  5.06643690e-02  3.22124809e-02\n",
            "  1.66845191e-02 -4.02602814e-02  3.63654420e-02  2.15924531e-02\n",
            "  1.11150600e-01 -4.03261073e-02  6.56824708e-02  6.98622316e-02\n",
            " -3.01956956e-04 -2.28433236e-02  1.09245293e-01 -1.90891121e-02\n",
            "  6.25819527e-03  1.26449410e-02  1.24527156e-01  4.85552140e-02\n",
            "  6.36484250e-02 -3.63718048e-02  1.93892598e-01 -2.97936462e-02\n",
            "  3.42085622e-02  2.15759389e-02  1.08168036e-01 -3.39121111e-02\n",
            "  5.03138527e-02  1.01682702e-02  3.44990939e-02 -1.00560196e-01\n",
            " -7.71970896e-04 -3.72267030e-02  1.02539964e-01 -1.07844159e-01\n",
            "  8.17084163e-02 -3.64903174e-02  6.66719526e-02  7.80464634e-02\n",
            "  8.49622935e-02 -5.48882522e-02  1.24427244e-01 -1.60145406e-02\n",
            "  1.17597081e-01 -6.12804219e-02 -6.74857050e-02  4.91556115e-02\n",
            " -9.72908065e-02 -1.75250955e-02 -3.07834670e-02  7.42818192e-02\n",
            "  4.93315980e-02 -5.17342761e-02 -1.87409371e-02  2.27910895e-02\n",
            " -6.99298456e-02  1.19555131e-01  1.06020905e-02  1.84648130e-02\n",
            " -2.83020232e-02 -1.21296398e-01  3.52048203e-02  9.14994702e-02\n",
            "  4.38804179e-03 -1.13416389e-01  4.13718037e-02 -4.44121510e-02\n",
            "  1.14705116e-01 -1.35661587e-02 -2.36022398e-02 -7.14149922e-02\n",
            "  1.64071560e-01  7.78709054e-02 -3.80744487e-02 -2.45795888e-03\n",
            "  1.53427273e-01  7.03331456e-02 -7.58907497e-02  1.75557584e-02\n",
            " -1.39774065e-02  2.04827040e-02  4.19020019e-02  4.74181548e-02\n",
            " -2.45185420e-02 -3.16612870e-02  2.42091017e-03  1.94290467e-02\n",
            " -2.55984664e-02 -5.76056391e-02 -2.00253651e-02  6.00983500e-02\n",
            " -2.35998128e-02  5.43425567e-02  1.33708596e-01 -2.17161253e-01\n",
            "  6.79311454e-02 -2.56706104e-02 -1.65635690e-01  1.97151139e-01\n",
            " -5.73411991e-04 -5.68835512e-02 -1.49743319e-01  4.71948758e-02\n",
            "  6.64388463e-02 -3.21194530e-02 -8.53553936e-02  1.17086709e-01\n",
            " -4.67637889e-02  1.17282301e-01 -6.04831502e-02 -2.10909471e-02\n",
            "  9.01630893e-03  1.30341917e-01  3.94264460e-02  8.69366154e-02\n",
            "  9.05744508e-02 -9.09650102e-02 -1.01046460e-02 -2.52677333e-02\n",
            " -2.33632675e-03  9.79224667e-02  2.96388636e-04 -5.45651168e-02\n",
            " -3.19874622e-02 -1.52303989e-03 -2.16485886e-03  2.15432234e-02\n",
            "  1.17684929e-02  5.65504842e-02  1.12480698e-02  6.73828050e-02\n",
            " -2.19227932e-02 -5.99066615e-02  3.43278274e-02  3.61276194e-02\n",
            "  4.80041094e-02  9.02451277e-02  7.45145082e-02 -3.57364491e-02\n",
            "  2.33326498e-02  2.29906905e-02 -2.15333458e-02  6.10386133e-02\n",
            "  2.34608520e-02 -1.03292530e-02 -1.15317237e-02  7.00563043e-02\n",
            " -1.43462392e-02  7.42180422e-02  1.20672686e-02 -5.69733642e-02\n",
            " -3.49981673e-02 -7.49684125e-02  5.36820441e-02 -2.60448027e-02\n",
            " -4.62988392e-02 -4.76445742e-02  3.42093483e-02 -6.51251078e-02\n",
            "  6.20931201e-02 -7.90174082e-02  4.47656214e-02 -1.08351879e-01\n",
            " -1.09158367e-01 -5.85834272e-02  3.33151147e-02  8.12405497e-02\n",
            " -1.19881943e-01  1.86264422e-02  5.45718111e-02  1.98570210e-02\n",
            "  5.24913380e-03 -4.30500880e-02 -8.75301473e-03 -2.42549907e-02\n",
            " -7.60703757e-02 -9.56733525e-02 -2.99636088e-03  6.69682398e-04\n",
            " -9.54847485e-02  4.18577679e-02 -5.91417514e-02  1.16965282e-04\n",
            "  1.20401802e-02 -1.42179625e-02  4.45006453e-02  1.30767241e-01\n",
            " -2.47599781e-02  4.54414636e-02 -6.17121682e-02 -5.07903881e-02\n",
            "  4.70944643e-02  6.96341321e-02  5.86719252e-03 -4.68934327e-03\n",
            "  2.28350866e-03 -7.67239630e-02  4.10969667e-02 -4.56089452e-02\n",
            " -4.64391746e-02  7.98535496e-02  6.11164682e-02  9.35257375e-02\n",
            " -4.25216556e-02  3.08098514e-02 -4.80572768e-02  1.38392495e-02\n",
            " -3.47191393e-02 -4.20357473e-02  1.03085181e-02  9.96999443e-02\n",
            " -6.85951393e-03  7.23136663e-02  6.63782358e-02 -4.33187261e-02\n",
            "  1.85233280e-02  1.06159255e-01 -6.49497006e-03  3.35737318e-03\n",
            "  5.41319922e-02 -1.79415420e-02 -6.18536286e-02  1.15568563e-02\n",
            "  8.97499248e-02  4.23817895e-02 -2.59829219e-02 -4.48384769e-02\n",
            " -3.94942276e-02  2.99394447e-02  7.18688369e-02  4.38603647e-02\n",
            " -5.31837679e-02 -3.19278147e-03  2.84797587e-02 -9.96019989e-02\n",
            " -8.34160149e-02 -4.91966829e-02 -8.34947452e-02 -1.17317168e-02\n",
            "  7.12700980e-03 -3.16418223e-02 -6.30494729e-02 -1.56259071e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encontrar os 5 documentos mais similares ao primeiro\n",
        "similar_docs = model_dbow.dv.most_similar(0, topn=5)\n",
        "print(f\"Documentos mais similares ao primeiro: {similar_docs}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viNo38vLTL1z",
        "outputId": "6cd7ebdd-a1a1-48a5-cbf3-a63b1bb26b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documentos mais similares ao primeiro: [(99464, 0.8115514516830444), (106603, 0.7995979189872742), (4513, 0.7983075976371765), (4787, 0.7942085862159729), (261, 0.7788448333740234)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nova_frase = \"Esse jogo é muito bom\"\n",
        "vetor = model_dbow.infer_vector(nova_frase.split())  # Gera um vetor para a frase\n",
        "print(model_dbow.dv.most_similar([vetor], topn=5))  # Encontra os documentos mais parecidos\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y68LbLP9TrFY",
        "outputId": "e4faa8ad-749d-46bb-b337-aaaaf18d171e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(105969, 0.9028264284133911), (105756, 0.8919234871864319), (105687, 0.8876928687095642), (25457, 0.8848954439163208), (104560, 0.8838923573493958)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_dbow.dv.most_similar(0, topn=5))  # Mostra os 5 documentos mais similares ao primeiro\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD5OkqzheEyn",
        "outputId": "bc57a3ad-c3b3-468b-e164-07c498129b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(99464, 0.8115514516830444), (106603, 0.7995979189872742), (4513, 0.7983075976371765), (4787, 0.7942085862159729), (261, 0.7788448333740234)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model_dbow.dv.index_to_key)[:20])  # Mostra os primeiros 20 documentos armazenados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkbGCODvfkgJ",
        "outputId": "20517672-a0da-4f5e-e432-8c5732f71dbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_dbow.dv.most_similar(0, topn=5))  # Mostra os 5 documentos mais similares ao primeiro\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2S7dxQ0frB2",
        "outputId": "1604946d-a77a-4fd3-a442-6f91e52f4ac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(99464, 0.8115514516830444), (106603, 0.7995979189872742), (4513, 0.7983075976371765), (4787, 0.7942085862159729), (261, 0.7788448333740234)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento Word2Vec"
      ],
      "metadata": {
        "id": "vEW3bg-79JK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Caminho base onde estão os arquivos\n",
        "reviews_path = \"/content/drive/MyDrive/TCC/Dados/Reviews Da Steam filtradas/\"\n",
        "\n",
        "# Listar tudo dentro da pasta\n",
        "conteudo = os.listdir(reviews_path)\n",
        "\n",
        "# Separar arquivos e diretórios\n",
        "pastas = [f for f in conteudo if os.path.isdir(os.path.join(reviews_path, f))]\n",
        "arquivos = [f for f in conteudo if os.path.isfile(os.path.join(reviews_path, f))]\n",
        "\n",
        "print(\"📂 Diretórios encontrados:\", pastas)\n",
        "print(\"📄 Arquivos encontrados:\", arquivos)\n"
      ],
      "metadata": {
        "id": "ud6pIAl59NhE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3395beaa-cf81-4e36-e326-84144e3ab843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Diretórios encontrados: ['Action', 'Combined', 'Adventure', 'FPS', 'Horror', 'Sports', 'Simulation', 'Indie', 'RPG', 'Racing', 'Strategy']\n",
            "📄 Arquivos encontrados: ['02_A_Word2Vec.ipynb', 'codigo_final.ipynb', 'concat.ipynb', '01_featurization-word2vec.ipynb', 'Racing_json_rest_part_50.json', 'Action_json_rest_part_50.json', 'Adventure_json_rest_part_50.json', 'FPS_json_rest_part_50.json', 'Horror_json_rest_part_50.json', 'Indie_json_rest_part_50.json', 'RPG_json_rest_part_50.json', 'Simulation_json_rest_part_50.json', 'Sports_json_rest_part_50.json', 'Strategy_json_rest_part_50.json', 'Combined_json_rest_part_50.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Caminho principal\n",
        "reviews_path = \"/content/drive/MyDrive/TCC/Dados/Reviews Da Steam filtradas/\"\n",
        "\n",
        "# Listar diretórios que representam os gêneros\n",
        "generos = [f for f in os.listdir(reviews_path) if os.path.isdir(os.path.join(reviews_path, f))]\n",
        "\n",
        "# Escolher um gênero para exemplo\n",
        "genero_exemplo = generos[0]  # Pegando o primeiro gênero da lista\n",
        "genero_path = os.path.join(reviews_path, genero_exemplo)\n",
        "\n",
        "# Listar arquivos JSON dentro do diretório do gênero\n",
        "arquivos_json = [f for f in os.listdir(genero_path) if f.endswith(\".json\")]\n",
        "\n",
        "print(f\"📂 Gênero escolhido: {genero_exemplo}\")\n",
        "print(f\"📄 Arquivos JSON encontrados: {arquivos_json}\")\n",
        "\n",
        "# Exemplo: Carregar um JSON\n",
        "if arquivos_json:\n",
        "    json_path = os.path.join(genero_path, arquivos_json[0])  # Pegando o primeiro JSON\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        dados = json.load(f)\n",
        "        print(f\"🔍 Exemplo de dados: {list(dados.items())[:2]}\") # Exibir apenas os 2 primeiros registros\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTmPs5Su4kjJ",
        "outputId": "7c75d7db-49bf-4648-fa82-ccad2493054b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Gênero escolhido: Action\n",
            "📄 Arquivos JSON encontrados: ['Action_SkatemastaTcheco.json', 'Action_SteelRats.json', 'Action_ATOMEGA.json', 'Action_JustCause3MultiplayerMod.json', 'Action_VroomKaboom.json', 'Action_MiniBattlegrounds.json', 'Action_SamuraiRiot.json', 'Action_ViciousAttackLlamaApocalypse.json', 'Action_OffensiveCombatRedux.json', 'Action_SteampunkTower2.json', 'Action_MayheminSingleValley.json', 'Action_Hacktag.json', 'Action_Dungeons&DragonsDarkAlliance.json', 'Action_BloodAncestors.json', 'Action_AcanaHeart3LOVEMAXSIXSTARSXTEND.json', 'Action_AssassinsCreedOriginsTheHiddenOnes.json', 'Action_review_624910.json', 'Action_MysteriaOccultShadows.json', 'Action_HammerHelm.json', 'Action_Zombotron.json', 'Action_DungeonsofTalDoria.json', 'Action_TheInitial.json', 'Action_Injustice2.json', 'Action_IdleChampionsOfTheFOrgottenRealms.json', 'Action_DrunkenWrestlers2.json', 'Action_SkyForceReloaded.json', 'Action_DeadMaze.json', 'Action_CryptStalker.json', 'Action_Espire1VROperative.json', 'Action_BDSMBigDrunkSatanicMassacre.json', 'Action_GrazeCounter.json', 'Action_BladeandSorcery.json', 'Action_MORDHAU.json', 'Action_WarTechFighters.json', 'Action_ManaSpark.json', 'Action_WarRobotsVRTheSkirmish.json', 'Action_DeceitWerewolfPack.json', 'Action_review_631450.json', 'Action_SonofScoregasm.json', 'Action_DevilMayCryHDCollection.json', 'Action_Starblast.json', 'Action_WorldWar3.json', 'Action_Einar.json', 'Action_FightNRage.json', 'Action_OatsStudios.json', 'Action_NarutoToBorutoShinobiStriker.json', 'Action_Tannenberg.json', 'Action_303SquadronBattleofBritain.json', 'Action_TimeWArpers.json', 'Action_HeroesofHammerwatch.json', 'Action_SigiAFartforMelusina.json', 'Action_review_677370.json', 'Action_review_636690.json', 'Action_Splitgate.json', 'Action_SAS.json', 'Action_TalesOfglory.json', 'Action_DragonBallFighterZ.json', 'Action_HalfLifeCaged.json', 'Action_omegaStrike.json', 'Action_OUTRIDERS.json', 'Action_EagleIslandTwist.json', 'Action_Descenders.json', 'Action_ZeusBattlegrounds.json', 'Action_MurderousPursuits.json', 'Action_OperationWarcadeVR.json', 'Action_NoLights.json', 'Action_MineFight.json', 'Action_Arma3Malden.json', 'Action_1982.json', 'Action_ABloodyNight.json', 'Action_review_639780.json', 'Action_Battlegun.json', 'Action_TheDroneRacingLeagueSimulator.json', 'Action_TheKingofFightersDestiny(1).json', 'Action_HellLetLoose.json', 'Action_CallysCaves4.json', 'Action_THEKINGOFFIGHTERSDESTINY.json', 'Action_HalfLifeTheFreemanChronicles.json', 'Action_SEGAMEGADRIVECLASSICS.json', 'Action_DeathtoSpiesMomentofTruth.json', 'Action_SniperGhostWarrior.json', 'Action_SniperGhostWarrior2.json', 'Action_Razor2HiddenSkies.json', 'Action_BatmanArkhamAsylumGOTY.json', 'Action_Clutch.json', 'Action_DefenceAlliance2.json', 'Action_RedOrchestra2.json', 'Action_ForeignLegionBucketsofBlod.json', 'Action_review_36630.json', 'Action_NinjaBlade.json', 'Action_MDK.json', 'Action_review_38830.json', 'Action_PainkillerBlackEdition.json', 'Action_AquaNox.json', 'Action_Chaser.json', 'Action_Mafia.json', 'Action_review_41010.json', 'Action_SeriousSamClassicTheFirstEncounter.json', 'Action_SeriousSamClassicTheSecondEncounter.json', 'Action_SeriousSam3.json', 'Action_review_688430.json', 'Action_KillingFloorIncursion.json', 'Action_FogOfWarFreeEdition.json', 'Action_PopulationOne.json', 'Action_SpaceFighter.json', 'Action_ZombieArmy4DeadWar.json', 'Action_ArmyMenRTS.json', 'Action_NotMyCar.json', 'Action_BulletWitch.json', 'Action_FolkloreHunter.json', 'Action_review_696680.json', 'Action_review_696790.json', 'Action_UntilNoneRemainBattleRoyalePCEdition.json', 'Action_WorldWarZaftermath.json', 'Action_SCP.json', 'Action_TheLastBlade2.json', 'Action_TheKingOfFighters97.json', 'Action_ProjectMercury.json', 'Action_DevWill.json', 'Action_SuperBombermanR.json', 'Action_BlazBlue.json', 'Action_Ben10.json', 'Action_Hidden&DangerousActionPack.json', 'Action_HIddenDangerous2CourageUnderFire.json', 'Action_GenerationZero.json', 'Action_SenseofTheDevil.json', 'Action_BLOCKSPOT.json', 'Action_WillToLiveOnline.json', 'Action_review_707830.json', 'Action_Gridiron.json', 'Action_OverrideMechCityBrawl.json', 'Action_BloodyGlimpse.json', 'Action_SkyJump.json', 'Action_GenesisAlphaOneDeluxeEdition.json', 'Action_review_33420.json', 'Action_review_33910.json', 'Action_Arma2.json', 'Action_Arma2ArmyoftheCzechRepublic.json', 'Action_Arma2OperationArrowhead.json', 'Action_ArmoredKitten.json', 'Action_BlackCloverQuartetKnights.json', 'Action_LEFTALIVE.json', 'Action_AntinomyofCommonFlowers.json', 'Action_KritikaOnlineFreeElitePlayersPack.json', 'Action_review_717690.json', 'Action_Warmonger.json', 'Action_Fridaythe13thTheGameEmotePartyPack1.json', 'Action_review_719690.json', 'Action_KillerInstinctTheCompleteSoundtrack.json', 'Action_LEGOMARVELSUPERHEROES2.json', 'Action_RAD.json', 'Action_ModernCombatVersus.json', 'Action_ThePiratePlagueoftheDead.json', 'Action_TheRareNine.json', 'Action_ReX.json', 'Action_ELDERBORN.json', 'Action_SniperEliteV2Remastered.json', 'Action_Zomborg.json', 'Action_DynastyWarrior9.json', 'Action_review_730590.json', 'Action_Hammer2.json', 'Action_CrashBandicootNsanetrilogy.json', 'Action_WarTrigger2.json', 'Action_Injustice2FighterPack2.json', 'Action_WHeelRidersonlineOBT.json', 'Action_BattleRush.json', 'Action_review_734880.json', 'Action_Fridaythe13thTheGameCostumePartyCounselorClothingPack.json', 'Action_PostScriptum.json', 'Action_BlackClover.json', 'Action_Breathedge.json', 'Action_NewGundamBreaker.json', 'Action_review_739280.json', 'Action_DarkOldSun.json', 'Action_DRAGONBALLXENOVERSE2ExtraDLCpack2.json', 'Action_Fridaythe13thTheGameJasonPart7MacheteKillPack.json', 'Action_DragonBallXenoverse2ExtraDLCPack4.json', 'Action_JohnTheZombie.json', 'Action_MegaMan11.json', 'Action_Slayone.json', 'Action_MegaManXLegacyCollection.json', 'Action_GrooveCoaster.json', 'Action_RiseofAges.json', 'Action_TomClancysRainbowSiexSiegeYear3.json', 'Action_Arma3TacOpsMissionPack.json', 'Action_Overclocked.json', 'Action_Reflex.json', 'Action_TheWalkingZombieDeadCity.json', 'Action_HardcoreMecha.json', 'Action_BattleriteAllChampionsPack.json', 'Action_HalLife2YearLongAlarm.json', 'Action_ZulaGlobal.json', 'Action_MyHeroOnesJustice.json', 'Action_StandOutVRBattleRoyale.json', 'Action_TheSinkingCity.json', 'Action_StreetFighterVSeason3CharacterPass.json', 'Action_FracturedLands.json', 'Action_review_751390.json', 'Action_AftertheFall.json', 'Action_review_751610.json', 'Action_BlackFuture88.json', 'Action_Hellbound.json', 'Action_BombBotsArena.json', 'Action_review_754350.json', 'Action_OnePIeceWorldSeeker.json', 'Action_RingOfElysium.json', 'Action_TokyoGhoulreCalltoExist.json', 'Action_BigDay.json', 'Action_PAYDAY2h3h3CharacterPack.json', 'Action_AncientWarfare3.json', 'Action_VampireTheMasquerade.json', 'Action_review_760760.json', 'Action_OnimushaWarlords.json', 'Action_LongLiveSanta.json', 'Action_FarCry5SeasonPass.json', 'Action_Maelstrom.json', 'Action_FeartheNight.json', 'Action_BeanBattles.json', 'Action_LightBearers.json', 'Action_WarRobots.json', 'Action_GrandTheftAutoVCriminalEnterpriseStarterPack.json', 'Action_Primallight.json', 'Action_ShieldImpact.json', 'Action_AragamiNightfall.json', 'Action_Thespywhoshotme.json', 'Action_BattleRoyaleTrainer.json', 'Action_MIGHTYGUNVOLTBURST.json', 'Action_YUMENIKKIDREAMDIARY.json', 'Action_CriminalBundle.json', 'Action_DektopAgentsCov1d999.json', 'Action_review_779300.json', 'Action_DeathFieldTheBattleRoyaleDisaster.json', 'Action_DragonBallFighterZBardock.json', 'Action_DragonBallFighterZBroly.json', 'Action_DRAGONBALLFIGHTERZVegitoSSGSS.json', 'Action_DragonBallFighterZVegeta.json', 'Action_UnrulyHeroes.json', 'Action_DoomEternal.json', 'Action_BattleTanksLegendsofWorldWarII.json', 'Action_Diepigdie.json', 'Action_Ironsight.json', 'Action_TreasureStack.json', 'Action_RulesOfSurvival.json', 'Action_DeadOrSchool.json', 'Action_TheQuitMan.json', 'Action_WorldofWarplanes.json', 'Action_Paunch.json', 'Action_Exocraft.json', 'Action_LetItDie.json', 'Action_KoihimeEnbuRyoRairai.json', 'Action_WorldofTennisRoaring20s.json', 'Action_review_797470.json', 'Action_CrocoMars.json', 'Action_review_799520.json', 'Action_Magnificient5.json', 'Action_UnderNightInBirth.json', 'Action_HellboundSurvivalMode.json', 'Action_DestroyAllHumans.json', 'Action_Papersplease.json', 'Action_Wrecked.json', 'Action_RUSSIABATTLEGROUNDS.json', 'Action_ZeroRanger.json', 'Action_BrazilianRoot.json', 'Action_BreachofContractReloaded.json', 'Action_HalfLifeAbsoluteZero.json', 'Action_Supraland.json', 'Action_RealmRoyale.json', 'Action_Injustice2InfiniteTransforms.json', 'Action_SpaceHulkDeathwing.json', 'Action_MonkeyKingMasteroftheClouds.json', 'Action_MetalWOlfChaosXD.json', 'Action_EscapeFromTethys.json', 'Action_review_822770.json', 'Action_FarCry5DeluxePack.json', 'Action_Defiance2050Beta.json', 'Action_DeadEndJob.json', 'Action_TombTowers.json', 'Action_WarhammerVermintide2ShadowsOverBogenhafen.json', 'Action_BlondeDriver.json', 'Action_review_830660.json', 'Action_JetsnGuns2.json', 'Action_WarriorsOrochi4.json', 'Action_ZombieDerby.json', 'Action_InfernalRadiation.json', 'Action_StarValor.json', 'Action_CubeZone.json', 'Action_YakuzaKiwami.json', 'Action_ConquerorsBlade.json', 'Action_Dreadnought.json', 'Action_StayCoolKobayashiSan.json', 'Action_PixelGameMakerMV.json', 'Action_OperationThunderstorm.json', 'Action_HyperParasite.json', 'Action_BloodstainedCurseOfTheMoon.json', 'Action_DeadOrAlive6.json', 'Action_BattleRoyaleSurvivors.json', 'Action_OutlawsOfTheOldWest.json', 'Action_Daymare1998.json', 'Action_GalaxyChampionsTV.json', 'Action_Slab.json', 'Action_DeadlyFlare.json', 'Action_TowerHunterErzasTrial.json', 'Action_KurtzPel.json', 'Action_TheFriendsofRingoIshikawa.json', 'Action_DYSMANTLE.json', 'Action_BrawlahallaSpringchampionship2018pack.json', 'Action_KatamariDamacyREROLL.json', 'Action_SniperStrikeSpecialOps.json', 'Action_SuperDestronaut.json', 'Action_RaccooVenture.json', 'Action_FreefallTournament.json', 'Action_GUiltyGear(1).json', 'Action_BloodHarvest3.json', 'Action_DragonBallZKakarot.json', 'Action_MaximumAction.json', 'Action_SuperfightersDeluxe.json', 'Action_review_856620.json', 'Action_UntillYouFall.json', 'Action_SecretNeighbor.json', 'Action_USA2020.json', 'Action_BountyBattle.json', 'Action_DemonsAreCrazy.json', 'Action_CyberShadow.json', 'Action_review_861810.json', 'Action_HITMAN2.json', 'Action_Fallback.json', 'Action_HellCat.json', 'Action_SuperBitBlasterXL.json', 'Action_OutofReachTreasureRoyale.json', 'Action_FarCry5InsideEdensGate.json', 'Action_TheFederalRescue.json', 'Action_LEGODCSuperVillains.json', 'Action_FightingExLayer.json', 'Action_BattleRush2.json', 'Action_RogueCompany.json', 'Action_CapsellaTheLightsofLucern.json', 'Action_review_872790.json', 'Action_SurvivalZBattlegrounds.json', 'Action_TotalWarThreeKingdomsReignofBlood.json', 'Action_SoulcaliburVIDLC2B.json', 'Action_Climb.json', 'Action_GravityWars.json', 'Action_Comanche.json', 'Action_BattleriteRoyale.json', 'Action_WarRock.json', 'Action_Noita.json', 'Action_BrawhallaSummerChampionship2018.json', 'Action_TheSlater.json', 'Action_360NoScopeArena.json', 'Action_CRSED.json', 'Action_CapcomBeatemUp.json', 'Action_DevilsHunt.json', 'Action_EventPAssSanhok.json', 'Action_NTBSSMasterCharacterTrainingPack(1).json', 'Action_NTBSSMasterCharacterTrainingPackMadaUchiha.json', 'Action_MetroExodusTheTwoColonels.json', 'Action_MetroExodusSamStory.json', 'Action_platoon.json', 'Action_DevilEngine.json', 'Action_EndlessBattle.json', 'Action_review_897290.json', 'Action_GODEATER3.json', 'Action_LastOasis.json', 'Action_SubdivisionInfinity.json', 'Action_Killsquad.json', 'Action_AssasinsCreedIIIRemastered.json', 'Action_PlasticSoldiers.json', 'Action_MistSurvival.json', 'Action_SNKRX.json', 'Action_PixelStrike3D.json', 'Action_ThemandUs.json', 'Action_TheWalkingDeadSaints&Sinners.json', 'Action_SCUMSUpporterPack.json', 'Action_ResidentEvil2ClaireCostume98.json', 'Action_ResidentEvil2.json', 'Action_ResidentEvil2AllIngameRewardsUnlocked.json', 'Action_ModernCombat5.json', 'Action_MortalRoyale.json', 'Action_Knightin.json', 'Action_Arboria.json', 'Action_MetroExodusExpansionPass.json', 'Action_Back4Blood.json', 'Action_WolfQuestAnniversaryEdition.json', 'Action_YakuzaKiwami2.json', 'Action_BlazingCore.json', 'Action_RTypeDimensionsEX.json', 'Action_AzureReflections.json', 'Action_AceCombat7.json', 'Action_review_929860.json', 'Action_BOLSOMITO.json', 'Action_AmericanFugitive.json', 'Action_WarplanesWW2Dogfight.json', 'Action_review_938460.json', 'Action_Darksburg.json', 'Action_PandemicExpress.json', 'Action_FarCryNewDawn.json', 'Action_ColtCanyon.json', 'Action_Minoria.json', 'Action_review_942810.json', 'Action_PanPanda.json', 'Action_Abalyte.json', 'Action_GachiHeroes.json', 'Action_TheLastFriend.json', 'Action_ZombieBuilderDefense.json', 'Action_review_945700.json', 'Action_review_946430.json', 'Action_MarbleCombat.json', 'Action_MagicaeMundi.json', 'Action_REDO.json', 'Action_Hitman2HawkesBay.json', 'Action_Volcanoids.json', 'Action_review_952320.json', 'Action_BrawlhallaBCX2018Pack.json', 'Action_MASSBuilder.json', 'Action_WarDust.json', 'Action_AfronttooFar.json', 'Action_SeedoftheDead.json', 'Action_LetItFlow.json', 'Action_Maytroid.json', 'Action_DJMAXRESPECTV.json', 'Action_MonsterHunterWorldHighResolutionTexturePack.json', 'Action_review_961080.json', 'Action_review_961090.json', 'Action_review_961440.json', 'Action_TravisStrikesAgainNoMoreHeroesCompleteEdition.json', 'Action_review_962400.json', 'Action_SKATERXL.json', 'Action_Contractors.json', 'Action_Prodeus.json', 'Action_WalkingZombie2.json', 'Action_BoomerangFu.json', 'Action_ChronosBeforetheAshes.json', 'Action_DYNASTYWARRIORS7XtremeLegendsDefinitiveEdition.json', 'Action_SmokingSnakes.json', 'Action_ChronoBreach.json', 'Action_FPSTraining.json', 'Action_review_971925.json', 'Action_review_971996.json', 'Action_review_971998.json', 'Action_review_971999.json', 'Action_SniperGhostWarriorContracts.json', 'Action_review_973810.json', 'Action_DAMNOSAUR.json', 'Action_Resolutiion.json', 'Action_MetalSlugXX.json', 'Action_WarpzoneDrifter.json', 'Action_MortalKombat11.json', 'Action_EnderalForgottenSotiresSpecialEdition.json', 'Action_SteelSwordStory.json', 'Action_SaintsRowTheThirdRemastered.json', 'Action_RebelForces.json', 'Action_TheAscent.json', 'Action_OneFingerDeathPunch2.json', 'Action_PixelBattleRoyale.json', 'Action_SynthetikArena.json', 'Action_DRONETheGame.json', 'Action_PlanetSideArena.json', 'Action_DisneysHercules.json', 'Action_MauiMallardinColdShadow.json', 'Action_MilionArthurArcanaBlood.json', 'Action_SurvivorPassVikendi.json', 'Action_ONEPUNCHMANAHERONOBODYKNOWS.json', 'Action_GunboundM.json', 'Action_DragonBallFighterZJiren.json', 'Action_DragonBallFighterZGokuGt.json', 'Action_DragonBallFighterZVidel.json', 'Action_DragonBallFighterZGogeta.json', 'Action_DragonBallFIghterZBrolyDBS.json', 'Action_LostCityofVampires.json', 'Action_TheArkofHorizon.json', 'Action_review_996480.json', 'Action_MarvelsAvengers.json', 'Action_SamuraiShodownNeogeoCollection.json', 'Action_Zengeon.json', 'Action_JumpingMaster.json', 'Action_HellishQuart.json', 'Action_WrathAeonOfRuin.json', 'Action_Fireboy&WatergirlElements.json', 'Action_review_1003720.json', 'Action_EarthDefenseForce5.json', 'Action_AlienShooter2.json', 'Action_WillyJetmanAstromonkeysRevenge.json', 'Action_Overstep.json', 'Action_LostDaughter.json', 'Action_DeadbyDaylightAshvsEvilDead.json', 'Action_BloodFreshSupply.json', 'Action_HideandSeek.json', 'Action_TottalyReliableDeliveryService.json', 'Action_IntotheRadiusVR.json', 'Action_PeakyBlindersMastermind.json', 'Action_AronsAdventure.json', 'Action_WoundedTheBeginning.json', 'Action_THELASTPLAYERVR.json', 'Action_NERVE.json', 'Action_WestofDead.json', 'Action_AnniversaryCollectionArcadeCLassics.json', 'Action_ContraAnniversaryCollection.json', 'Action_CastlevaniaAnniversaryCollection.json', 'Action_BombingQuest.json', 'Action_KAMIKO.json', 'Action_SecondExtinction.json', 'Action_SectoresEdge.json', 'Action_review_1028860.json', 'Action_MafiaIIDefinitiveEdition.json', 'Action_MafiaDefinitiveEdition.json', 'Action_TouHouMakukaSai.json', 'Action_SticksAndBones.json', 'Action_WarhammerVermintide2WindsofMagic.json', 'Action_MinionMasterVoidborneOnslaught.json', 'Action_BlasterMasterZero.json', 'Action_BlasterMasterZero2.json', 'Action_UltimateZombieDefense.json', 'Action_ShadowWarrior3.json', 'Action_NeptuniaShooter.json', 'Action_PawPawPaw.json', 'Action_EarthDefenseForceIronRain.json', 'Action_ShatteredTaleoftheForgottenKing.json', 'Action_SurvivorPass3WildCard.json', 'Action_Peekaboo.json', 'Action_RiverCityGirls.json', 'Action_review_1049660.json', 'Action_BLOCKADE.json', 'Action_SCAR.json', 'Action_VCBWhyCity4k.json', 'Action_Dezzan.json', 'Action_MortalKombat11KombatPack1.json', 'Action_ResistanceElement.json', 'Action_MortalKombat11CangaceiroKano.json', 'Action_MuseDashJustasPlanned.json', 'Action_WolfensteinYoungBlood.json', 'Action_BorderOfficer.json', 'Action_BattleGroundsIII.json', 'Action_NeonBoost.json', 'Action_StarWArsBattlefront2004.json', 'Action_Myheroonesjustice2.json', 'Action_BeyondtheWire.json', 'Action_RitualCrownofHorns.json', 'Action_DeviousDungeon.json', 'Action_HuntersArena.json', 'Action_SuperMonkeyBallBanaBlitzHD.json', 'Action_ConanChopChop.json', 'Action_Embr.json', 'Action_PewDewRedemption.json', 'Action_EscapeuntilFriday.json', 'Action_review_1064221.json', 'Action_Halo2Anniversary.json', 'Action_Halo4.json', 'Action_Halo3.json', 'Action_Halo3ODST.json', 'Action_AzureStrikerGunvolt2.json', 'Action_NaritaBoy.json', 'Action_KurtzPelStarterPack.json', 'Action_Aster.json', 'Action_WorldofTanksBlitzFreePack.json', 'Action_WorldofTanksBlitz.json', 'Action_TeethBrushingSimulator.json', 'Action_BitetheBullet.json', 'Action_ValgraveImmortalPlains.json', 'Action_SamuraiShodownVSpecial.json', 'Action_SparktheElectricJester2.json', 'Action_HimnoTheSilentMelody.json', 'Action_PistolWhip.json', 'Action_TheWalkingDeadOnslaught.json', 'Action_GunvoltChronicles.json', 'Action_NTBSSMAsterCharacterTrainingPackZabuzaMomochi.json', 'Action_NTBSSMasterCharacterTrainingPackSasukeUchihaBoruto.json', 'Action_NTBSSMasterCharacterTrainingPackNarutoUzumaki.json', 'Action_Yakuza3Remastered.json', 'Action_MarvelsGuardiansOftheGalaxy.json', 'Action_OnePiecePirateWarriors4.json', 'Action_ProjectZeroDeaths.json', 'Action_NTBSSMAsterCharacterTrainingPack.json', 'Action_NTBSSMasterCharacterTrainingPackShisuiUchiha.json', 'Action_NTBSSTopSecret.json', 'Action_NTBSSTopSecretTrainingSet.json', 'Action_Destiny2ShadowkeepDigitalDeluxe.json', 'Action_Smelter.json', 'Action_RoyalCrown.json', 'Action_MortalKombat11KlassicArcadeNinjaSkinPack1.json', 'Action_SkellboyRefractured.json', 'Action_Gears5.json', 'Action_DOOMEternalTheAncientGods.json', 'Action_review_1100600.json', 'Action_Bombergrounds.json', 'Action_Yakuza4Remastered.json', 'Action_Yakuza5Remastered.json', 'Action_Fault.json', 'Action_TheMessengerPicnicPanicDLC.json', 'Action_WarThunderUsStarterPack.json', 'Action_Perspective.json', 'Action_PowerRAngersBattleForTheGrid.json', 'Action_UnturnedDedicatedServer.json', 'Action_AyotheClown.json', 'Action_UNDEFEATED.json', 'Action_SnowdropEscape.json', 'Action_1976BacktoMidway.json', 'Action_TrenchesWIP.json', 'Action_EasternExorcist.json', 'Action_bitDungeon.json', 'Action_SayonaraWildHearts.json', 'Action_StormArea51.json', 'Action_RetroMachina.json', 'Action_Deadswitch3.json', 'Action_PropAndSeek.json', 'Action_ITORAH.json', 'Action_DarkLight.json', 'Action_ALTF4.json', 'Action_Ghostrunner.json', 'Action_CosmicBreakUniversal.json', 'Action_RedWingsAcesoftheSky.json', 'Action_WWE2KBATTLEGROUNDS.json', 'Action_NARUTOSHIPPUDENUNS4ROADTOBORUTONEXTGENERATIONSPack.json', 'Action_Remothered.json', 'Action_FunwithRagdollsTheGame.json', 'Action_FLATLANDVol1.json', 'Action_HuntShowdownLegendsoftheBayou.json', 'Action_ReadyOrNot.json', 'Action_WaifuHell.json', 'Action_DRAGONBALLZKAKAROTTRUNKSTHEWARRIOROFHOPE.json', 'Action_DragonBallZKakarotSeasonPass.json', 'Action_SurvivorPassBadlands.json', 'Action_WarriorsOrochi4TheUltimateUpgradePack.json', 'Action_DOOM64.json', 'Action_TipoftheSpearTaskForceElite.json', 'Action_DragonMarkedForDeath.json', 'Action_ICARUS.json', 'Action_StreetFighterVChampionEditionUpgradeKit.json', 'Action_SamuraiJackBattleThroughTime.json', 'Action_Slaveblade.json', 'Action_DayZLivonia.json', 'Action_GalacticRangersVR.json', 'Action_DarknessMazeCubeHardcorePuzzleGame.json', 'Action_LogistiqueAct1.json', 'Action_GoingUnder.json', 'Action_WarplanesWW1SkyAces.json', 'Action_TheBindingofYOU.json', 'Action_Aragami2.json', 'Action_Galaxium.json', 'Action_review_1158790.json', 'Action_IdleBigDevil.json', 'Action_Ziggurat2.json', 'Action_KnockoutParty.json', 'Action_Tekken7DLC13frameDataDisplay.json', 'Action_AngreyVideoGameNerdI&IIDeluxe.json', 'Action_BrassBrigade.json', 'Action_MahouArms.json', 'Action_ThingsThatBounceandExplode.json', 'Action_HuntShowdownThePhantom.json', 'Action_DAEMONXMACHINA.json', 'Action_DangerScavenger.json', 'Action_XIIIClassic.json', 'Action_MortalOnline2.json', 'Action_Countersnipe.json', 'Action_StarWarsFallenOrder.json', 'Action_RedDeadRedemptionII.json', 'Action_DoomsdayHunters.json', 'Action_TheyCameFromaCommunistPlanet.json', 'Action_SpaceCrewLegendaryEdition.json', 'Action_Rocketron.json', 'Action_KillItWithFire.json', 'Action_StayOut.json', 'Action_IDEGO.json', 'Action_Scavengers.json', 'Action_Russiaphobia.json', 'Action_DyingLightChivalryWepaonPack.json', 'Action_PAYDAY2BorderCrossingHeist.json', 'Action_PhantomBreakerOmnia.json', 'Action_BleedingEdge.json', 'Action_WallachiaReignofDracula.json', 'Action_AnimeRedemption.json', 'Action_Zelter.json', 'Action_review_1201710.json', 'Action_ManStanding.json', 'Action_Fallout1st.json', 'Action_Naraka.json', 'Action_RecordOfLodoss.json', 'Action_TiamatsDrink.json', 'Action_review_1205040.json', 'Action_CyberHunter.json', 'Action_IslandSaver.json', 'Action_RakionChaosForce.json', 'Action_CartelTycoon.json', 'Action_BlueFire.json', 'Action_AWayOut.json', 'Action_StarWarsSquadrons.json', 'Action_Fe.json', 'Action_ShadowArena.json', 'Action_SeveredSteel.json', 'Action_Arma3CreatorDLCSOGPrairieFire.json', 'Action_TheConvenienceStore.json', 'Action_HuntShowdownFireFight.json', 'Action_ULTRAKILL.json', 'Action_Chaos.json', 'Action_Borderlands3GunsLoveandTentacles.json', 'Action_Borderlands3MoxxisHeistoftheHandsomeJackpot.json', 'Action_OneeChanbaraORIGIN.json', 'Action_Borderlands3BountyofBlood.json', 'Action_RocketArena.json', 'Action_YakuzaLikeADragon.json', 'Action_review_1236240.json', 'Action_BossRushMythology.json', 'Action_STARWARSBAttlefrontII.json', 'Action_StarWarsBattlefront.json', 'Action_DeadSpace3Awakened.json', 'Action_Battlefield4UltimateShortcutBundle.json', 'Action_review_1238880.json', 'Action_Retrowave.json', 'Action_POLYGON.json', 'Action_Stuffed.json', 'Action_RemnantFromtheAshesSwampsofCorsus.json', 'Action_WarDogsRedsReturn.json', 'Action_DeadsideSupporterPack.json', 'Action_DRAGONBALLFIGHTERZGoku.json', 'Action_DRAGONBALLFIGHTERZGogetaSS$.json', 'Action_BreakingGates.json', 'Action_AeternoBladeII.json', 'Action_FallenRegion.json', 'Action_review_1252330.json', 'Action_RisingHell.json', 'Action_RollerRiot.json', 'Action_PortalReloaded.json', 'Action_SentimentalK.json', 'Action_review_1257290.json', 'Action_BloodstainedCurseOfTheMoon2.json', 'Action_DeathStrandingDigitalArtBook.json', 'Action_SpellPunkVR.json', 'Action_Daysgone.json', 'Action_PuyoPuyoTetris2.json', 'Action_ChallengeSpeedball.json', 'Action_SmashingSpiritsBrazilsFirstBoxer.json', 'Action_review_1263850.json', 'Action_TheLastStandAftermath.json', 'Action_Trashed.json', 'Action_FlyPunchBoom.json', 'Action_Shrine.json', 'Action_LEWDAPOCALYPSE.json', 'Action_KingOfCrabs.json', 'Action_MortalKombat11AftermathExpansion.json', 'Action_CobraKaiTheKarateKidSagaContinues.json', 'Action_Crysis3.json', 'Action_FrogBath.json', 'Action_HalfLifeRestored.json', 'Action_Pronty.json', 'Action_Schwarzerblitz.json', 'Action_VampireTheMasqueradeNightRoad.json', 'Action_RUNRUNWITCHemily.json', 'Action_DragonBallZKakarotANewPowerAwakensSet.json', 'Action_DyingLightHellraid.json', 'Action_KnockoutCity.json', 'Action_review_1301350.json', 'Action_GeometricSniper.json', 'Action_DieAgainPrologue.json', 'Action_Voidigo.json', 'Action_DeathTales.json', 'Action_review_1306580.json', 'Action_LostRuins.json', 'Action_MayhemBrawler.json', 'Action_CallofCoronga.json', 'Action_SuperBombermanROnline.json', 'Action_HentaiRoguelike.json', 'Action_Greak.json', 'Action_SourceofMadness.json', 'Action_review_1318940.json', 'Action_Quest4PapaReloaded.json', 'Action_HSNIPERWorldWarII.json', 'Action_EasyRed2.json', 'Action_Arma3ArtofWarCharityPack.json', 'Action_MoonRaider.json', 'Action_FISTForgedInShadowTorch.json', 'Action_Wolfstride.json', 'Action_AlexKiddinMiracleWorldDX.json', 'Action_Alisa.json', 'Action_Nohra.json', 'Action_ANightInBerlin.json', 'Action_SniperGhostWarriorContracts2.json', 'Action_RIO.json', 'Action_SherwoodExtreme.json', 'Action_Afterinfection.json', 'Action_DYNASTYWARRIORSEmpires.json', 'Action_SamuraiSHODOWN.json', 'Action_GangV.json', 'Action_WarhammerVermintide2.json', 'Action_FallGuysCollectosPack.json', 'Action_FOOTSIESRollbackEdition.json', 'Action_GrappleDog.json', 'Action_FreedomFighters.json', 'Action_ServantsofHarvestWish.json', 'Action_SmashLegends.json', 'Action_HAAK.json', 'Action_DyingLightVolkanCombatArmorBundle.json', 'Action_SakunaOfRiceandRuin.json', 'Action_OvernOver.json', 'Action_ZeroHour.json', 'Action_TheInfected.json', 'Action_HalfLifeAlyx.json', 'Action_Ties.json', 'Action_KillitWithFireHEATWAVE.json', 'Action_BladeAssault.json', 'Action_review_1368430.json', 'Action_review_1368440.json', 'Action_review_1368450.json', 'Action_review_1368460.json', 'Action_NINJAGAIDENMasterCollectionNINJAGAIDEN3RazorsEdge.json', 'Action_IronConflict.json', 'Action_MeltyBlood.json', 'Action_BloodRayneTerminalCut.json', 'Action_Bloodrayne2TerminalCut.json', 'Action_SwordRogue.json', 'Action_GhostsnGoblinsResurrection.json', 'Action_Survivio.json', 'Action_NightOfTheDead.json', 'Action_review_1378490.json', 'Action_TribalHunter.json', 'Action_GuiltyGear.json', 'Action_NinjaHanrei.json', 'Action_DriftersLoottheGalaxy.json', 'Action_Yakuza6TheSongofLife.json', 'Action_Deathroids.json', 'Action_IslesofLimbo.json', 'Action_HighEntropyChallenges.json', 'Action_Amalgam.json', 'Action_WarframeInitiatePack.json', 'Action_WarIdentity.json', 'Action_OceansHeart.json', 'Action_ContrabandPolice.json', 'Action_Bossofthisgyn.json', 'Action_Spellbreak.json', 'Action_LustFromBeyondScarlet.json', 'Action_RedDeadOnline.json', 'Action_WorldOfTanks.json', 'Action_NieRReplicant4YoRHa.json', 'Action_Krunker.json', 'Action_TheLastKingsArcher.json', 'Action_Sophstar.json', 'Action_CrystalCall.json', 'Action_BEACHED.json', 'Action_ShadowManRemastered.json', 'Action_NickelodenAllStarBrawl.json', 'Action_ShrineII.json', 'Action_Gemini.json', 'Action_DreadHunger.json', 'Action_NoMoreHeroes2.json', 'Action_NoMoreHeroes.json', 'Action_CosmoDreamer.json', 'Action_review_1425880.json', 'Action_LOSTEPIC.json', 'Action_Vicewave1984.json', 'Action_FallGuys.json', 'Action_RoboSquare.json', 'Action_PrisonSimulatorPrologue.json', 'Action_DevilMayCry5PlayableCharacterVergil.json', 'Action_Aurora.json', 'Action_Raidfield2.json', 'Action_RTypeFInal2.json', 'Action_EternalDungeon.json', 'Action_ApexLegendsChampionEdition.json', 'Action_GhostbusterTheVideoGameRemastered.json', 'Action_AtlasRogues.json', 'Action_MortalKombat11KombatPack2.json', 'Action_HauntChaser.json', 'Action_XenoShooter.json', 'Action_ArcApellago.json', 'Action_DyingLightL$d2BillandGnomeChompskiPack.json', 'Action_review_1456350.json', 'Action_ResidentEvilVillageTraumaPack.json', 'Action_Marfusha.json', 'Action_KukoosLostPets.json', 'Action_Plokoth.json', 'Action_ThunderTierOne.json', 'Action_streetFighterVSeason5PremiumPass.json', 'Action_TheDawn.json', 'Action_FightsinTightSpaces.json', 'Action_NANOCELLSMissionBackHome.json', 'Action_JustActNatural.json', 'Action_ANVIL.json', 'Action_SovietHentai.json', 'Action_EarthDefenseForceWorldBrothers.json', 'Action_TheKingOfFIghtersXV.json', 'Action_Figment2CreedValley.json', 'Action_MinitFunRacer.json', 'Action_DragonBallXenoverse2LegendaryPack1.json', 'Action_ObjectN.json', 'Action_ColdHeart.json', 'Action_SwallowTheBlueRemastered.json', 'Action_ChickenInvadersUniverse.json', 'Action_SwallowtheSea.json', 'Action_ShapeNeonChaos.json', 'Action_WelcomeBack.json', 'Action_CapcomArcadeStadium.json', 'Action_PeacefulGunner.json', 'Action_FoglightOnline.json', 'Action_AeternaNoctis.json', 'Action_review_1520470.json', 'Action_PerfectHeist2.json', 'Action_KillingFloor2ArmorySeasonPass.json', 'Action_GladioandGlory.json', 'Action_RedLaserZ.json', 'Action_GorillaTag.json', 'Action_Bird.json', 'Action_OnePixel.json', 'Action_MadPack.json', 'Action_AliensFireteamElite.json', 'Action_Warbox.json', 'Action_CastlevaniaAdvanceCollection.json', 'Action_PaintChips.json', 'Action_IngloriousWaifuVSNaziZombies.json', 'Action_PredatorHuntingGrounds.json', 'Action_ROUNDS.json', 'Action_SkulgirlsAnnie.json', 'Action_Utopos.json', 'Action_Badlanders.json', 'Action_Dysterra.json', 'Action_TouhouKouryudou.json', 'Action_ToHellWithIt.json', 'Action_review_1569040.json', 'Action_VividKnight.json', 'Action_DreadXCollectionTheHunt.json', 'Action_LabRags.json', 'Action_LustfromBeyond.json', 'Action_Spookware.json', 'Action_SNKVSCAPCOMTHEMATCHOFTHEMILLENNIUM.json', 'Action_Suspects.json', 'Action_MasthoisTogether.json', 'Action_WorldofTanksBlitzSpacePack.json', 'Action_review_1579150.json', 'Action_NinjaGaidenMasterCollection.json', 'Action_NinjaGaidenmasterCollection(1).json', 'Action_NARAKABLAdepoint.json', 'Action_StreetsOfRage4MrXNightmare.json', 'Action_EngineEvolution2021.json', 'Action_BroFalls.json', 'Action_Clownfield2042.json', 'Action_SamuraiWArriors5.json', 'Action_Metamorphos.json', 'Action_AnarchyWolfslawPrologue.json', 'Action_CrazyGravity.json', 'Action_DyingLightRustWeaponPack.json', 'Action_TheCycleFrontier.json', 'Action_VampireTheMasqueradeBloodhunt.json', 'Action_3DAimTrainer.json', 'Action_WillWalker.json', 'Action_VirtuousWestern.json', 'Action_BattleBitRemastered.json', 'Action_Baldo.json', 'Action_TheLastStandLegacyCollection.json', 'Action_DininhoSpaceAdventure.json', 'Action_Anatidae.json', 'Action_SUPERPEOPLE.json', 'Action_DeadPoly.json', 'Action_BlackOneBloodBrothers.json', 'Action_KateCollateralDamage.json', 'Action_Muck.json', 'Action_StreetStriker.json', 'Action_RiftAdventure.json', 'Action_review_1634500.json', 'Action_BloodSpear.json', 'Action_review_1638720.json', 'Action_MirloAbovetheSUn.json', 'Action_BerserkMode.json', 'Action_Destiny2TheWitchQueen.json', 'Action_Replacer.json', 'Action_SamuraiShampoo.json', 'Action_review_1671200.json', 'Action_Grandchase.json', 'Action_PowerSlaveExhumed.json', 'Action_Toroom.json', 'Action_XForceGenesis.json', 'Action_Kursor.json', 'Action_DRAMA.json', 'Action_review_1707550.json', 'Action_HaloInfiniteCampaign.json', 'Action_BrawlhallaAutumnChampionship2021Pack.json', 'Action_CrysisRemastered.json', 'Action_RuinsofAlbion.json', 'Action_PoppyPlaytime.json', 'Action_NoStraightRoadsEncoreEdition.json', 'Action_RhythmBrawl.json', 'Action_review_1732380.json', 'Action_GunvoltChroniclesluminousLuminousAvengeriX2.json', 'Action_Propnight.json', 'Action_DragonBallFighterZAndroid21.json', 'Action_HuntShowdownColdBlooded.json', 'Action_DeadbyDaylightHouroftheWitchChapter.json', 'Action_KillerWorm2.json', 'Action_DeludedI.json', 'Action_DeadlyInfestation.json', 'Action_review_1793660.json', 'Action_DeadbyDaylightPortraitofaMurderChapter.json', 'Action_SnakeForce.json', 'Action_GrandCrossRenovation.json', 'Action_Paunch2.json', 'Action_BrawlhallaWinterChampionship2022Pack.json', 'Action_CampWars.json', 'Action_DodgeIt2.json', 'Action_CaveCrawler.json', 'Action_ShadowBurglar.json', 'Action_FPSGameDevTest.json', 'Action_SeraphsLastStand.json', 'Action_BioshockInfiniteColumbiasFinest.json', 'Action_json_part50.json', 'Action_StreetFighterVSeason2CharacterPass.json', 'Action_LegendsoftheUniverse.json', 'Action_MadCombatMarines.json', 'Action_RadicalSpectrumVolume1.json', 'Action_FruitNinjaVR.json', 'Action_GodsTrigger.json', 'Action_MADNESSProjectNexus.json', 'Action_ChickenAssassin.json', 'Action_review_489890.json', 'Action_Battalion1944.json', 'Action_SWARMRIDERS.json', 'Action_DeadbyDaylight.json', 'Action_tropico6.json', 'Action_GTFO.json', 'Action_DeepSpaceDash.json', 'Action_RivaisEmBatalha.json', 'Action_MarvelvsCapcomInfinite.json', 'Action_DCUNIVERSEONLINE2016.json', 'Action_EliosisHunt.json', 'Action_UBOAT.json', 'Action_TooAngrytoSpace.json', 'Action_NarutoUltimateNinjaStorm.json', 'Action_NarutoStorm4RoadToBoruto.json', 'Action_Shiny.json', 'Action_NoobSquad.json', 'Action_Hammerfight.json', 'Action_review_41210.json', 'Action_Altitude.json', 'Action_IonAssault.json', 'Action_LeadandGold.json', 'Action_review_42160.json', 'Action_review_42640.json', 'Action_Singularity.json', 'Action_FrontMissionEvolved.json', 'Action_TheHauntedHellsReach.json', 'Action_review_43160.json', 'Action_review_44320.json', 'Action_OperationFlashpoint.json', 'Action_DarkVoid.json', 'Action_DevilMayCry4.json', 'Action_DarkVoidZero.json', 'Action_LostPlanetExtremeConditionColoniesEdition.json', 'Action_LostPlanet2.json', 'Action_DeadRising2.json', 'Action_DeadRIsing2OffTheRecord.json', 'Action_UltraStreetFighterIV.json', 'Action_Avencast.json', 'Action_WastelandAngel.json', 'Action_TrappedDead.json', 'Action_review_48160.json', 'Action_review_48180.json', 'Action_AssassinsCreedBrotherhood.json', 'Action_Borderlands2.json', 'Action_PlainSight.json', 'Action_BorderlandsTheScretArmoryofGeneralKnoxx.json', 'Action_MafiaII.json', 'Action_SpecOpsTheLine.json', 'Action_review_50650.json', 'Action_review_51100.json', 'Action_Homefront.json', 'Action_RedFactionArmageddon.json', 'Action_Warhammer40000.json', 'Action_SaintsRowTheThird.json', 'Action_BatmanArkhamCityOriginal.json', 'Action_TheFirstTemplarSteamSpecialEdition.json', 'Action_Luxor5thPassage.json', 'Action_FlightControlHD.json', 'Action_MondayNightCombat.json', 'Action_SniperEliteV2(1).json', 'Action_PainkillerRedemption.json', 'Action_Arma2BritishArmedForces.json', 'Action_ARMAGoldEdition.json', 'Action_ARMA.json', 'Action_TheBureau.json', 'Action_TheDarknessII.json', 'Action_DInoD_Day.json', 'Action_ChanteliseATaleofTwoSisters.json', 'Action_CrazyTaxi.json', 'Action_SpaceChannel5.json', 'Action_review_71270.json', 'Action_review_72771.json', 'Action_IronFrontDigitalWarEdition.json', 'Action_review_91310.json', 'Action_Hydrophobia.json', 'Action_ARES.json', 'Action_ShadowHarvestPhantomOps.json', 'Action_Nidhogg.json', 'Action_Capsized.json', 'Action_ibb&obb.json', 'Action_AirConflictsSecretWars.json', 'Action_review_96300.json', 'Action_Nexuiz.json', 'Action_HardResetExileDLC.json', 'Action_RenegadeOps.json', 'Action_review_99810.json', 'Action_review_102700.json', 'Action_review_102820.json', 'Action_Shank2.json', 'Action_Portal2TheFinalHours.json', 'Action_review_104700.json', 'Action_review_105400.json', 'Action_MsSplosionMan.json', 'Action_review_105430.json', 'Action_review_106000.json', 'Action_SpacePiratesandZombies.json', 'Action_ArmaIII.json', 'Action_review_107900.json', 'Action_DeathRally.json', 'Action_AlanWakeCollectorsEditionExtras.json', 'Action_review_109400.json', 'Action_review_109410.json', 'Action_APBReloaded.json', 'Action_IronBrigade.json', 'Action_Prototype2.json', 'Action_Prototype2RadnetAccessPack.json', 'Action_GlobalOpsCommandoLibya.json', 'Action_BatmanArkhamCity.json', 'Action_BatmanArkhamCityGOTYEDITION.json', 'Action_SonicGenerationsCasinoNightDLC.json', 'Action_MaxPayne(1).json', 'Action_review_201700.json', 'Action_Wolfenstein.json', 'Action_AssassinsCreedRevelations.json', 'Action_ChoplifterHD.json', 'Action_review_202090.json', 'Action_SleepingDogs.json', 'Action_SonicGenerationsCollection.json', 'Action_MAxPayne.json', 'Action_DynamiteJack.json', 'Action_HitmanAbsolution.json', 'Action_AmericasArmy.json', 'Action_review_203730.json', 'Action_BinaryDomain.json', 'Action_Satazius.json', 'Action_review_204080.json', 'Action_MaxPayne3.json', 'Action_SeriousSam2.json', 'Action_CallOfJuarez.json', 'Action_InfestedPlanet.json', 'Action_RetroCityRampage.json', 'Action_DeepBlackReloaded.json', 'Action_Dishonored.json', 'Action_HellYeahWrathOfTheDeadRabbit.json', 'Action_review_205350.json', 'Action_ForeignLegionMultiMassacre.json', 'Action_review_205890.json', 'Action_JetSetRadio.json', 'Action_review_205930.json', 'Action_SaintsRowIV.json', 'Action_AirMechStrike.json', 'Action_CastleCrashers.json', 'Action_review_207210.json', 'Action_Fireburst.json', 'Action_ArcheBlade.json', 'Action_YsTheOathinFelghana.json', 'Action_review_207270.json', 'Action_PAYDAYTheHeistWolfpackDLC.json', 'Action_PAYDAYTheHeistSoundtrack.json', 'Action_review_207890.json', 'Action_SacredCitadel.json', 'Action_review_208030.json', 'Action_DOOM3BFG.json', 'Action_DishonoredTheNifeofDunwall.json', 'Action_DishonoredDunwallCityTrials.json', 'Action_StarWarsKnightsOfTheOldRepublicII.json', 'Action_BatmanArkhamKnight.json', 'Action_Apotheon.json', 'Action_BatmanArkhamOrigins.json', 'Action_StreetFighterxTekken.json', 'Action_AValleyWithoutWind.json', 'Action_Blacklight.json', 'Action_SniperElitev2.json', 'Action_KillingFloorThechickenatorPack.json', 'Action_VikingBattleforAsgard.json', 'Action_Deadlight.json', 'Action_ThiefGold.json', 'Action_ThiefIITheMetalAge.json', 'Action_ConflictDesertStorm.json', 'Action_KungFuStrike.json', 'Action_StarConflict.json', 'Action_review_212370.json', 'Action_Inversion.json', 'Action_review_212580.json', 'Action_TomClancysghostReconFutureSoldier.json', 'Action_SuperCrateBox.json', 'Action_review_212910.json', 'Action_Borderlands2MechromancerPack.json', 'Action_Borderlands2MrtorguesCampaignofCarnage.json', 'Action_MDK2HD.json', 'Action_Borderlands2CollectorsEditionPack.json', 'Action_IamAlive.json', 'Action_review_214230.json', 'Action_GearUp.json', 'Action_ETHERVAPORRemaster.json', 'Action_FairyBloomFreesia.json', 'Action_GuacameleeGoldEdition.json', 'Action_review_214850.json', 'Action_BioShockInfiniteClashintheClouds.json', 'Action_AirConflictsPacificCarriers.json', 'Action_BioShockInfiniteBurialatSea(1).json', 'Action_BioshockInfiniteBurialatSea.json', 'Action_BioShockInfiniteSeasonPass.json', 'Action_review_215100.json', 'Action_ZombiePlayground.json', 'Action_ZenoClash2.json', 'Action_DungeonParty.json', 'Action_Closers.json', 'Action_review_216150.json', 'Action_TinyTroopers.json', 'Action_review_216250.json', 'Action_review_216890.json', 'Action_review_217370.json', 'Action_SONICADVENTURE2BATTLE.json', 'Action_review_217860.json', 'Action_AlienRageUnlimited.json', 'Action_review_218170.json', 'Action_review_218130.json', 'Action_PlanetSide2.json', 'Action_review_218330.json', 'Action_review_218450.json', 'Action_review_218470.json', 'Action_PAYDAY2.json', 'Action_Lucius.json', 'Action_DroidAssault.json', 'Action_review_219600.json', 'Action_Chivalry.json', 'Action_review_219870.json', 'Action_FarCry3.json', 'Action_DmcDevilMayCry.json', 'Action_review_221080.json', 'Action_DayZ.json', 'Action_review_221340.json', 'Action_TheKingOfFighters98.json', 'Action_TheKingOfFighters2002.json', 'Action_review_222900.json', 'Action_Insurgency.json', 'Action_TKOFXIII.json', 'Action_GianaSisters.json', 'Action_ArizonaSunshine.json', 'Action_MechWarriorOnline.json', 'Action_ZombieKillofTheWeekReborn.json', 'Action_EuropeatWar.json', 'Action_Gunscape.json', 'Action_HIS.json', 'Action_review_223390.json', 'Action_review_223650.json', 'Action_review_223670.json', 'Action_DMCDevilMayCryWeaponBundle.json', 'Action_DmCDevilMayCryCostumePack.json', 'Action_DmCDevilMayCryVergilsDownfall.json', 'Action_YsI&IIChronicles.json', 'Action_LocoCycle.json', 'Action_review_224060.json', 'Action_NoMoreRoominHell.json', 'Action_LegacyofKain.json', 'Action_review_224420.json', 'Action_ArmaIIDayz.json', 'Action_SuperHouseofDeadNinjas.json', 'Action_review_225140.json', 'Action_review_225180.json', 'Action_JustCause3.json', 'Action_BladeSymphony.json', 'Action_SvenCoop.json', 'Action_review_226320.json', 'Action_FarCry3deluxeBundleDLC.json', 'Action_InfestationSurvivorStories2020.json', 'Action_LostPlanet3.json', 'Action_GalacticCivilizationsIII.json', 'Action_review_226980.json', 'Action_SniperEliteNaziZombieArmy.json', 'Action_review_227240.json', 'Action_review_227280.json', 'Action_GodMode.json', 'Action_ScourgeOutbreak.json', 'Action_review_227680.json', 'Action_SeriousSamClassicsRevolution.json', 'Action_Retrovirus.json', 'Action_Heroes&Generals.json', 'Action_CompanyOfHeroes.json', 'Action_AceCombatAssaultHorizon.json', 'Action_TeenageMutantNinjaTurtlesOutoftheShadows.json', 'Action_review_228880.json', 'Action_review_228940.json', 'Action_DmCDevilMayCryBloodyPalaceMode.json', 'Action_ShootManiaStorm.json', 'Action_LaMulana.json', 'Action_review_231670.json', 'Action_review_231990.json', 'Action_residentEvil6SurvivorsMode.json', 'Action_SniperGhostWarrior2WorldHunterPack.json', 'Action_ThunderWolves.json', 'Action_ShadowWarrior.json', 'Action_FinalExam.json', 'Action_review_233250.json', 'Action_AirConflictsVietnam.json', 'Action_FarCry3BloodDragon.json', 'Action_TombRaiderTheFinalHoursDigitalBook.json', 'Action_review_233630.json', 'Action_review_234000.json', 'Action_CastlevaniaLordsOfShadow.json', 'Action_MadMax.json', 'Action_review_234310.json', 'Action_review_234530.json', 'Action_NarutoShippudenUNS3FullBurst.json', 'Action_BadBots.json', 'Action_MetalGearRising.json', 'Action_WarhammerEndtimes.json', 'Action_TomClancySplinterCellBlacklist.json', 'Action_MINERVA.json', 'Action_InsterstellarMarines.json', 'Action_WarThunder.json', 'Action_PacManchampionshipEdition.json', 'Action_review_236530.json', 'Action_HITMAN.json', 'Action_elsword.json', 'Action_review_237590.json', 'Action_BatmanArkhamOriginsInitiation.json', 'Action_SniperElite3.json', 'Action_review_238170.json', 'Action_SaintsRowIVCommanderInChiefPack.json', 'Action_LegendofDungeon.json', 'Action_SaintsRowIVTheExecutivePrivilegePack.json', 'Action_SaintsRowIVTheRectifier.json', 'Action_FistPuncher.json', 'Action_review_238590.json', 'Action_review_239220.json', 'Action_Castlevania2LordsOfShadow2.json', 'Action_review_239450.json', 'Action_review_239570.json', 'Action_review_240380.json', 'Action_review_240460.json', 'Action_RainBloodChroniclesMirage.json', 'Action_GettingOverIt.json', 'Action_review_240970.json', 'Action_ChivalryDeadliestWarrior.json', 'Action_review_241640.json', 'Action_VectorThrust.json', 'Action_TheChaosEngine.json', 'Action_Styx.json', 'Action_NuclearThrone.json', 'Action_GunZ2TheSecondDuel.json', 'Action_InjusticeGodsAmongUs.json', 'Action_Verdun.json', 'Action_Daikatana.json', 'Action_BloodOmen2LegacyofKain.json', 'Action_Pandemonium.json', 'Action_UrbanChaos.json', 'Action_review_243320.json', 'Action_GasGuzzlersExtreme.json', 'Action_review_243870.json', 'Action_Invisible.json', 'Action_review_244390.json', 'Action_MenOfWar.json', 'Action_FoulPlay.json', 'Action_VelocityUltra.json', 'Action_DeathtrapDungeon.json', 'Action_review_245130.json', 'Action_Skullgirls2ndEncore.json', 'Action_Flashback.json', 'Action_Borderlands2Headhunter2WattleGobbler.json', 'Action_Borderlands2Headhunter5.json', 'Action_review_246280.json', 'Action_review_246400.json', 'Action_TheTypingoftheDead.json', 'Action_CookServeDelicious.json', 'Action_VolgarrtheViking.json', 'Action_SaintsRowIVBradyGamesPack.json', 'Action_SaintsRowIVPresidentialPack.json', 'Action_SaintsRowIVDubstepGunPack.json', 'Action_SaintsRowIVGATVPack.json', 'Action_SaintsRowIVEnterTheDominatrix.json', 'Action_SaintsRowIVElementofDestructionPAck.json', 'Action_SaintsRowIVPiratesBootyPack.json', 'Action_SaintsRowIVTheSuperSaintsPack.json', 'Action_SaintsRowIVHowtheSaintsSaveChristmas.json', 'Action_SaintsRowIVBlingBlingPack.json', 'Action_Hitmancontracts.json', 'Action_review_247580.json', 'Action_review_247830.json', 'Action_SniperEliteNaziZombieArmy2.json', 'Action_FreedomPlanet.json', 'Action_AWalkintheDark.json', 'Action_Vector.json', 'Action_review_249380.json', 'Action_MarlowBriggsAndTheMaskOfDeath.json', 'Action_FORCED.json', 'Action_AssaultAndroidCactusplus.json', 'Action_MetalSlug3.json', 'Action_HowToSurvive.json', 'Action_BunnyMustDieChelseaandthe7Devils.json', 'Action_review_250680.json', 'Action_review_250870.json', 'Action_review_251040.json', 'Action_DarkMatter.json', 'Action_TowerfallAscension.json', 'Action_review_251610.json', 'Action_7daystodie.json', 'Action_review_251670.json', 'Action_review_251970.json', 'Action_WWIIOnline.json', 'Action_Oniken.json', 'Action_YaibaNinjaGaidenZ.json', 'Action_DoubleDragonNeon.json', 'Action_DustyRevengeCoOpEdition.json', 'Action_DeathRoadtoCanada.json', 'Action_review_253470.json', 'Action_FortressForever.json', 'Action_Sparkle2Evo.json', 'Action_Ikaruga.json', 'Action_FortressCraftEvolved.json', 'Action_AquanoxDeepDescent.json', 'Action_SaintsRowIVThankYouPack.json', 'Action_AbyssOdyssey.json', 'Action_kickBeatSteamEdition.json', 'Action_review_255480.json', 'Action_PixelJunkShooter.json', 'Action_Enemyfront.json', 'Action_review_256350.json', 'Action_review_256410.json', 'Action_review_256500.json', 'Action_ProjectNimbusCompleteEdition.json', 'Action_review_257080.json', 'Action_SeriousSAm4.json', 'Action_BlastEm.json', 'Action_BloodyTrapland.json', 'Action_review_257890.json', 'Action_Oozi.json', 'Action_review_258160.json', 'Action_DragonNestEurope.json', 'Action_Gauntlet.json', 'Action_StateofDecayLifeline.json', 'Action_JustCause2MultiplayerMod.json', 'Action_HeliHeroes.json', 'Action_ChickenShootGold.json', 'Action_PAYDAY2GageSniperPack.json', 'Action_PAYDAY2GageModeCourier.json', 'Action_EdenStar.json', 'Action_AssassinsCreedLiberationHD.json', 'Action_BloodoftheWerewolf.json', 'Action_ColdWar.json', 'Action_KillerisDead.json', 'Action_LethalLeague.json', 'Action_BorderlandsThePreSequel.json', 'Action_HalfLifeBefore.json', 'Action_Zombeer.json', 'Action_VanguardPrincess.json', 'Action_JetsnGunsGold.json', 'Action_WorldOfGuns.json', 'Action_Crimsonland.json', 'Action_BlacBlueCalamityTrigger.json', 'Action_review_263260.json', 'Action_review_263440.json', 'Action_MistsurugiKamuiHikae.json', 'Action_Brawlout.json', 'Action_TurboDismount.json', 'Action_WyvandKeep.json', 'Action_OneFingerDeathPunch.json', 'Action_MajorMayhem.json', 'Action_PAYDAY2ArmoredTransport.json', 'Action_DeadRising3.json', 'Action_FistfulOfFrags.json', 'Action_review_265650.json', 'Action_SecretPonchos.json', 'Action_CannonsLasersRockets.json', 'Action_LostSagaNA.json', 'Action_SainsRowIVGamestopWarpedWeaponCHallenge.json', 'Action_review_266940.json', 'Action_MURI.json', 'Action_PAYDAY2AMerryPaydayChristmasSoundtrack.json', 'Action_PAYDAY2GageWeaponPack.json', 'Action_BatmanArkhamOriginsBlackGate.json', 'Action_review_267550.json', 'Action_GuiltyGearIsuka.json', 'Action_Glacier3TheMeltdown.json', 'Action_GunMetal.json', 'Action_HyperFighters.json', 'Action_Meltdown.json', 'Action_SatelliteReign.json', 'Action_TheDishwasher.json', 'Action_HeroSiege.json', 'Action_AcesWildManicBrawlingAction.json', 'Action_review_269390.json', 'Action_review_269910.json', 'Action_TimeRifters.json', 'Action_RunningWithRifles.json', 'Action_WormsWorldPartyRemastered.json', 'Action_SniperArtofVictory.json', 'Action_GrandTheftAutoV.json', 'Action_HumanityAsset.json', 'Action_review_272350.json', 'Action_NarutoShippudenUNSRevolution.json', 'Action_SeriousSamsBogusdetour.json', 'Action_CounterStrikeNexon.json', 'Action_CastlevaniaLordsofShadow2.json', 'Action_EvolveStage2.json', 'Action_Over9000Zombies.json', 'Action_Descent.json', 'Action_RamboTheVideoGameBakerTeamDLC.json', 'Action_BrigadorUpArmoredEdition.json', 'Action_Depth.json', 'Action_Guacamelee.json', 'Action_PAYDAY2GageWeaponPack02.json', 'Action_Arma3Zeus.json', 'Action_HaloSpartanAssault.json', 'Action_AssassinsCreedFreedomCry.json', 'Action_BatmanArkhamOriginsColColdHeart.json', 'Action_ShantaeRiskysRevengeDIrectorsCut.json', 'Action_review_277950.json', 'Action_RIVEWreckHackDie.json', 'Action_DynastyWarriors8.json', 'Action_review_278210.json', 'Action_DiggerOnline.json', 'Action_UltionusATaleofPettyRevenge.json', 'Action_Gunjitsu.json', 'Action_Aragami.json', 'Action_ApertureTag.json', 'Action_VanguardPrincessDirectorsCut.json', 'Action_BloodRAyneBetrayal.json', 'Action_Mashed.json', 'Action_UbersoldierII.json', 'Action_Woolfe.json', 'Action_Splatter.json', 'Action_review_282201.json', 'Action_review_282350.json', 'Action_AlienIsolationSafeHaven.json', 'Action_AlienIsolationTrauma.json', 'Action_AlienIsolationCorporateLockdown.json', 'Action_AlienIsolationLostcontact.json', 'Action_EurofighterTyphoon.json', 'Action_DesertThunder.json', 'Action_MarineSharpshooterIIJungleWarfare.json', 'Action_IncomingFOrces.json', 'Action_CTSpecialFOrcesFireforEffect.json', 'Action_AstebreedDefinitieEdition.json', 'Action_DiadraEmpty.json', 'Action_review_284390.json', 'Action_SpeedKills.json', 'Action_Solarix.json', 'Action_review_285050.json', 'Action_ACEArena.json', 'Action_EnemyMind.json', 'Action_review_286500.json', 'Action_Metro2033.json', 'Action_HardTruckApocalypseRiseOfClansExMachinaMeridian113.json', 'Action_ShadowOpsredMercury.json', 'Action_ChaosDomain.json', 'Action_Ionball2Ionstorm.json', 'Action_MetroLastLightRedux.json', 'Action_review_287680.json', 'Action_MetalGearSolidV.json', 'Action_8BitCommando.json', 'Action_StrikeSuitZero.json', 'Action_ElMatador.json', 'Action_Collapse.json', 'Action_AkanetheKunoichi.json', 'Action_review_291210.json', 'Action_review_291290.json', 'Action_Warface.json', 'Action_RealmsoftheHaunting.json', 'Action_PanzerEliteActionGoldEdition.json', 'Action_GunsAndRobots.json', 'Action_review_293560.json', 'Action_KnightSquad.json', 'Action_WarsandWarriors.json', 'Action_BlazBlueContinuum.json', 'Action_review_295270.json', 'Action_SweezyGunner.json', 'Action_IronStorm.json', 'Action_BallisticOverkill.json', 'Action_ZombiesonaPlane.json', 'Action_FarCry4.json', 'Action_WarTrigger3.json', 'Action_OrbitalGear.json', 'Action_BrawlhallaCollectorsPack.json', 'Action_BloodIITheChosenExpansion.json', 'Action_BlockNLoad.json', 'Action_RogueStormers.json', 'Action_review_299700.json', 'Action_Miscreated.json', 'Action_review_299860.json', 'Action_Epsilon.json', 'Action_review_300970.json', 'Action_review_301480.json', 'Action_Robocraft.json', 'Action_Battlezone98Redux.json', 'Action_ZombieArmyTrilogy.json', 'Action_UltraStreetFighterIVDigitalUpgrade.json', 'Action_CityofBrass.json', 'Action_SaintsRowGatoutofHell.json', 'Action_TheBlueFlamingo.json', 'Action_RyseSonOfRome.json', 'Action_OfGuardsAndThieves.json', 'Action_BosonX.json', 'Action_CalltoArms.json', 'Action_Blockade3d.json', 'Action_TheHouseinFataMorgana.json', 'Action_DeadBits.json', 'Action_KillAllZombies.json', 'Action_KickAss2.json', 'Action_ForHonor.json', 'Action_Arma3Helicopters.json', 'Action_AgentsofMayhem.json', 'Action_SkyGamblersStormRaiders.json', 'Action_BlueEstateTheGame.json', 'Action_HeavyFIreAfghanistan.json', 'Action_Slipstream5000.json', 'Action_Unturned.json', 'Action_PAYDAY2TheBigBankHeist.json', 'Action_IronFisticle.json', 'Action_Nux.json', 'Action_Platypus.json', 'Action_SleepingDogsDefinitiveEdition.json', 'Action_MortalKombatX.json', 'Action_SavageLands.json', 'Action_Geneshift.json', 'Action_GeometryWars3DimensionsEvolved.json', 'Action_OnikiraDemonKIller.json', 'Action_StreetFighterV.json', 'Action_ZeroEscapeZeroTimeDIlemma.json', 'Action_MetalGearSolidVGroundHeroes.json', 'Action_VerticalDropHeroesHD.json', 'Action_DeadOrAlive5.json', 'Action_SuperTrenchAttack.json', 'Action_WildWarfare.json', 'Action_Chasm.json', 'Action_review_312410.json', 'Action_RainWorld.json', 'Action_MetalSlugX.json', 'Action_PowerUP.json', 'Action_SniperElite4.json', 'Action_PixelHunter.json', 'Action_AlphaZylon.json', 'Action_WilsonChronicles.json', 'Action_BooBunnyPlague.json', 'Action_GuiltyGearX2.json', 'Action_DoubleDragonTrilogy.json', 'Action_Deathsmiles.json', 'Action_BombingBastards.json', 'Action_MARS.json', 'Action_StarSaviors.json', 'Action_Mightyn9.json', 'Action_SpaceHack.json', 'Action_ARESExtinctionAgendaEX.json', 'Action_Polarity.json', 'Action_review_315440.json', 'Action_RaidenIIIDigitalEdition.json', 'Action_review_315640.json', 'Action_review_315880.json', 'Action_Stonerid.json', 'Action_DisneyUniverse.json', 'Action_review_316390.json', 'Action_KingsofKungFu.json', 'Action_Airscrape.json', 'Action_DoubleAction.json', 'Action_review_317460.json', 'Action_review_317463.json', 'Action_review_317465.json', 'Action_review_317780.json', 'Action_EnforcerPoliceCrimeAction.json', 'Action_MiddleEarthShadowOfMordorLordoftheHunt.json', 'Action_MiddleearthSHadowofMordorTheBrightLord.json', 'Action_TheFlameInTheFlood.json', 'Action_DisneyGForce.json', 'Action_PlatypusII.json', 'Action_AXEL.json', 'Action_PAYDAY2GageAssaultPack.json', 'Action_WeHappyFew.json', 'Action_review_320590.json', 'Action_review_321040.json', 'Action_Wickland.json', 'Action_UNLOVED.json', 'Action_PrimalCarnage.json', 'Action_review_322010.json', 'Action_GunsGore&Cannoli.json', 'Action_GuruminAMonstruousAdventure.json', 'Action_review_322330.json', 'Action_SUPERHOT.json', 'Action_DYNASTYWARRIORS8Empires.json', 'Action_WorldsAdrift.json', 'Action_theHunterPrimal.json', 'Action_HalfLife2Soundtrack.json', 'Action_RaidenIVOVerKill.json', 'Action_DragonBallXenoverse.json', 'Action_AlienIsolation.json', 'Action_FarCry4ValleyoftheYetis.json', 'Action_HaloSpartanStrike.json', 'Action_GeminiHeroesReborn.json', 'Action_SlenderTheArrivalSoundtrack.json', 'Action_ShadowWarrior2.json', 'Action_review_325080.json', 'Action_review_325600.json', 'Action_VikingSquad.json', 'Action_review_326621.json', 'Action_DeepEclipse.json', 'Action_SlaveZero.json', 'Action_review_329030.json', 'Action_DMC4SE.json', 'Action_PhantomBreaker.json', 'Action_review_330710.json', 'Action_review_330760.json', 'Action_OnePiecePirateWarriors3.json', 'Action_CarmageddonTDR2000.json', 'Action_PAYDAY2GageHistoricalPack.json', 'Action_GRAV.json', 'Action_PhoenixForce.json', 'Action_PhantomBreakerBattleGrounds.json', 'Action_ForwardtotheSky.json', 'Action_review_333740.json', 'Action_DirtyBomb.json', 'Action_DownToOne.json', 'Action_Fortified.json', 'Action_InsanitysBlade.json', 'Action_FromEarth.json', 'Action_BrickForce.json', 'Action_BetOnSoldier.json', 'Action_GrimoireManastorm.json', 'Action_GauntletLilithTheNecromancer.json', 'Action_IamWeaponRevival.json', 'Action_RaptorCallofTheShadows2015Edition.json', 'Action_BloodsportsTV.json', 'Action_review_337320.json', 'Action_DeadIslandRetroRevenge.json', 'Action_PAYDAY2CloverCharacterPack.json', 'Action_PAYDAY2TheDiamondHeist.json', 'Action_review_338470.json', 'Action_NavyFIeld2ConqueroroftheOcean.json', 'Action_ZOMBI.json', 'Action_PAYDAY2TheBombHeists.json', 'Action_Freestyle2.json', 'Action_Headlander.json', 'Action_Survivalist.json', 'Action_TDP4TeamBattle.json', 'Action_NinjaGuy.json', 'Action_DisneyBolt.json', 'Action_ChroniclesofTeddy.json', 'Action_IAmTheHero.json', 'Action_MustacheinHell.json', 'Action_RoadRage.json', 'Action_TomatoJones.json', 'Action_Bulletstorm.json', 'Action_BERSERK.json', 'Action_AceCombat7SkiesUnknown.json', 'Action_StrikeisTheGame.json', 'Action_GangsofSpace.json', 'Action_Battlerite.json', 'Action_TheGodsChain.json', 'Action_CarmageddonMaxDAmage.json', 'Action_LetThemCome.json', 'Action_PartyPanic.json', 'Action_LastManStanding.json', 'Action_DOGOS.json', 'Action_DRAGONBALLXENOVERSE2SuperPass.json', 'Action_DragonBallXenoverse2SuperPack1.json', 'Action_DragonBallXenoverse2SuperPack3.json', 'Action_DragonBallXenoverse2SuperPack4.json', 'Action_HandsomeMrFrog.json', 'Action_DeadbyDaylightThelastBreathChapter.json', 'Action_review_509840.json', 'Action_Bumper.json', 'Action_FateExtella.json', 'Action_MakeAmericaGreatAgain.json', 'Action_ThepirateCaribbeanHunt.json', 'Action_ARKScorchedEarth.json', 'Action_KUBOOM.json', 'Action_Blade&Bones.json', 'Action_SCUM.json', 'Action_DeadlyDozen.json', 'Action_LineofSightVietnam.json', 'Action_Alone.json', 'Action_UBERMOSHVOL3.json', 'Action_Runner3.json', 'Action_Pinkman.json', 'Action_GunGirl2.json', 'Action_JustCause4Reloaded.json', 'Action_ChimpactChucksAdventure.json', 'Action_Intruder.json', 'Action_Zone4.json', 'Action_ZomboBusterRising.json', 'Action_SodaGirls.json', 'Action_NextDay.json', 'Action_GuiltyGearXrd.json', 'Action_DeathsHangover.json', 'Action_GUNGODZ.json', 'Action_HYPERCHARGEUnboxed.json', 'Action_TechwarsGlobalConflict.json', 'Action_OfBirdandCage.json', 'Action_AsuraVengeanceEdition.json', 'Action_TheDisneyAfternoonCollection.json', 'Action_GunsGoreandCannoli2.json', 'Action_TheWildEight.json', 'Action_review_526370.json', 'Action_WhatTheBox.json', 'Action_Merger3D.json', 'Action_Wells.json', 'Action_DoubleDragonIV.json', 'Action_Shu.json', 'Action_RogueTrooperRedux.json', 'Action_BrawlofAges.json', 'Action_PixelWarfarePro.json', 'Action_BannedFootageVol2.json', 'Action_EndofZoe.json', 'Action_review_531800.json', 'Action_TheDesolationofMordorStoryExpansion.json', 'Action_review_533200.json', 'Action_AgentoRigins.json', 'Action_DragonsSin.json', 'Action_Domina.json', 'Action_Nidhogg2.json', 'Action_MicroMachinesWorldSeries.json', 'Action_CardsofCthulhu.json', 'Action_ChaosCodeNewSignofCatatrophe.json', 'Action_review_537324.json', 'Action_GutsandGlory.json', 'Action_InnerChains.json', 'Action_TwelveSky2Classic.json', 'Action_NuclearContingency.json', 'Action_GTTOD.json', 'Action_AlienShooterTD.json', 'Action_DisneyInfinity20GoldEdition.json', 'Action_BubbleBlowout.json', 'Action_BlockBlowout.json', 'Action_BalloonBlowout.json', 'Action_ByteFamily.json', 'Action_DeadRising4.json', 'Action_NarutoShippudenUltimateNinjaStorm2.json', 'Action_METALGEARSURVIVE.json', 'Action_NITETeam4MilitaryHackingDivision.json', 'Action_HolyAvenger.json', 'Action_SoulCaliburVI.json', 'Action_PuyoPuyoTetris.json', 'Action_BriefKarateFoolish.json', 'Action_MachineHunt.json', 'Action_panGEMic.json', 'Action_Clown2Beat.json', 'Action_DeepRockGalactic.json', 'Action_RAGE2.json', 'Action_IronCrypticle.json', 'Action_LeviathanStarblade.json', 'Action_review_550040.json', 'Action_UminekoGoldenFantasia.json', 'Action_Toukiden2.json', 'Action_WarhhammerVermintide2.json', 'Action_FarCry5.json', 'Action_Sumoman.json', 'Action_review_553030.json', 'Action_ICEY.json', 'Action_PWND.json', 'Action_ArchangelHellfireenlist.json', 'Action_FrequentFlyer.json', 'Action_RageWars.json', 'Action_Crackhead.json', 'Action_PavlovVR.json', 'Action_review_555440.json', 'Action_InfestationTheNewZ.json', 'Action_TomClancysTHeDivisonSurvival.json', 'Action_review_556970.json', 'Action_LeagueOfMaidens.json', 'Action_GermWars.json', 'Action_review_559840.json', 'Action_StarWarsShadowsofTheEmpire.json', 'Action_IndianaJonesandtheEmperorsTomb.json', 'Action_SlaughterTribeNemesisExpansion.json', 'Action_TankiOnline.json', 'Action_Waveshaper.json', 'Action_GalacticJunkLeague.json', 'Action_SteelEmpire.json', 'Action_AlienSwarm.json', 'Action_BudSpencer&TerenceHillSlapsAndBeans.json', 'Action_Rosenkreuzstilette.json', 'Action_NotAHero.json', 'Action_SeriousSamFusion2017.json', 'Action_BladeStrangers.json', 'Action_review_567090.json', 'Action_BloodOfSteel.json', 'Action_review_568110.json', 'Action_RaidenVDirectorsCut.json', 'Action_Extinction.json', 'Action_TheKingOfFightersXIVSteamEdition.json', 'Action_DED.json', 'Action_AngelswithScalyWings.json', 'Action_review_571870.json', 'Action_NoWayOut.json', 'Action_review_572600.json', 'Action_RED.json', 'Action_TomClancysGhostReconWildlandsSeasonPassYear1.json', 'Action_TomClancysGhostReconWildlandsFallenGhosts.json', 'Action_FogofWar.json', 'Action_SpaceWars.json', 'Action_MOTHERGUNSHIP.json', 'Action_EarthDefenseForce.json', 'Action_Remnants.json', 'Action_ThemsFightinHerds.json', 'Action_StateofAnarchyMasterofMayhem.json', 'Action_review_576440.json', 'Action_2Ninjas1Cup.json', 'Action_ThePitInfinity.json', 'Action_KillerInstinct.json', 'Action_PUBGBATTLEGROUNDS.json', 'Action_review_578600.json', 'Action_GORN.json', 'Action_review_579800.json', 'Action_BloodyTrapland2.json', 'Action_Tekken7SeasonPass.json', 'Action_InsurgencySandstorm.json', 'Action_TheAlbatross.json', 'Action_SwordWithSauce.json', 'Action_IronArmada.json', 'Action_review_582380.json', 'Action_review_582880.json', 'Action_review_584210.json', 'Action_StayinAlive.json', 'Action_review_585030.json', 'Action_Trailmakers.json', 'Action_WildGunsReloaded.json', 'Action_BlazBlueCentralfiction.json', 'Action_StreetFighter30thanniversary.json', 'Action_Wulverblade.json', 'Action_DarkThrone.json', 'Action_HalfLife2Downfall.json', 'Action_DeadDrop.json', 'Action_FalseFront.json', 'Action_Holdfast.json', 'Action_ShovelKnightSpecterofTorment.json', 'Action_LearntoFly3.json', 'Action_RemnantsofNaezith.json', 'Action_JohnWickChapter2.json', 'Action_review_591530.json', 'Action_PAYDAY2JohnWickHeists.json', 'Action_SniperFury.json', 'Action_HyperBrawlTournament.json', 'Action_FORHONORYear1HeroesBundle.json', 'Action_Tekken7DLC3.json', 'Action_KnightsAndBikes.json', 'Action_ShadowWarrior2BountyHunt.json', 'Action_AerialDestruction.json', 'Action_PixARK.json', 'Action_review_593880.json', 'Action_HuntShowdown.json', 'Action_TheOnlyTraitorDLC.json', 'Action_NightStarRogueWings.json', 'Action_SkyKnights.json', 'Action_SamuraiWarriorsSpirtofSanada.json', 'Action_Apocryphandoldschoolshooter.json', 'Action_HyperKnights.json', 'Action_CloneDroneInTheDangerZone.json', 'Action_SliceDiceRice.json', 'Action_BorealBlade.json', 'Action_Cryogear.json', 'Action_AttackOnTitan2.json', 'Action_DevilMayCry5.json', 'Action_LampHead.json', 'Action_CavemanWarriors.json', 'Action_FOXnFORESTS.json', 'Action_ShotgunFarmers.json', 'Action_TankForce.json', 'Action_InDeath.json', 'Action_FlashingLights.json', 'Action_DieforValhalla.json', 'Action_NightTrap.json', 'Action_SineMoraEX.json', 'Action_MasterofAnima.json', 'Action_CrimsomMetalClassic1999.json', 'Action_Potentia.json', 'Action_review_607200.json', 'Action_SCARF.json', 'Action_EpicSnails.json', 'Action_PIXELZUMBI.json', 'Action_ShockRods.json', 'Action_BlastZoneTournament.json', 'Action_UltraGoodness.json', 'Action_WarriorsAllStars.json', 'Action_CityBattle.json', 'Action_DoomVFR.json', 'Action_WolfensteinsIINewColossus.json', 'Action_ZoneoftheEndersThe2ndRunner.json', 'Action_QuantumLeague.json', 'Action_QuakeChampions.json', 'Action_ZombidleREMONSTERED.json', 'Action_WolfensteinII.json', 'Action_NeedForDrink.json', 'Action_DeadbeatHeroes.json', 'Action_DishonoredDeathoftheOutsider.json', 'Action_TheMisfits.json', 'Action_BlackSquad.json', 'Action_BlackSquadFoundersPackage.json', 'Action_BlackSquadEAFREETIMEDWEAPONPACKAGE3.json', 'Action_BlackSuqadEAFREETIMEDWEAPONPACKAGE4.json', 'Action_BloodWaves.json', 'Action_MaskedForcesZombieSurvival.json', 'Action_Nokbak.json', 'Action_review_615050.json', 'Action_Compound.json', 'Action_Heat.json', 'Action_ClawsofFurry.json', 'Action_RICO.json', 'Action_ArcadeMayhemJuanito.json', 'Action_CannonsDefenders.json', 'Action_SUPERHOTVR.json', 'Action_BeatHazard2.json', 'Action_SOS.json', 'Action_KillingFloor.json', 'Action_DarkestHourEurope44.json', 'Action_Sinepisodes.json', 'Action_SiNgold.json', 'Action_Earth2160.json', 'Action_Ultimatedoom.json', 'Action_DOOMII.json', 'Action_QUAKEIIMissionPackTheReckoning.json', 'Action_HeXenBeyondHeretic.json', 'Action_HeXenDeathkingsoftheDarkCitadel.json', 'Action_BloodyGoodTime.json', 'Action_Shadowgrounds.json', 'Action_VampireTheMasqueradebloodlines.json', 'Action_GUN.json', 'Action_CallofDutyUnitedOffensive.json', 'Action_ARMACombatOperations.json', 'Action_CallOfJuarezOriginal.json', 'Action_PeggleExtreme.json', 'Action_PeggleNights.json', 'Action_ZumasRevenge.json', 'Action_SniperElite.json', 'Action_JudgeDreddDreddvsDeath.json', 'Action_Psychonauts.json', 'Action_STALKERShadowOfChernobyl.json', 'Action_FullSpectrumWarrior.json', 'Action_review_4540.json', 'Action_review_4550.json', 'Action_StarWarsRepublicCommando.json', 'Action_StarWarsJediKnightJediAcademy.json', 'Action_StarWarsJediKnightII.json', 'Action_MakingHIstoryTheCalm&theStorm.json', 'Action_LostPLanetExtremeCondition.json', 'Action_review_6570.json', 'Action_DevilMayCry3.json', 'Action_Commandos3DestinationBerlin.json', 'Action_BattlestationsMidway.json', 'Action_HitmanBloodMoney.json', 'Action_JustCause.json', 'Action_HitmanCodename47.json', 'Action_ThiefDeadlyShadows.json', 'Action_RogueTrooper.json', 'Action_ProjectSnowblind.json', 'Action_Bioshock.json', 'Action_NecroVision.json', 'Action_KaneandLynchDeadMen.json', 'Action_Conflict.json', 'Action_BattlestationsPacific.json', 'Action_JustCause2.json', 'Action_GeometryWarsRetroEvolved.json', 'Action_bioshock2.json', 'Action_BioShockInfinite.json', 'Action_BorderlandsGOTY.json', 'Action_SpearofDestiny.json', 'Action_DOOM3.json', 'Action_HeXenII.json', 'Action_DOOM3RessusrectionofEvil.json', 'Action_MasterLevelsforDoomII.json', 'Action_CommanderKeen.json', 'Action_RAGE.json', 'Action_FrontlinesFuelofWar.json', 'Action_SaintsRow2.json', 'Action_Desperados2CoopersRevenge.json', 'Action_DeathtoSpies.json', 'Action_review_9870.json', 'Action_BladeKitten.json', 'Action_review_9990.json', 'Action_TimeSHift.json', 'Action_CallofDutyModernWarfare2ResurgencePack.json', 'Action_PostalIII.json', 'Action_AliensvsPredator.json', 'Action_ShadowgroundsSurvivor.json', 'Action_PenguinsArenaSednasWorld.json', 'Action_LarvaMortus.json', 'Action_review_11420.json', 'Action_CrashTIme2.json', 'Action_Manhunt.json', 'ActionMaxPayne.json', 'Action_MaxPayne2.json', 'Action_GrandTheftAuto2.json', 'Action_GrandTheftAuto.json', 'Action_BullyScholarshipEdition.json', 'Action_GTAIV.json', 'Action_GrandThefAutoEpisodesFromLibertyCity.json', 'Action_review_12750.json', 'Action_review_12840.json', 'Action_AmericasArmy3.json', 'Action_Unreal2TheAwakening.json', 'Action_PrinceofPersiaWarriorWithin.json', 'Action_FarCry.json', 'Action_PrinceofPersiaTheTwoThrones.json', 'Action_TomClancysRaibownSixVegas.json', 'Action_TomClancysSPlinterCEll.json', 'Action_TomClancysSplinterCellDoubleAgent.json', 'Action_TomClancysSplinterCEllChaosTheory.json', 'Action_PrinceofPersiaTheSandsoftime.json', 'Action_TomClancysGhostReconDesertSiege.json', 'Action_TomClancysGhostReconIslandthunder.json', 'Action_RaymanRavingRabbids.json', 'Action_AssassinsCreedDirectorsCutEdition.json', 'Action_TomClancysRainbowSixVegas2.json', 'Action_BrotherinArmsHellsHighway.json', 'Action_AaaaaAAaaAAaaaA.json', 'Action_FEAR2.json', 'Action_VelvetAssassin.json', 'Action_Legendary.json', 'Action_GlobalAgendaFreeAgent.json', 'Action_CrysisWarhead.json', 'Action_Command&ConquerRedAlert3.json', 'Action_ZombiePanic.json', 'Action_Synergy.json', 'Action_EternalSilence.json', 'Action_Piratesvikingsandknights.json', 'Action_Dystopia.json', 'Action_INSURGENCY(1).json', 'Action_BrothersinArmsEarnedinBlood.json', 'Action_TomCLancysRainbowSix3Gold.json', 'Action_FarCry2Original.json', 'Action_review_19930.json', 'Action_PrinceofPersia.json', 'Action_RedFactionGUerrillaSteamEdition.json', 'Action_RedFaction.json', 'Action_RedFactionII.json', 'Action_WatchmenTheEndisNigh.json', 'Action_WatchmenTheEndisNighPart2.json', 'Action_FEAR.json', 'Action_FEAR3.json', 'Action_StreetFighterIV.json', 'Action_BionicCommando.json', 'Action_BionicCommandoRearmed.json', 'Action_review_21760.json', 'Action_DriverParallelLines.json', 'Action_review_21900.json', 'Action_review_21970.json', 'Action_CallOfJuarezBoundinBlood.json', 'Action_ZenoClash.json', 'Action_review_22180.json', 'Action_RogueWarrior.json', 'Action_HuntedTheDemonsForge.json', 'Action_AlienBreedImpact.json', 'Action_AlienBreed2.json', 'Action_AlienBreed3Descent.json', 'Action_EarthDefenseForceInsectArmageddon.json', 'Action_PaydayTheHeist.json', 'Action_review_24860.json', 'Action_LugaruHd.json', 'Action_Overgrowth.json', 'Action_BoosterTrooper.json', 'Action_DeadHorde.json', 'Action_Kayne&Lynch2.json', 'Action_review_28050.json', 'Action_DarkSector.json', 'Action_Caster.json', 'Action_review_31410.json', 'Action_StarWarsStarfighter.json', 'Action_StarWarsKnightsOfTheOldRepublic.json', 'Action_StarWarsJediKnightDarkForcesII.json', 'Action_StarWarsJediKnightMysteriesoftheSith.json', 'Action_StarWarsTheCloneWarsRepublicHeroes.json', 'Action_StarWarstheForceUnleashed(1).json', 'Action_StarWarsEmpireatWar.json', 'Action_StarWarsTheForceUnleashed.json', 'Action_DeltaForce2.json', 'Action_DeltaForce.json', 'Action_DeltaForceBlackHawkDown.json', 'Action_Comanche4.json', 'Action_JointOperationsCombinedArmsGold.json', 'Action_AlienShooter.json', 'Action_AlienShooter2Reloaded.json', 'Action_ZombieShooter.json', 'Action_ZombieShooter2.json', 'Action_TomClancysSplinterCellConviction.json', 'Action_PrinceofPersiaTheForgottenSands.json', 'Action_TeamFortress2.json', 'Action_Left4Dead.json', 'Action_Hatred.json', 'Action_TotoTempleDeluxe.json', 'Action_review_343330.json', 'Action_CrashDrive2.json', 'Action_CroNix.json', 'Action_DRAGONBALLXENOVERSEGTPack1.json', 'Action_DragonBallZResurrectionFPack.json', 'Action_DragonBallXenoverseGTPack2.json', 'Action_SunBlastStarFighter.json', 'Action_FlameOver.json', 'Action_TastyBlue.json', 'Action_review_345520.json', 'Action_review_346270.json', 'Action_IntoTheWar.json', 'Action_GoccoOfWar.json', 'Action_Steredenn.json', 'Action_RiseShine.json', 'Action_KarateMaster2KnockDownBlow.json', 'Action_Caromble.json', 'Action_PAYDAY2TheOVERKILLPack.json', 'Action_review_348350.json', 'Action_LexMortis.json', 'Action_SamuraiWarriors4II.json', 'Action_GuiltyGearXXAccent.json', 'Action_NaturoShippuder_UNS4.json', 'Action_BlastZone2.json', 'Action_ModularCombat.json', 'Action_Armillo.json', 'Action_PAYDAY2TheButchersWesternPack.json', 'Action_review_350280.json', 'Action_FlyintheHouse.json', 'Action_review_350660.json', 'Action_review_351040.json', 'Action_SURVIVAL.json', 'Action_review_351840.json', 'Action_PAYDAY2TheButchersAKCARModPack.json', 'Action_Bombshell.json', 'Action_TheDeadlyTowerofMonsters.json', 'Action_Aberoth.json', 'Action_AssassinsCreedChroniclesChina.json', 'Action_StarWarsXWINGSpecialEdition.json', 'Action_PAYDAYTheWebSeries.json', 'Action_WolfensteinTheOldBlood.json', 'Action_HeadcrabFrenzy.json', 'Action_SkyForceAnniversary.json', 'Action_CodenameCure.json', 'Action_ReignofBullets.json', 'Action_StyxShardsOfDarkness.json', 'Action_Survarium.json', 'Action_review_356200.json', 'Action_MetalSlugDEFENSE.json', 'Action_StarWArsGalacticBattlegroundsSaga.json', 'Action_review_356640.json', 'Action_BattleFantasiaRevisedEdition.json', 'Action_UltimateMarvelvsCapcom3.json', 'Action_RumbleFighterUnleashed.json', 'Action_PAYDAY2TheButchersBBQPack.json', 'Action_Stargunner.json', 'Action_RiseoftheTriadDarkWar.json', 'Action_review_358430.json', 'Action_review_359480.json', 'Action_AssassinsCreedChroniclesRussia.json', 'Action_AssassinsCreedChroniclesIndia.json', 'Action_MafiaIII.json', 'Action_review_360480.json', 'Action_Spellsworm.json', 'Action_review_360700.json', 'Action_POSTAL2.json', 'Action_TheMeanGreens.json', 'Action_MotherRussiaBleeds.json', 'Action_404Sight.json', 'Action_MortalKombatLegacy.json', 'Action_StarWarsXWingAlliance.json', 'Action_MortalKombatLegacyII.json', 'Action_Fighties.json', 'Action_BlackMesa.json', 'Action_ToukidenKiwami.json', 'Action_LeapofFate.json', 'Action_Spermination.json', 'Action_EscapeMachines.json', 'Action_Goliath.json', 'Action_Botology.json', 'Action_RedemptionSaintsAndSinners.json', 'Action_Ogrest.json', 'Action_Tranmissions.json', 'Action_TomClancysTheDivision.json', 'Action_FlyingTigerShadowsOverChina.json', 'Action_MetalSlug.json', 'Action_GAROU.json', 'Action_MetalSlug2.json', 'Action_ShockTroopers.json', 'Action_SavageResurrection.json', 'Action_PAYDAY2TheAlessoHeist.json', 'Action_CallofDUtyBlackOpsIII(1).json', 'Action_review_366844.json', 'Action_review_366845.json', 'Action_MightySwitchForceHyperDriveEdition.json', 'Action_AngelsFallFirst.json', 'Action_BatmanArkhamKnightSeasonPass.json', 'Action_SniperGhostWarrior3.json', 'Action_review_368420.json', 'Action_PAYDAY2TheOVERKILLBSidesSoundtrack.json', 'Action_GarbageDay.json', 'Action_VoidDestroyer2.json', 'Action_NotTheNameWeWanted.json', 'Action_JimPowerTheLostDimension.json', 'Action_ArcanaHear3LOVEMAX.json', 'Action_FieldsofBattle.json', 'Action_Holodrive.json', 'Action_Gunnheim.json', 'Action_FarCryPrimal.json', 'Action_Gunslugs.json', 'Action_SpookyCats.json', 'Action_TheLostMythologies.json', 'Action_KungFuryStreetRage.json', 'Action_review_373280.json', 'Action_StonesofSorrow.json', 'Action_review_373680.json', 'Action_review_373700.json', 'Action_Infernax.json', 'Action_PayDay2theGoldenGrinCasinoHeist.json', 'Action_HiredOps.json', 'Action_KungFury.json', 'Action_AirBrawl.json', 'Action_review_375960.json', 'Action_GUILTYGEAR(2).json', 'Action_review_376890.json', 'Action_TikiMan.json', 'Action_ThunderTieOne.json', 'Action_TomClancysRainbowSixSiegeultraHdTexturePack.json', 'Action_DARIUSBURSTChronicleSaviours.json', 'Action_Mushihimesama.json', 'Action_StrikeSuitInfinity.json', 'Action_review_378120.json', 'Action_Nomad.json', 'Action_TheSurge.json', 'Action_BluesandBullets.json', 'Action_PixelStarships.json', 'Action_SumoRevise.json', 'Action_DOOM.json', 'Action_ThreeHeroes.json', 'Action_review_380230.json', 'Action_review_380770.json', 'Action_Teeworlds.json', 'Action_review_381150.json', 'Action_CruelArena.json', 'Action_CounterStrikeNexonZombieJounreytotheWest.json', 'Action_review_381570.json', 'Action_review_381810.json', 'Action_8BitFiestaPartyGame.json', 'Action_DeadIslandRiptideDefinitiveEdition.json', 'Action_TheShipRemasted.json', 'Action_NimbatusTheSpaceDroneConstructor.json', 'Action_PAYDAY2YakuzaCharacterPack.json', 'Action_PAYDAY2GageNinjaPack.json', 'Action_Mutecrimsom.json', 'Action_ShadowComplexRemastered.json', 'Action_TimeClickers.json', 'Action_Pharaonic.json', 'Action_Vendetta.json', 'Action_CookServeDelicious2.json', 'Action_PixelFodder.json', 'Action_CaladriusBlaze.json', 'Action_BrawlhallaAllLegends.json', 'Action_CallOfDutyBlackOpsIII.json', 'Action_BlazBlueChronophantasmaExtend.json', 'Action_AzureStrikerGunvolt.json', 'Action_review_389280.json', 'Action_KnightOnline.json', 'Action_Tekken7.json', 'Action_UmbrellaCorps.json', 'Action_PewDiePieLegendoftheBrofist.json', 'Action_FreeStrike.json', 'Action_CallofTomsk7.json', 'Action_AccelerationofSUGURI2.json', 'Action_Sora.json', 'Action_AIPDArtificialIntelligencePoliceDepartment.json', 'Action_Blastoff.json', 'Action_Ladra.json', 'Action_WARMODE.json', 'Action_Crashlands.json', 'Action_WildGlory.json', 'Action_Uebergame.json', 'Action_TronRun.json', 'Action_Murasaki.json', 'Action_review_392060.json', 'Action_X4.json', 'Action_BadRatsShow.json', 'Action_Squad.json', 'Action_Hurtworld.json', 'Action_RogueOperativesHideandSeek.json', 'Action_ArcadeGameSeriesPacMan.json', 'Action_Battleborn.json', 'Action_BattleStick.json', 'Action_Helldivers.json', 'Action_TowerUnite.json', 'Action_DeadEffect2.json', 'Action_MiracleFly.json', 'Action_BenandEd.json', 'Action_EVERSPACE.json', 'Action_Borderlands3.json', 'Action_Moonbase332.json', 'Action_Clustertruck.json', 'Action_Timberman.json', 'Action_PorradariaUpgrade.json', 'Action_Prospekt.json', 'Action_review_399660.json', 'Action_Mightyno9Ray.json', 'Action_PAYDAY2GageChivalryPack.json', 'Action_POSTALREDUX.json', 'Action_Flinthook.json', 'Action_DeathstateAbyssalEdition.json', 'Action_PressXtoNotDie.json', 'Action_BlueRider.json', 'Action_HyperdriveMassacre.json', 'Action_ArcadeGameSeries.json', 'Action_ArcadeGameSeriesGalaga.json', 'Action_Dishonored2.json', 'Action_CodenameRogueFleet.json', 'Action_ZeroPunctuationHatfall.json', 'Action_TotalWarWARHAMMERChaosWarriors.json', 'Action_NexMachina.json', 'Action_AssassinsCreedSyndicateJackTheRipper.json', 'Action_CharlieMurder.json', 'Action_ZeroReflexBlackEyeEdition.json', 'Action_Turok.json', 'Action_DubDash.json', 'Action_review_407090.json', 'Action_review_407250.json', 'Action_ARKSURVIVALofTheFittest.json', 'Action_RaidenLegacySteamEdition.json', 'Action_HardResetRedux.json', 'Action_GuardiansofOrion.json', 'Action_UnfortunateSpacemen.json', 'Action_KnightAdventure.json', 'Action_GenesisOnline.json', 'Action_BioshockRemastered.json', 'Action_Bioshock2Remastered.json', 'Action_12isBetterThan6.json', 'Action_EarthDefenseForce41.json', 'Action_review_410420.json', 'Action_ArenaGods.json', 'Action_DragonQuestHeroesSlimeEdition.json', 'Action_review_411000.json', 'Action_Showtime2073.json', 'Action_Dota2PlayerProfiles.json', 'Action_MenofValor.json', 'Action_TYtheTasmanianTiger.json', 'Action_MetroExodus.json', 'Action_DDraceNetwork.json', 'Action_GASP.json', 'Action_TheBlackDeath.json', 'Action_MetalWarOnlineRetribution.json', 'Action_BulletHeaven2.json', 'Action_review_412720.json', 'Action_review_412940.json', 'Action_Mytheon.json', 'Action_MetalAssault.json', 'Action_review_413690.json', 'Action_RAIDWorldWarII.json', 'Action_CorgiWarlock.json', 'Action_PangAdventures.json', 'Action_ShootingStars.json', 'Action_Earthfall.json', 'Action_HeavyGearAssault.json', 'Action_CLASH.json', 'Action_NarutoShippudenUltimateNinjaStorm4Shikamarustale.json', 'Action_NarutoShippudenUltimateNinjaStorm4.json', 'Action_NARUTOSHIPPUDENUltimateNinjaSTORM4TheSoundFourCharactersPack.json', 'Action_FullMetalFuries.json', 'Action_TomClancysRainbowSixSiegeTheSafariBundle.json', 'Action_TomClancysRainbowSiexSiegeAmethystWeaponSkin.json', 'Action_TomClancysRainbowSixSiegeEmeraldWeaponSkin.json', 'Action_TomClancysRainbownSixSiegeCobaltWeaponSkin.json', 'Action_TomClancysRainbowSix.json', 'Action_MarcusLevel.json', 'Action_StreetWarriorsOnline.json', 'Action_ApotheonArena.json', 'Action_Subsistence.json', 'Action_TempestPirateActionRPG.json', 'Action_DrawSlasher.json', 'Action_RWBY.json', 'Action_RisginStorm2Vietnam.json', 'Action_TheTakeOver.json', 'Action_SpacePirateTrainer.json', 'Action_review_418990.json', 'Action_WarhammerEndtimesvermintide.json', 'Action_review_419270.json', 'Action_Blackwake.json', 'Action_TheLegendofDarkWitch.json', 'Action_Starbreak.json', 'Action_review_421650.json', 'Action_Furi.json', 'Action_AirMissionsHIND.json', 'Action_HitTankPRO.json', 'Action_Dinocide.json', 'Action_DeadlightDirectorsCut.json', 'Action_StreetFighterVSeason1CharacterPass.json', 'Action_Shadwen.json', 'Action_OnePieceBurningBlood.json', 'Action_Ghostbusters.json', 'Action_Seraph.json', 'Action_LegoMarvelsAvengersSeasonPass.json', 'Action_DeadRising.json', 'Action_WayoftheSamurai3.json', 'Action_Whosyourdaddy.json', 'Action_review_427920.json', 'Action_review_428420.json', 'Action_FullBlast.json', 'Action_MegatonRainfall.json', 'Action_NomadPremium.json', 'Action_Kabounce.json', 'Action_SilverKnight.json', 'Action_WelkinRoad.json', 'Action_Inversusdeluxe.json', 'Action_DieYoung.json', 'Action_MarvelUltimateAlliance.json', 'Action_BlackShot.json', 'Action_HeliborneCollection.json', 'Action_review_433800.json', 'Action_Z1.json', 'Action_BitBlasterXL.json', 'Action_DukeNukem3d20thanniversaryworldtour.json', 'Action_review_434120.json', 'Action_AHoleNewWorld.json', 'Action_MaskedShooters2.json', 'Action_BloodAndBacon.json', 'Action_Halfdead.json', 'Action_MetalGearOnlineExpansionPack.json', 'Action_Spacelords.json', 'Action_LineOfSight.json', 'Action_GuiltyGear2Overture.json', 'Action_TheCulling.json', 'Action_SquidsFromSpace.json', 'Action_TomCLancysTheDivisionSeasonPass.json', 'Action_VentureKId.json', 'Action_TomClancysTheDivisionMarineForcesOutfitsPack.json', 'Action_TomClancysTheDivisionMilitarySpecialists.json', 'Action_Dead6hot.json', 'Action_RocketLeagueBatmanvSuperman.json', 'Action_Midair.json', 'Action_HITMANEPISODE2Sapienza.json', 'Action_HeroesofTheWest.json', 'Action_ProjectArrhythmia.json', 'Action_TheBrookhavenExperiment.json', 'Action_epicbattleswithin5seconds.json', 'Action_SurvivalZombieTheInvertedEvolution.json', 'Action_review_441020.json', 'Action_Talewind.json', 'Action_PACMANCHAMPIONSHIPEDITION2.json', 'Action_PAYDAY2WolfPack.json', 'Action_Fragmented.json', 'Action_review_441920.json', 'Action_review_443080.json', 'Action_ArmoredWarfare.json', 'Action_Lastfight.json', 'Action_WorldOfTanksBlitz(1).json', 'Action_POLYWAR.json', 'Action_AgentOrigins(1).json', 'Action_SkautfoldShroudedinSanity.json', 'Action_Bloons.json', 'Action_Trapped.json', 'Action_Inexistence.json', 'Action_UBERMOSHBLACK.json', 'Action_review_446270.json', 'Action_APEOUT.json', 'Action_RedeemerEnhancedEdition.json', 'Action_review_447500.json', 'Action_CatonaDiet.json', 'Action_SoLongEarth.json', 'Action_review_448460.json', 'Action_Overload.json', 'Action_MomodoraReverieUndertheMoonlightOST.json', 'Action_LegoMarvelsavengersDLCSpiderMancharacterPack.json', 'Action_review_449670.json', 'Action_BloodyZombies.json', 'Action_AttackonTitanAOTWingsofFreedom.json', 'Action_OverloadPlayableTeaser.json', 'Action_TheLab.json', 'Action_PAYDAY2BikerCharacterPack.json', 'Action_TomClancysRainbowSixSiegeRubyWeaponSkin.json', 'Action_Andarilho.json', 'Action_review_451320.json', 'Action_KoihimeEnbu.json', 'Action_review_452430.json', 'Action_UNDERNIGHTINBIRTHEXE.json', 'Action_MadnessCubed.json', 'Action_DungeonEscape.json', 'Action_NeonHardcorps.json', 'Action_DaysofWardefinitiveEdition.json', 'Action_DragonBallXenoverse2.json', 'Action_DeuteriumWars.json', 'Action_PAcMan256.json', 'Action_TomClancysRainbowSixSiegeTopazWeaponSkin.json', 'Action_TomClancysRainbowSixSiegeCyanWeaponSkin.json', 'Action_OmensightDefinitiveEdition.json', 'Action_StarWarsRogueSquadron3D.json', 'Action_SpaceScaven.json', 'Action_Exception.json', 'Action_StarWarsREbelAssaultIII.json', 'Action_review_457199.json', 'Action_BigscreenBeta.json', 'Action_TheSignalFromTolva.json', 'Action_TheSlimekingsTower.json', 'Action_Bayonetta.json', 'Action_review_460870.json', 'Action_Vanquish.json', 'Action_AGents.json', 'Action_TomClancysGhostRecon.json', 'Action_DoDonPachiRessurection.json', 'Action_SeriousSamVR.json', 'Action_TheLastBlade.json', 'Action_OriandtheBlindForestAdditionalSoundtrack.json', 'Action_ZION.json', 'Action_Worm.is.json', 'Action_CantDriveThis.json', 'Action_Khimera.json', 'Action_SmashingTheBattle.json', 'Action_HiveAltenumWars.json', 'Action_PAYDAY2SydneyCharacterPack.json', 'Action_NeonSpace.json', 'Action_SpeedBrawl.json', 'Action_1917.json', 'Action_QuantumReplica.json', 'Action_Rocketbirds2Evolution.json', 'Action_VersusSquad.json', 'Action_Killbot.json', 'Action_BUTCHER.json', 'Action_SniperElite4SeasonPass.json', 'Action_QuantumBreak.json', 'Action_StreeFighterVAshadowfalls.json', 'Action_CallysTrials.json', 'Action_review_477940.json', 'Action_HideandShriek.json', 'Action_Prey.json']\n",
            "🔍 Exemplo de dados: [('reviews', {'106208136': {'recommendationid': '106208136', 'author': {'steamid': '76561198278381555', 'num_games_owned': 218, 'num_reviews': 27, 'playtime_forever': 397, 'playtime_last_two_weeks': 0, 'playtime_at_review': 397, 'last_played': 1625863019}, 'language': 'brazilian', 'review': 'Fodda.', 'timestamp_created': 1640050749, 'timestamp_updated': 1640050749, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': False, 'written_during_early_access': False}, '104230164': {'recommendationid': '104230164', 'author': {'steamid': '76561198424678766', 'num_games_owned': 73, 'num_reviews': 14, 'playtime_forever': 28, 'playtime_last_two_weeks': 0, 'playtime_at_review': 20, 'last_played': 1639332609}, 'language': 'brazilian', 'review': 'agora eu sei como andar de skate', 'timestamp_created': 1637972262, 'timestamp_updated': 1637972262, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '103969247': {'recommendationid': '103969247', 'author': {'steamid': '76561198860352124', 'num_games_owned': 56, 'num_reviews': 8, 'playtime_forever': 213, 'playtime_last_two_weeks': 0, 'playtime_at_review': 208, 'last_played': 1637882805}, 'language': 'brazilian', 'review': 'jogo pica tipo tony hawk, só que melho \\n⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⢀⡀⣼⣵⣽⣿⠄⡂⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⣴⣷⣿⣿⣿⣿⣷⣷⣷⣴⢠⣄⠄⢠⠄⠄⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⣬⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣷⣾⣷⣄⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⠃⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠛⠛⠛⠛⠛⠛⠿⣿⣿⣿⣿⢿⠛⣉⣥⣤⣀⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⢀⣤⡴⠶⠶⠶⢶⣿⣿⣿⣿⠛⢛⠛⠛⡉⠛⠄⠄⠄ ⠄⠄⠄⡀⠄⠄⠄⠄⠄⣴⣿⣡⣤⣤⣥⣿⣤⣢⠉⣿⣿⠄⣶⣶⣶⣶⣦⣦⡄⠄ ⠄⠄⠄⢋⣀⠄⠄⠄⠄⣿⣿⣿⣿⣿⣿⣿⣿⣿⣷⣿⣿⠄⣿⣿⣿⣿⣿⣿⡏⠄ ⠄⠄⠄⠈⢿⣆⠄⠄⠄⢻⣿⣿⣿⣿⣿⣿⣿⠿⠛⣿⣿⣦⡘⣿⣿⣿⣿⣿⠃⠄ ⠄⠄⠄⠄⠈⢻⣷⠄⠄⠈⣿⣿⣿⣿⣿⣿⣿⢼⣿⠿⣿⣿⣟⣽⣿⣿⣿⡟⠄⠄ ⣷⡄⠄⠄⠄⠄⠉⠄⠄⠄⣶⣿⣿⣿⣿⣿⣿⣿⣾⣿⣶⣿⣿⣿⣿⣿⣿⡇⡄⠄ ⠛⠁⠄⠄⠄⠄⠄⠄⠄⠄⠻⣿⣿⣿⣿⡛⠛⢛⣛⣟⣟⣻⣯⠍⢩⣿⣿⡏⠄⠄ ⠄⠄⠄⢠⢠⠄⠂⠄⠄⠄⠄⠙⢿⣿⣿⣿⣧⣌⣨⣯⣿⣯⠄⣤⣿⣿⡟⠃⠄⠄ ⠄⠄⠄⠋⠘⠄⠄⠄⠄⠄⠄⠄⠄⠻⣿⣿⣿⣿⣿⣿⣛⣿⣿⣿⣿⡟⠄⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠠⠄⠄⠄⠈⠿⠿⠿⠿⠿⠿⠿⠿⠿⠿⠄⠄⠄⠄⠄', 'timestamp_created': 1637882440, 'timestamp_updated': 1637882440, 'voted_up': True, 'votes_up': 1, 'votes_funny': 2, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '100097198': {'recommendationid': '100097198', 'author': {'steamid': '76561199003718330', 'num_games_owned': 74, 'num_reviews': 39, 'playtime_forever': 211, 'playtime_last_two_weeks': 0, 'playtime_at_review': 211, 'last_played': 1632843111}, 'language': 'brazilian', 'review': 'muito mais fodastico que o primeiro', 'timestamp_created': 1632843158, 'timestamp_updated': 1632843158, 'voted_up': True, 'votes_up': 2, 'votes_funny': 0, 'weighted_vote_score': '0.522336423397064209', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '99536971': {'recommendationid': '99536971', 'author': {'steamid': '76561198199749601', 'num_games_owned': 106, 'num_reviews': 14, 'playtime_forever': 99, 'playtime_last_two_weeks': 0, 'playtime_at_review': 83, 'last_played': 1644691291}, 'language': 'brazilian', 'review': 'Jogoé um pouco difícil, mas é engraçado. Bingo clandestino é de lascar', 'timestamp_created': 1631937516, 'timestamp_updated': 1631937516, 'voted_up': True, 'votes_up': 2, 'votes_funny': 0, 'weighted_vote_score': '0.522336423397064209', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '98865938': {'recommendationid': '98865938', 'author': {'steamid': '76561199093551448', 'num_games_owned': 41, 'num_reviews': 2, 'playtime_forever': 317, 'playtime_last_two_weeks': 0, 'playtime_at_review': 228, 'last_played': 1631346998}, 'language': 'brazilian', 'review': 'o jogo é de extrema qualidade, e extrema dificuldade, não é um jogo onde você é simplesmente um deus, e pode passar as fases na primeira tentativa, só pegue o game se a sua preocupação for com a qualidade do que está comprando, e pelo o preço vale muito a pena.', 'timestamp_created': 1630902046, 'timestamp_updated': 1630902046, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False, 'timestamp_dev_responded': 1631224683, 'developer_response': 'Fico contente que tenha gostado, Tristitia! Abraços!!'}, '96837778': {'recommendationid': '96837778', 'author': {'steamid': '76561198062780226', 'num_games_owned': 192, 'num_reviews': 18, 'playtime_forever': 860278, 'playtime_last_two_weeks': 20118, 'playtime_at_review': 545535, 'last_played': 1647947381}, 'language': 'brazilian', 'review': 'Gostei um pouco', 'timestamp_created': 1627944251, 'timestamp_updated': 1627944251, 'voted_up': True, 'votes_up': 4, 'votes_funny': 3, 'weighted_vote_score': '0.565711021423339844', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '96252918': {'recommendationid': '96252918', 'author': {'steamid': '76561199130286723', 'num_games_owned': 7, 'num_reviews': 11, 'playtime_forever': 14, 'playtime_last_two_weeks': 0, 'playtime_at_review': 10, 'last_played': 1630109756}, 'language': 'brazilian', 'review': 'jOGO TOP DE MAIS. TOTALMENTE ME LEMBRA COMO ERA BOM JOGAR NINTENDINHO.', 'timestamp_created': 1627067174, 'timestamp_updated': 1627067174, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': False, 'written_during_early_access': False}, '95444938': {'recommendationid': '95444938', 'author': {'steamid': '76561198809843678', 'num_games_owned': 100, 'num_reviews': 34, 'playtime_forever': 138, 'playtime_last_two_weeks': 0, 'playtime_at_review': 131, 'last_played': 1633915740}, 'language': 'brazilian', 'review': 'Marcelo achei um bug/glitch destruidor, eu esta no parque da sonica ai cheguei no boss com 1 coração partido ai eu dei um dash nela e deis dai não sofri dano mais, nada me matava as unicas coisas que me faziam perder de certa forma era cair nas vala dos mapa do caucho, lua plana... ARRUMA AI O LOCO MEU..', 'timestamp_created': 1625890096, 'timestamp_updated': 1625890096, 'voted_up': True, 'votes_up': 2, 'votes_funny': 0, 'weighted_vote_score': '0.518373727798461914', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '91372631': {'recommendationid': '91372631', 'author': {'steamid': '76561198064151123', 'num_games_owned': 382, 'num_reviews': 21, 'playtime_forever': 261, 'playtime_last_two_weeks': 0, 'playtime_at_review': 261, 'last_played': 1617231525}, 'language': 'brazilian', 'review': 'Skatemasta Tcheco é tipo aquelas fases de skate de wonderboy e Adventure Island... só que melhor (segundo eu mesmo xD), e custa menos que um salgado com refri, ouseja, compra logo gente!!!!!!!!\\n\\nSÓ OS LOUCOS SABEM!', 'timestamp_created': 1620069847, 'timestamp_updated': 1620069847, 'voted_up': True, 'votes_up': 3, 'votes_funny': 0, 'weighted_vote_score': '0.540504217147827148', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '89784295': {'recommendationid': '89784295', 'author': {'steamid': '76561198796408543', 'num_games_owned': 39, 'num_reviews': 12, 'playtime_forever': 358, 'playtime_last_two_weeks': 0, 'playtime_at_review': 355, 'last_played': 1617817924}, 'language': 'brazilian', 'review': 'Jogo Muito Barato E Estilo NES Recomendo Muito :)', 'timestamp_created': 1617646390, 'timestamp_updated': 1617646390, 'voted_up': True, 'votes_up': 2, 'votes_funny': 0, 'weighted_vote_score': '0.522336423397064209', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '86886118': {'recommendationid': '86886118', 'author': {'steamid': '76561198850469770', 'num_games_owned': 95, 'num_reviews': 39, 'playtime_forever': 268, 'playtime_last_two_weeks': 0, 'playtime_at_review': 120, 'last_played': 1617511132}, 'language': 'brazilian', 'review': 'só os loucos sabem', 'timestamp_created': 1613573954, 'timestamp_updated': 1613573954, 'voted_up': True, 'votes_up': 2, 'votes_funny': 0, 'weighted_vote_score': '0.524401605129241943', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '86854516': {'recommendationid': '86854516', 'author': {'steamid': '76561198035348259', 'num_games_owned': 1269, 'num_reviews': 285, 'playtime_forever': 354, 'playtime_last_two_weeks': 0, 'playtime_at_review': 26, 'last_played': 1619828568}, 'language': 'brazilian', 'review': 'Impressionante como ele fez 2 jogos do Tcheco e acertou em cheio nos 2 \\n\\nMesmo mudando totalmente a jogabilidade pra um jogo de Skate o jogo é muito divertido \\n\\nEstupidamente Difícil, mas assim como Souls vc se esforça para progredir e passar as fases \\n\\nDessa vez diferente de Tcheco no Castelo de Sarney o jogo tem Save e isso já da uma ajuda monstro\\n\\nSe tem algo que me incomoda e que o pulo e o dash é no mesmo botão então as vezes que tava no caos e dei o dash caindo no buraco não é brincadeira se fosse em outro botão ficaria perfeito para jogar\\n\\nMas pelo preço, não tem como não recomendar é um jogaço', 'timestamp_created': 1613539482, 'timestamp_updated': 1613539482, 'voted_up': True, 'votes_up': 2, 'votes_funny': 0, 'weighted_vote_score': '0.524401605129241943', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '84617052': {'recommendationid': '84617052', 'author': {'steamid': '76561198804641907', 'num_games_owned': 12, 'num_reviews': 8, 'playtime_forever': 224, 'playtime_last_two_weeks': 0, 'playtime_at_review': 9, 'last_played': 1610585598}, 'language': 'brazilian', 'review': 'skatemasta tcheco, o melhor jogo do brasil... e se bobear, DO MUNDO! serio mt divertido, dificuldade ta no pico do pico do pico pqp, top 10 jogos foda', 'timestamp_created': 1610550192, 'timestamp_updated': 1610550192, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '81756759': {'recommendationid': '81756759', 'author': {'steamid': '76561198344517152', 'num_games_owned': 86, 'num_reviews': 20, 'playtime_forever': 134, 'playtime_last_two_weeks': 0, 'playtime_at_review': 78, 'last_played': 1635036642}, 'language': 'brazilian', 'review': 'Jogo plataforma 2d,Brasileiro,RS <3,Tcheco amg,jogue e aprove', 'timestamp_created': 1607302842, 'timestamp_updated': 1607302842, 'voted_up': True, 'votes_up': 2, 'votes_funny': 1, 'weighted_vote_score': '0.524401605129241943', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': True, 'written_during_early_access': False}, '81314228': {'recommendationid': '81314228', 'author': {'steamid': '76561198065759344', 'num_games_owned': 168, 'num_reviews': 3, 'playtime_forever': 102, 'playtime_last_two_weeks': 0, 'playtime_at_review': 97, 'last_played': 1608393207}, 'language': 'brazilian', 'review': 'É um jogo bastante desafiador, mas nada mais justo para desafiar o mestre do skate!!', 'timestamp_created': 1606791880, 'timestamp_updated': 1606791880, 'voted_up': True, 'votes_up': 2, 'votes_funny': 1, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '81280942': {'recommendationid': '81280942', 'author': {'steamid': '76561198012840778', 'num_games_owned': 681, 'num_reviews': 8, 'playtime_forever': 22, 'playtime_last_two_weeks': 0, 'playtime_at_review': 22, 'last_played': 1606769916}, 'language': 'brazilian', 'review': 'Jogo baratinho mas divertido e bem feito com presença de humor alto astral (afinal de contas é o Tcheco)\\nNesse segundo jogo do Tcheco temos agora um sistema de save mas o jogo ainda testa as habilidades do jogador.', 'timestamp_created': 1606770336, 'timestamp_updated': 1606770336, 'voted_up': True, 'votes_up': 6, 'votes_funny': 0, 'weighted_vote_score': '0.578138530254364014', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '81242753': {'recommendationid': '81242753', 'author': {'steamid': '76561198072828221', 'num_games_owned': 269, 'num_reviews': 14, 'playtime_forever': 185, 'playtime_last_two_weeks': 0, 'playtime_at_review': 33, 'last_played': 1611082329}, 'language': 'brazilian', 'review': 'Massa!', 'timestamp_created': 1606753361, 'timestamp_updated': 1606753361, 'voted_up': True, 'votes_up': 2, 'votes_funny': 1, 'weighted_vote_score': '0.512250661849975586', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': False, 'written_during_early_access': False}, '81021816': {'recommendationid': '81021816', 'author': {'steamid': '76561198399549057', 'num_games_owned': 106, 'num_reviews': 14, 'playtime_forever': 27, 'playtime_last_two_weeks': 0, 'playtime_at_review': 27, 'last_played': 1589576964}, 'language': 'brazilian', 'review': 'é um sucesso. é um absurdo. é uma coisa boa. é uma gratificação instantânea de baixo custo.', 'timestamp_created': 1606641911, 'timestamp_updated': 1606641911, 'voted_up': True, 'votes_up': 37, 'votes_funny': 4, 'weighted_vote_score': '0.81218254566192627', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '80698613': {'recommendationid': '80698613', 'author': {'steamid': '76561198121126910', 'num_games_owned': 297, 'num_reviews': 5, 'playtime_forever': 16, 'playtime_last_two_weeks': 0, 'playtime_at_review': 16, 'last_played': 1606503429}, 'language': 'brazilian', 'review': 'Jogo divertido leve e com boa dificuldade;', 'timestamp_created': 1606503546, 'timestamp_updated': 1606503546, 'voted_up': True, 'votes_up': 2, 'votes_funny': 1, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': False, 'written_during_early_access': False}, '80622443': {'recommendationid': '80622443', 'author': {'steamid': '76561198219420949', 'num_games_owned': 115, 'num_reviews': 3, 'playtime_forever': 147, 'playtime_last_two_weeks': 0, 'playtime_at_review': 42, 'last_played': 1627516489}, 'language': 'brazilian', 'review': 'Desafiador e divertido', 'timestamp_created': 1606483422, 'timestamp_updated': 1606483422, 'voted_up': True, 'votes_up': 2, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '80471556': {'recommendationid': '80471556', 'author': {'steamid': '76561197960462503', 'num_games_owned': 263, 'num_reviews': 10, 'playtime_forever': 30, 'playtime_last_two_weeks': 0, 'playtime_at_review': 30, 'last_played': 1606428918}, 'language': 'brazilian', 'review': 'O SOL E O CACHORRO\\nEra uma vez o sol,\\nera uma vez o cachorro,\\naí o sol falou para o cachorro,\\n-eeeehn eeenhehnune eenaeea,\\naí o cachorro falou,\\n-aitsne tchisnueeiii aieuuuuinhee\\naí o sol e o cachorro foram para a beira do rio fumar crack,\\naí o sol falou,\\n-uiiiuu\\naí o cahorro falou,\\n-também também\\naí o sol e o cachorro foram nadar no rio,\\nFIM.', 'timestamp_created': 1606429437, 'timestamp_updated': 1606429437, 'voted_up': True, 'votes_up': 5, 'votes_funny': 3, 'weighted_vote_score': '0.540426492691040039', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '80441752': {'recommendationid': '80441752', 'author': {'steamid': '76561198449983201', 'num_games_owned': 50, 'num_reviews': 4, 'playtime_forever': 42, 'playtime_last_two_weeks': 0, 'playtime_at_review': 28, 'last_played': 1612313335}, 'language': 'brazilian', 'review': 'compra rapaz, ta esperando oq ?', 'timestamp_created': 1606421905, 'timestamp_updated': 1606421905, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '80413622': {'recommendationid': '80413622', 'author': {'steamid': '76561198258897526', 'num_games_owned': 124, 'num_reviews': 9, 'playtime_forever': 24, 'playtime_last_two_weeks': 0, 'playtime_at_review': 23, 'last_played': 1606416514}, 'language': 'brazilian', 'review': 'Obra de arte', 'timestamp_created': 1606416302, 'timestamp_updated': 1606416302, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '80333601': {'recommendationid': '80333601', 'author': {'steamid': '76561198042794352', 'num_games_owned': 89, 'num_reviews': 3, 'playtime_forever': 180, 'playtime_last_two_weeks': 0, 'playtime_at_review': 180, 'last_played': 1596061027}, 'language': 'brazilian', 'review': 'MAVRAA', 'timestamp_created': 1606402275, 'timestamp_updated': 1606402275, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '80137563': {'recommendationid': '80137563', 'author': {'steamid': '76561198110253908', 'num_games_owned': 152, 'num_reviews': 13, 'playtime_forever': 306, 'playtime_last_two_weeks': 0, 'playtime_at_review': 306, 'last_played': 1606369435}, 'language': 'brazilian', 'review': 'Irado,radical,brutal, só cai uma vez', 'timestamp_created': 1606369553, 'timestamp_updated': 1606369553, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '80118967': {'recommendationid': '80118967', 'author': {'steamid': '76561197963700443', 'num_games_owned': 639, 'num_reviews': 21, 'playtime_forever': 49, 'playtime_last_two_weeks': 0, 'playtime_at_review': 46, 'last_played': 1606365940}, 'language': 'brazilian', 'review': 'bao de mais da conta so', 'timestamp_created': 1606365720, 'timestamp_updated': 1606365720, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': False, 'written_during_early_access': False}, '80094352': {'recommendationid': '80094352', 'author': {'steamid': '76561198081370215', 'num_games_owned': 196, 'num_reviews': 8, 'playtime_forever': 84, 'playtime_last_two_weeks': 0, 'playtime_at_review': 84, 'last_played': 1606360471}, 'language': 'brazilian', 'review': 'Skatemasta Tcheco é um dos melhores jogos de todos os tempos.', 'timestamp_created': 1606360529, 'timestamp_updated': 1606360529, 'voted_up': True, 'votes_up': 1, 'votes_funny': 1, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '80039269': {'recommendationid': '80039269', 'author': {'steamid': '76561199072645900', 'num_games_owned': 2, 'num_reviews': 2, 'playtime_forever': 10, 'playtime_last_two_weeks': 0, 'playtime_at_review': 10, 'last_played': 1600415674}, 'language': 'brazilian', 'review': 'jogo muito bom !', 'timestamp_created': 1606349543, 'timestamp_updated': 1606349543, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '79992618': {'recommendationid': '79992618', 'author': {'steamid': '76561198135290690', 'num_games_owned': 183, 'num_reviews': 14, 'playtime_forever': 58, 'playtime_last_two_weeks': 0, 'playtime_at_review': 57, 'last_played': 1606342703}, 'language': 'brazilian', 'review': 'Lembra das fases de skate do último Tcheco?\\n\\nGostava e jogava mal elas? Eu também!\\n\\nContinua impossível :    )', 'timestamp_created': 1606342339, 'timestamp_updated': 1606342339, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '79954392': {'recommendationid': '79954392', 'author': {'steamid': '76561198012394044', 'num_games_owned': 497, 'num_reviews': 42, 'playtime_forever': 115, 'playtime_last_two_weeks': 0, 'playtime_at_review': 105, 'last_played': 1615919708}, 'language': 'brazilian', 'review': 'esse é top, retro total', 'timestamp_created': 1606338190, 'timestamp_updated': 1606338190, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '79933874': {'recommendationid': '79933874', 'author': {'steamid': '76561197989501315', 'num_games_owned': 665, 'num_reviews': 19, 'playtime_forever': 52, 'playtime_last_two_weeks': 0, 'playtime_at_review': 49, 'last_played': 1624574983}, 'language': 'brazilian', 'review': 'O mito, a lenda Tcheco volta oa mundo dos GEAMS em uma aventura frenética demonstrando todo o domínio no Skate. Um pouco mais amigável que o jogo anterior 9agora tem save entre as fases) mas ainda bastante desafiador e LOTADO de referências. Excelente custo-benefício', 'timestamp_created': 1606336361, 'timestamp_updated': 1606336361, 'voted_up': True, 'votes_up': 5, 'votes_funny': 0, 'weighted_vote_score': '0.571947276592254639', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '79905765': {'recommendationid': '79905765', 'author': {'steamid': '76561198028112914', 'num_games_owned': 443, 'num_reviews': 16, 'playtime_forever': 208, 'playtime_last_two_weeks': 0, 'playtime_at_review': 208, 'last_played': 1606333953}, 'language': 'brazilian', 'review': 'nice', 'timestamp_created': 1606333989, 'timestamp_updated': 1606333989, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '79853484': {'recommendationid': '79853484', 'author': {'steamid': '76561198038308266', 'num_games_owned': 158, 'num_reviews': 5, 'playtime_forever': 151, 'playtime_last_two_weeks': 0, 'playtime_at_review': 149, 'last_played': 1606330266}, 'language': 'brazilian', 'review': 'tcheco é pica pode comprar', 'timestamp_created': 1606330210, 'timestamp_updated': 1606330210, 'voted_up': True, 'votes_up': 3, 'votes_funny': 1, 'weighted_vote_score': '0.544112503528594971', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '79817587': {'recommendationid': '79817587', 'author': {'steamid': '76561198381501505', 'num_games_owned': 142, 'num_reviews': 15, 'playtime_forever': 22, 'playtime_last_two_weeks': 0, 'playtime_at_review': 22, 'last_played': 1606328007}, 'language': 'brazilian', 'review': 'melhor jogo do mundo fodah-se', 'timestamp_created': 1606327981, 'timestamp_updated': 1606327981, 'voted_up': True, 'votes_up': 2, 'votes_funny': 2, 'weighted_vote_score': '0.524401605129241943', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': False, 'written_during_early_access': False}, '78741912': {'recommendationid': '78741912', 'author': {'steamid': '76561198131626260', 'num_games_owned': 29, 'num_reviews': 7, 'playtime_forever': 44, 'playtime_last_two_weeks': 0, 'playtime_at_review': 12, 'last_played': 1630040710}, 'language': 'brazilian', 'review': 'Entrevistador>Tcheco o que você acha do seu jogo? \\nTcheco> Não sei!', 'timestamp_created': 1604545967, 'timestamp_updated': 1604545967, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '78533867': {'recommendationid': '78533867', 'author': {'steamid': '76561198401041219', 'num_games_owned': 189, 'num_reviews': 8, 'playtime_forever': 132, 'playtime_last_two_weeks': 0, 'playtime_at_review': 131, 'last_played': 1627945971}, 'language': 'brazilian', 'review': \"O jogo é divertido e desafiador até o fim, inclusive se você acaba te faltando uma fase a concluir mas deixando o Tcheco com pouca vida, muitas referências hilárias a personagens de outros jogos e ao Brasil também e uma trilha sonora bem amigável e nada enjoativa. Só é uma pena que o jogo acaba sendo curto.\\n\\nComo foi dito no trailer do game, é uma gratificação de baixo custo e sem dúvidas é um 'Brazil's Pride and Joy!'\", 'timestamp_created': 1604245227, 'timestamp_updated': 1604245227, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '76339902': {'recommendationid': '76339902', 'author': {'steamid': '76561198404787779', 'num_games_owned': 70, 'num_reviews': 16, 'playtime_forever': 85, 'playtime_last_two_weeks': 0, 'playtime_at_review': 30, 'last_played': 1625517212}, 'language': 'brazilian', 'review': '- UM SUCESSO\\n-UM ABSURDO\\n-UMA COISA BOUA', 'timestamp_created': 1600707826, 'timestamp_updated': 1606495800, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '75072844': {'recommendationid': '75072844', 'author': {'steamid': '76561198418302241', 'num_games_owned': 117, 'num_reviews': 73, 'playtime_forever': 107, 'playtime_last_two_weeks': 0, 'playtime_at_review': 107, 'last_played': 1589397289}, 'language': 'brazilian', 'review': 'mt legal, vale cada centavo gasto', 'timestamp_created': 1598644667, 'timestamp_updated': 1598644667, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '75032182': {'recommendationid': '75032182', 'author': {'steamid': '76561198334209648', 'num_games_owned': 491, 'num_reviews': 142, 'playtime_forever': 126, 'playtime_last_two_weeks': 0, 'playtime_at_review': 109, 'last_played': 1604252795}, 'language': 'brazilian', 'review': 'É um sucesso\\nÉ um absurdo\\nÉ uma coisa boa\\nÉ uma gratificação instantânea de baixo custo\\n\\nJogo gênial. Tão bom quanto os games indie da gringa. Vlw cada cents. Jogão!', 'timestamp_created': 1598578780, 'timestamp_updated': 1598578866, 'voted_up': True, 'votes_up': 6, 'votes_funny': 0, 'weighted_vote_score': '0.559523820877075195', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '74888884': {'recommendationid': '74888884', 'author': {'steamid': '76561198931845773', 'num_games_owned': 78, 'num_reviews': 23, 'playtime_forever': 316, 'playtime_last_two_weeks': 0, 'playtime_at_review': 314, 'last_played': 1598541741}, 'language': 'brazilian', 'review': 'prefiro o tcheco no castelo do lucio :D', 'timestamp_created': 1598362412, 'timestamp_updated': 1598362412, 'voted_up': False, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.499406516551971436', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': False, 'written_during_early_access': False, 'timestamp_dev_responded': 1599327994, 'developer_response': 'Um dia pretendo fazer a continuação do primeiro jogo, naquele mesmo estilo.'}, '72857276': {'recommendationid': '72857276', 'author': {'steamid': '76561198166398612', 'num_games_owned': 402, 'num_reviews': 15, 'playtime_forever': 13, 'playtime_last_two_weeks': 0, 'playtime_at_review': 13, 'last_played': 1595014913}, 'language': 'brazilian', 'review': 'Nasceu nenê, morreu nenê.', 'timestamp_created': 1595014995, 'timestamp_updated': 1595014995, 'voted_up': True, 'votes_up': 3, 'votes_funny': 0, 'weighted_vote_score': '0.545994043350219727', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '72112314': {'recommendationid': '72112314', 'author': {'steamid': '76561198851948776', 'num_games_owned': 81, 'num_reviews': 59, 'playtime_forever': 353, 'playtime_last_two_weeks': 0, 'playtime_at_review': 23, 'last_played': 1594257785}, 'language': 'brazilian', 'review': 'Jogo mto divertido e engraçado, eu sentia falta de jogos simples assim, que são um ótimo passatempo\\n\\nE ainda tem a Sônica! S2', 'timestamp_created': 1593975373, 'timestamp_updated': 1593975373, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 1, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '71596064': {'recommendationid': '71596064', 'author': {'steamid': '76561198118957425', 'num_games_owned': 157, 'num_reviews': 18, 'playtime_forever': 57, 'playtime_last_two_weeks': 0, 'playtime_at_review': 42, 'last_played': 1593451543}, 'language': 'brazilian', 'review': 'é um sucesso', 'timestamp_created': 1593371496, 'timestamp_updated': 1593371496, 'voted_up': True, 'votes_up': 3, 'votes_funny': 0, 'weighted_vote_score': '0.545994043350219727', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '71522276': {'recommendationid': '71522276', 'author': {'steamid': '76561198130611029', 'num_games_owned': 148, 'num_reviews': 11, 'playtime_forever': 305, 'playtime_last_two_weeks': 0, 'playtime_at_review': 224, 'last_played': 1638745566}, 'language': 'brazilian', 'review': 'Bom\\nSalve São Tcheco\\nViva Tchecolândia', 'timestamp_created': 1593294453, 'timestamp_updated': 1593294453, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 1, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '71187968': {'recommendationid': '71187968', 'author': {'steamid': '76561198120974440', 'num_games_owned': 278, 'num_reviews': 30, 'playtime_forever': 32, 'playtime_last_two_weeks': 0, 'playtime_at_review': 6, 'last_played': 1593052906}, 'language': 'brazilian', 'review': 'A qualidade em que jogos brasileiros estão chegando é impressionante !\\n\\nMeus parabéns ao Marcelo por esta obra !', 'timestamp_created': 1592850245, 'timestamp_updated': 1592850245, 'voted_up': True, 'votes_up': 2, 'votes_funny': 0, 'weighted_vote_score': '0.518678724765777588', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '71112376': {'recommendationid': '71112376', 'author': {'steamid': '76561198057937455', 'num_games_owned': 215, 'num_reviews': 7, 'playtime_forever': 741, 'playtime_last_two_weeks': 0, 'playtime_at_review': 127, 'last_played': 1627516230}, 'language': 'brazilian', 'review': 'PHODDA', 'timestamp_created': 1592719584, 'timestamp_updated': 1592753818, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '70772442': {'recommendationid': '70772442', 'author': {'steamid': '76561198015494055', 'num_games_owned': 91, 'num_reviews': 2, 'playtime_forever': 126, 'playtime_last_two_weeks': 0, 'playtime_at_review': 17, 'last_played': 1592448719}, 'language': 'brazilian', 'review': 'Sempre soube que Pepito, o Cão Bonito, era melhor que o cachorro do Megaman.\\n\\nNão lembro a última vez que dei tanta risada com jogo!', 'timestamp_created': 1592134655, 'timestamp_updated': 1592137500, 'voted_up': True, 'votes_up': 3, 'votes_funny': 0, 'weighted_vote_score': '0.524401605129241943', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '70465081': {'recommendationid': '70465081', 'author': {'steamid': '76561198315042599', 'num_games_owned': 70, 'num_reviews': 5, 'playtime_forever': 201, 'playtime_last_two_weeks': 0, 'playtime_at_review': 187, 'last_played': 1631855940}, 'language': 'brazilian', 'review': 'GOTY!', 'timestamp_created': 1591574266, 'timestamp_updated': 1606369472, 'voted_up': True, 'votes_up': 0, 'votes_funny': 0, 'weighted_vote_score': 0, 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '69741510': {'recommendationid': '69741510', 'author': {'steamid': '76561198030312520', 'num_games_owned': 159, 'num_reviews': 23, 'playtime_forever': 341, 'playtime_last_two_weeks': 0, 'playtime_at_review': 107, 'last_played': 1596414135}, 'language': 'brazilian', 'review': 'Tony Hawk e Chorão são amadores perto do Tcheco, o maior skatista de todo o Brasil!', 'timestamp_created': 1590347076, 'timestamp_updated': 1590347076, 'voted_up': True, 'votes_up': 9, 'votes_funny': 0, 'weighted_vote_score': '0.610164821147918701', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '69690771': {'recommendationid': '69690771', 'author': {'steamid': '76561198039392830', 'num_games_owned': 3278, 'num_reviews': 108, 'playtime_forever': 42, 'playtime_last_two_weeks': 0, 'playtime_at_review': 20, 'last_played': 1593747762}, 'language': 'brazilian', 'review': 'É um sucesso. \\nÉ um absurdo. \\nÉ uma coisa boa. \\nÉ uma gratificação instantânea de baixo custo.', 'timestamp_created': 1590271598, 'timestamp_updated': 1590271598, 'voted_up': True, 'votes_up': 19, 'votes_funny': 6, 'weighted_vote_score': '0.705165624618530273', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '68080229': {'recommendationid': '68080229', 'author': {'steamid': '76561198000705971', 'num_games_owned': 933, 'num_reviews': 111, 'playtime_forever': 106, 'playtime_last_two_weeks': 0, 'playtime_at_review': 14, 'last_played': 1628358908}, 'language': 'brazilian', 'review': 'TEM A ARACY DA TOP THERM COMO BOSS MANÉ. TA DOIDO? VTNK JOGO EXCELENTE!\\n\\nPURA MAESTRIA DO MARCELÃO!', 'timestamp_created': 1587933179, 'timestamp_updated': 1587933179, 'voted_up': True, 'votes_up': 12, 'votes_funny': 1, 'weighted_vote_score': '0.642268717288970947', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': False, 'written_during_early_access': False}, '67531256': {'recommendationid': '67531256', 'author': {'steamid': '76561198148693741', 'num_games_owned': 420, 'num_reviews': 44, 'playtime_forever': 10, 'playtime_last_two_weeks': 0, 'playtime_at_review': 10, 'last_played': 1584988723}, 'language': 'brazilian', 'review': 'Pessoal querendo Half Life 3, Team Fortress 4 e essas coisas, mas na verdade esse era a continuação mais aguardada do mundo.\\n10000/10', 'timestamp_created': 1587175302, 'timestamp_updated': 1606424065, 'voted_up': True, 'votes_up': 4, 'votes_funny': 0, 'weighted_vote_score': '0.421945244073867798', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '66989442': {'recommendationid': '66989442', 'author': {'steamid': '76561198828718515', 'num_games_owned': 74, 'num_reviews': 5, 'playtime_forever': 546, 'playtime_last_two_weeks': 0, 'playtime_at_review': 224, 'last_played': 1644533844}, 'language': 'brazilian', 'review': 'top', 'timestamp_created': 1586476358, 'timestamp_updated': 1586476358, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '65528494': {'recommendationid': '65528494', 'author': {'steamid': '76561198870172539', 'num_games_owned': 161, 'num_reviews': 25, 'playtime_forever': 110, 'playtime_last_two_weeks': 0, 'playtime_at_review': 24, 'last_played': 1639541976}, 'language': 'brazilian', 'review': 'Que Jogo íncrivel! Puta que pariu', 'timestamp_created': 1584856458, 'timestamp_updated': 1584856458, 'voted_up': True, 'votes_up': 2, 'votes_funny': 0, 'weighted_vote_score': '0.524401605129241943', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': False, 'written_during_early_access': False}, '65373973': {'recommendationid': '65373973', 'author': {'steamid': '76561198262034306', 'num_games_owned': 197, 'num_reviews': 5, 'playtime_forever': 109, 'playtime_last_two_weeks': 0, 'playtime_at_review': 86, 'last_played': 1584682950}, 'language': 'brazilian', 'review': 'Bem difícil. Vai “nascer neném, morrer neném” muito até zerar esse jogo.\\nO humor e as piadinhas desse jogo são sensacionais kkkkkk\\n', 'timestamp_created': 1584680727, 'timestamp_updated': 1584680727, 'voted_up': True, 'votes_up': 2, 'votes_funny': 0, 'weighted_vote_score': '0.524401605129241943', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': False, 'written_during_early_access': False}, '65283053': {'recommendationid': '65283053', 'author': {'steamid': '76561197985993195', 'num_games_owned': 1588, 'num_reviews': 69, 'playtime_forever': 185, 'playtime_last_two_weeks': 0, 'playtime_at_review': 185, 'last_played': 1582324076}, 'language': 'brazilian', 'review': 'Melhor jogo BR\\nhttps://www.youtube.com/watch?v=AMAbfo21to8', 'timestamp_created': 1584556027, 'timestamp_updated': 1584556027, 'voted_up': True, 'votes_up': 4, 'votes_funny': 1, 'weighted_vote_score': '0.538015782833099365', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': True, 'written_during_early_access': False}, '64478005': {'recommendationid': '64478005', 'author': {'steamid': '76561198982102846', 'num_games_owned': 273, 'num_reviews': 8, 'playtime_forever': 99, 'playtime_last_two_weeks': 0, 'playtime_at_review': 99, 'last_played': 1583283559}, 'language': 'brazilian', 'review': 'Me surpreendi com este jogo BRASILEIRO, vale a pena por cada referência e é bem divertido.', 'timestamp_created': 1583284069, 'timestamp_updated': 1583284069, 'voted_up': True, 'votes_up': 15, 'votes_funny': 0, 'weighted_vote_score': '0.67765122652053833', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': True, 'written_during_early_access': False}, '64252392': {'recommendationid': '64252392', 'author': {'steamid': '76561198200340947', 'num_games_owned': 55, 'num_reviews': 4, 'playtime_forever': 735, 'playtime_last_two_weeks': 0, 'playtime_at_review': 735, 'last_played': 1582677689}, 'language': 'brazilian', 'review': 'Estilo 8 bits com muita Zuera e altas referencias aos games retrô. \\no jogo tem dificuldade Kaizo.\\nvale o preço e vale a Jogatina\\nvocê vai se tornar fã do Theco \\nprepara o suco de maracujá que a jogatina vai ser insana kkkk.', 'timestamp_created': 1582908452, 'timestamp_updated': 1582908452, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': False, 'written_during_early_access': False}, '64148720': {'recommendationid': '64148720', 'author': {'steamid': '76561198072763687', 'num_games_owned': 21, 'num_reviews': 18, 'playtime_forever': 396, 'playtime_last_two_weeks': 0, 'playtime_at_review': 14, 'last_played': 1583896008}, 'language': 'brazilian', 'review': 'É um jogo que todas as crianças pequenas de menor devem jogar!', 'timestamp_created': 1582725835, 'timestamp_updated': 1613931245, 'voted_up': True, 'votes_up': 2, 'votes_funny': 1, 'weighted_vote_score': '0.524401605129241943', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': False, 'written_during_early_access': False}, '63902166': {'recommendationid': '63902166', 'author': {'steamid': '76561198326873422', 'num_games_owned': 490, 'num_reviews': 24, 'playtime_forever': 99, 'playtime_last_two_weeks': 0, 'playtime_at_review': 68, 'last_played': 1632690070}, 'language': 'brazilian', 'review': 'Resumindo em apenas uma palavra: GOTY 2020!', 'timestamp_created': 1582331661, 'timestamp_updated': 1606387261, 'voted_up': True, 'votes_up': 11, 'votes_funny': 0, 'weighted_vote_score': '0.634990036487579346', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '63622149': {'recommendationid': '63622149', 'author': {'steamid': '76561198845523008', 'num_games_owned': 154, 'num_reviews': 31, 'playtime_forever': 129, 'playtime_last_two_weeks': 0, 'playtime_at_review': 127, 'last_played': 1583884778}, 'language': 'brazilian', 'review': 'Mt brave, mais tryhard que o seu antecessor, com mundinhos mas eu quero saber sobre o Taxaceiro, o que aconteceu, Nego Ney matou ele????? EIS QUE LETO', 'timestamp_created': 1581871439, 'timestamp_updated': 1581871439, 'voted_up': True, 'votes_up': 4, 'votes_funny': 0, 'weighted_vote_score': '0.545994043350219727', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False, 'timestamp_dev_responded': 1581890077, 'developer_response': 'calma'}, '63506876': {'recommendationid': '63506876', 'author': {'steamid': '76561198046544489', 'num_games_owned': 154, 'num_reviews': 1, 'playtime_forever': 478, 'playtime_last_two_weeks': 0, 'playtime_at_review': 454, 'last_played': 1633916950}, 'language': 'brazilian', 'review': 'Tcheco, meu querido Tcheco. \\nPersonagem icônico do folclore Rio Grandense. Orgulho Nacional. \\nUm dos jogos mais aguardados em 2020 por mim. \\nVocê que busca motivos pra comprar, leve em consideração que não há a mais remota possibilidade de um jogo do Tcheco decepcionar. \\nAlém de que não deve ter lugar no Brasil que uma passagem de ônibus custe isso ou menos. E mesmo se custasse, quando que um dia na história desse mundo valeu a pena ir lá fora? Com Skatemasta instalado no meu microcomputador eu é que não quero saber de pegar sol nunca mais.\\n\\nJogue jogos Tcheco!\\nGostoso demais', 'timestamp_created': 1581712669, 'timestamp_updated': 1581712669, 'voted_up': True, 'votes_up': 5, 'votes_funny': 0, 'weighted_vote_score': '0.545994043350219727', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '63460262': {'recommendationid': '63460262', 'author': {'steamid': '76561198205712051', 'num_games_owned': 707, 'num_reviews': 30, 'playtime_forever': 198, 'playtime_last_two_weeks': 1, 'playtime_at_review': 100, 'last_played': 1646962123}, 'language': 'brazilian', 'review': 'Alem de ser totalmente diferente do primeiro jogo, deveria ser considerado um Souls Like.\\n~ ❤️', 'timestamp_created': 1581641661, 'timestamp_updated': 1600826428, 'voted_up': True, 'votes_up': 7, 'votes_funny': 1, 'weighted_vote_score': '0.540717244148254395', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': True, 'written_during_early_access': False}, '63399204': {'recommendationid': '63399204', 'author': {'steamid': '76561198003019731', 'num_games_owned': 1629, 'num_reviews': 299, 'playtime_forever': 7, 'playtime_last_two_weeks': 0, 'playtime_at_review': 7, 'last_played': 1580527695}, 'language': 'brazilian', 'review': 'Quando Tcheco in the Castle of Lucio foi lançado em 2015, foi celebrado merecidamente como o grande feito de Marcelo Barbosa, um desenvolvedor independente com um grande talento para a sátira e para o desenho e com uma grande paixão para os jogos eletrônicos, mas sem experiência na área. Os poucos recursos do jogo faziam parte de sua mítica \"naif\" e o título disfarçava suas limitações técnicas com um banho de nostalgia e compensava com dez vezes mais simpatia que jogos de grandes equipes.\\n\\nConsiderando-se os anos necessários para concretizar aquele jogo, teria Barbosa fôlego para tentar de novo? A resposta é Skatemasta Tcheco, a prova viva de que um raio pode e deve cair duas vezes no mesmo lugar.\\n\\n[h1]Só os Loucos Sabem[/h1]\\n\\nSe o jogo anterior era uma coleção de 65 mini-jogos costurados pela fino fio da insanidade em um castelo onde nada fazia sentido, desta vez nosso protagonista está de volta em outro mundo estranho, mas desta vez melhor costurado. O nome entrega: Skatemasta Tcheco coloca o personagem principal em cima de um skate em uma jogabilidade arcade de plataforma. O jogador não precisa gastar tempo tentando entender os desafios de cada tela, como era antes, é só incorporar seu Tony Hawk interior e deixar as rodas te levarem.\\n\\nNesse ponto, pode-se dizer que Barbosa trocou a anarquia do primeiro jogo por uma jogabilidade mais coesa, familiar até. Por conta disso, houve uma redução no grau de dificuldade, evidenciada na curva suave de desafio entre os mundos de Skatemasta Tcheco. Ao contrário do padrão de outros jogos similares, aqui o desenvolvedor libera acesso imediato a todos os mapas (ou à maioria deles, talvez haja níveis secretos). Então, se você quiser partir logo para cenários mais tensos, a decisão é sua.\\n\\nBarbosa também é bastante caridoso com o número de vidas disponíveis desde o início, com kits médicos bem distribuídos pelos mapas.\\n\\nEssa nova abordagem não significa que Skatemasta Tcheco não tenha atrativos para os jogadores hardcore. Executar os movimentos com precisão e memorizar os padrões de inimigos e obstáculos que vão aparecendo continuam sendo a chave do sucesso e a diferença entre a tela de Game Over (\"Nasceu nenê, morreu nenê\") e o triunfo. Entretanto, novamente, há uma \"mordomia\" aqui que não havia no Castelo do Lúcio: é possível salvar seu progresso a cada mapa completado.\\n\\nPara quem se importa com pontuação, o jogo registra seu recorde. Porém, não há um ranking global online. E, mesmo em relação a si mesmo, é possível \"trapacear\": níveis mais complexos rendem mais pontos, mesmo que você sobreviva por poucos minutos neles. O ideal, nesse caso, seria uma pontuação separada para cada nível.\\n\\nÉ importante também não confundir coesão com perda do jeito pirado que sempre caracterizou o universo de Tcheco. Ainda há referências bizarras ao longo do jogo, assim como elementos que ou são piadas internas obscuras ou fenômenos aleatórios exclusivos da mente de Barbosa, como bailarinas rodopiantes surgindo de lugar nenhum, um homem-mão saltitante, um tiozão vampiro chamado Seu Almeida e a onipresente ajudante cadela-cibernética Pepita com uma mola nas costas.\\n\\n[h1]Se Não Eu, Quem Vai Fazer Você Feliz?[/h1]\\n\\nO mundo de Tcheco in the Castle of Lucio era fulgurante e alegre de tão exótico, mas o pobre Tcheco sempre aparecia cabisbaixo, certamente incomodado por estar prisioneiro. Desta vez, o nosso herói é bicho solto, a céu aberto e praticamente abre um sorrisão em todas as telas, enquanto desvia de ameaças, coleta dinheiro e atravessa os cenários mais inesperados.\\n\\nBarbosa mantém a lógica urbana do skate, com inclinações e tudo, somente no primeiro mapa. Depois disso, está liberada de novo a bagunça e nosso skatista vidaloka vai passar por um parque de diversões, um shopping center, uma praia com areia e tudo, a superfície da Lua e até mesmo a chegada de Papai Noel em um estádio. Essa tradição natalina esquecida das grandes metrópoles aqui é mais um playground para Tcheco e uma boa desculpa para colocar o personagem vestido de acordo.\\n\\nAlém de juntar dinheiro para pagar o save no final do mapa, Tcheco também precisa coletar letras em seu passeio de skate. Reunidas, essas letras dão a dica para a pessoa para quem ele vai telefonar para pedir uma ajuda para a batalha com o boss da fase. É nesse momento que entram os convidados especiais de Skatemasta Tcheco, como Mavra, heroína de Blazing Chrome, ou Dandy, de Dandy & Randy, para combater inimigos como o meme Sônica. É uma festa de arromba e muita gente ainda pode chegar. Barbosa é querido por todos e sua casa está de portas abertas.\\n\\n[h1]Eu Vou Fazer De Um Jeito Que Ela Não Vai Esquecer[/h1]\\n\\nSkatemasta Tcheco não mexe um pixel no estilo visual do jogo anterior e isso é bom. O mundo de Tcheco é 2D, é retrô, tem linhas de televisão velha, tem traços simples. É um retrato Polaroid da era NES, uma era que permanece viva no coração de marmanjos e ainda consegue cativar a molecada.\\n\\nTecnicamente falando, tem alguma marotagem em cena: apertar F12 não ativa a captura de tela do Steam, mas o debugador do navegador. Seria Skatemasta Tcheco um jogo em Flash rodando em um navegador Chrome encapsulado? Estamos aqui diante de uma gambiarra tecnológica, outra demonstração do espírito \"do it yourself\" de Barbosa, mais um detalhe punk da trajetória de uma franquia que ninguém segura mais.\\n\\nA trilha sonora é o glacê do bolo, mais uma camada de nostalgia que nos leva para outros tempos e o casamento perfeito para seu gráfico charmosamente ultrapassado. Efeitos sonoros propositalmente toscos e surpreendentes completam a experiência.\\n\\nSkatemasta Tcheco termina sendo uma palpável evolução do que foi visto antes. Não uma revolução, ou não seria outro jogo do Tcheco, mas uma caminhada (de skate) em direção a um jogo melhor elaborado, mais coeso, mas não menos simpático ou imprevisível.\\n\\nPublicado originalmente em: [url=https://www.gamerview.com.br/reviews/skatemasta-tcheco]https://www.gamerview.com.br/reviews/skatemasta-tcheco[/url]', 'timestamp_created': 1581531157, 'timestamp_updated': 1581531157, 'voted_up': True, 'votes_up': 35, 'votes_funny': 1, 'weighted_vote_score': '0.78114241361618042', 'comment_count': 3, 'steam_purchase': False, 'received_for_free': True, 'written_during_early_access': False}, '63185540': {'recommendationid': '63185540', 'author': {'steamid': '76561197969421157', 'num_games_owned': 481, 'num_reviews': 12, 'playtime_forever': 376, 'playtime_last_two_weeks': 0, 'playtime_at_review': 117, 'last_played': 1610385781}, 'language': 'brazilian', 'review': 'Pontos Fortes:\\n-Pra quem gosta de viver radicalmente\\n-Fechando com mais de um milhão de pontos e sem save você aprende a andar de skate na vida real\\n-Uma acurada representação quase história do sul do Brasil\\n\\nPontos Fracos:\\n-Estragou a graça de 2020 entregando o GOTY tão cedo no ano\\n-O final do jogo pode acabar emocionando demais corações mais fracos\\n-Choca a população ao perceber que seu preço não compra nem uma coxinha atualmente', 'timestamp_created': 1581201817, 'timestamp_updated': 1581201817, 'voted_up': True, 'votes_up': 5, 'votes_funny': 5, 'weighted_vote_score': '0.543891191482543945', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': False, 'written_during_early_access': False}, '62939555': {'recommendationid': '62939555', 'author': {'steamid': '76561198193828699', 'num_games_owned': 21, 'num_reviews': 6, 'playtime_forever': 420, 'playtime_last_two_weeks': 0, 'playtime_at_review': 18, 'last_played': 1631892517}, 'language': 'brazilian', 'review': 'Divertido, engraçado, brasileiro, roda em qualquer máquina e baratinho!\\nLindo, cara! Parabéns!', 'timestamp_created': 1580784540, 'timestamp_updated': 1580784540, 'voted_up': True, 'votes_up': 8, 'votes_funny': 0, 'weighted_vote_score': '0.562544643878936768', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': False, 'written_during_early_access': False}, '62929576': {'recommendationid': '62929576', 'author': {'steamid': '76561198908852827', 'num_games_owned': 117, 'num_reviews': 5, 'playtime_forever': 280, 'playtime_last_two_weeks': 0, 'playtime_at_review': 235, 'last_played': 1628858656}, 'language': 'brazilian', 'review': 'esse jogo é tão parecido com um jogo de nes que se fizessem  uma fita e vendessem ninguém ia acredita que é de pc\\n\\n\\n\\n\\n\\nnota(9/10)', 'timestamp_created': 1580763066, 'timestamp_updated': 1580763066, 'voted_up': True, 'votes_up': 5, 'votes_funny': 0, 'weighted_vote_score': '0.520601570606231689', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '62905676': {'recommendationid': '62905676', 'author': {'steamid': '76561198093123271', 'num_games_owned': 174, 'num_reviews': 2, 'playtime_forever': 2960, 'playtime_last_two_weeks': 0, 'playtime_at_review': 763, 'last_played': 1600416683}, 'language': 'brazilian', 'review': 'Menino aventura, orgulho do Brasil!\\nDo penhasco? Cai. Do skate? Jamais.', 'timestamp_created': 1580724314, 'timestamp_updated': 1580724314, 'voted_up': True, 'votes_up': 9, 'votes_funny': 0, 'weighted_vote_score': '0.576205074787139893', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': False, 'written_during_early_access': False}, '62775709': {'recommendationid': '62775709', 'author': {'steamid': '76561198119704724', 'num_games_owned': 155, 'num_reviews': 36, 'playtime_forever': 458, 'playtime_last_two_weeks': 0, 'playtime_at_review': 200, 'last_played': 1626905056}, 'language': 'brazilian', 'review': '[h1]Skatemasta chegou com tudo! :D[/h1]\\n\\nTcheco agora anda por aí  de skate e coleta saquinhos de dinheiro enquanto derruba alguns inimigos no caminho - em cenários bem aleatórios e recheados de referências ao mundo gamer (e outras que somente os brasileiros vão identificar - [spoiler]como a loja \"JequiTcheco\" na fase do Xop Cents, haha)[/spoiler]. A \"Chegada do Papai Noel\" é uma das fases mais geniais do jogo, repleta de elementos que vão deixar o jogador cada vez mais curioso em identificar as referências :)\\n\\nDestaque para a jogabilidade e as mecânicas desafiadoras (por exemplo, plataformas que desaparecem quando pisamos nelas e outras que só aparecem quando estamos prestes a cair) - tem que ter os reflexos bem rápidos, [b]senão o Tcheco cai[/b], haha. \\n\\nÉ o tipo de jogo que você treina pra melhorar os recordes e isso aumenta muito o fator replay. Os gráficos, sons, jogabilidade... ficou tudo muito bem refinado :) dá pra ver esse nível de refinamento no cenário: na fase \"Litoral Gaúcho\", lá no fundo aparece um avião carregando uma faixa pelo céu, bem típico das praias brasileiras :) muito genial. Esses elementos que dão identidade a cada fase, os inimigos, as mecânicas pra pegar os itens e escapar das armadilhas... tudo ficou muito bem encaixado e divertido. Além disso, há um equilíbrio de dificuldade entre as fases - dá pra começar por uma mais fácil (de menos estrelas) e depois ir pegando a manha pra encarar as fases mais difíceis (com mais estrelas), haha :)\\n\\nSkatemasta chegou com tudo e você vai precisar usar todas as suas habilidades pra fazer a maior pontuação sem perder vidas - [b]porque SIM, as fases são repletas de inimigos e armadilhas que querem te derrubar o tempo todo[/b], haha. E aí, vai encarar o desafio? ;)\\n\\n[h1]VAAAAAAAAAAAAAAI, TCHECOOOO!!![/h1]', 'timestamp_created': 1580539301, 'timestamp_updated': 1580539456, 'voted_up': True, 'votes_up': 8, 'votes_funny': 0, 'weighted_vote_score': '0.545994043350219727', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': False, 'written_during_early_access': False}, '62749207': {'recommendationid': '62749207', 'author': {'steamid': '76561198061604773', 'num_games_owned': 3090, 'num_reviews': 187, 'playtime_forever': 343, 'playtime_last_two_weeks': 0, 'playtime_at_review': 7, 'last_played': 1580853452}, 'language': 'brazilian', 'review': '\"Eu não cai nenhuma vez\" 😎', 'timestamp_created': 1580494786, 'timestamp_updated': 1580494786, 'voted_up': True, 'votes_up': 45, 'votes_funny': 19, 'weighted_vote_score': '0.759667754173278809', 'comment_count': 1, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '62738160': {'recommendationid': '62738160', 'author': {'steamid': '76561198015510683', 'num_games_owned': 166, 'num_reviews': 17, 'playtime_forever': 29, 'playtime_last_two_weeks': 0, 'playtime_at_review': 8, 'last_played': 1581592436}, 'language': 'brazilian', 'review': 'Grande jogo sobre um menino que dá uns rolê de skate. Engraçado, divertido, controles precisos. Enfim, vale muito a pena!', 'timestamp_created': 1580480294, 'timestamp_updated': 1580480294, 'voted_up': True, 'votes_up': 10, 'votes_funny': 1, 'weighted_vote_score': '0.55473637580871582', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}, '62737358': {'recommendationid': '62737358', 'author': {'steamid': '76561198065200200', 'num_games_owned': 334, 'num_reviews': 163, 'playtime_forever': 209, 'playtime_last_two_weeks': 0, 'playtime_at_review': 31, 'last_played': 1581642590}, 'language': 'brazilian', 'review': 'Divertido, bem feito e cheio de referências BR! Skatemasta Tcheco é ainda melhor que seu antecessor, mais engraçado e com uma gameplay muito mais fluida! Vale cada centavo, extremamente recomendado!', 'timestamp_created': 1580479288, 'timestamp_updated': 1580479288, 'voted_up': True, 'votes_up': 11, 'votes_funny': 0, 'weighted_vote_score': '0.5957183837890625', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}}), ('query_summary', {'num_reviews': 73, 'review_score': 8, 'review_score_desc': 'Very Positive', 'total_positive': 72, 'total_negative': 1, 'total_reviews': 73})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extrair apenas os reviews corretamente\n",
        "reviews = dados['reviews']  # Acessa o dicionário de reviews\n",
        "exemplo_reviews = list(reviews.values())[:2]  # Pega os dois primeiros comentários\n",
        "print(f\"🔍 Exemplo de dados: {exemplo_reviews}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0NS83Jl6QKd",
        "outputId": "aa6dbf88-dc21-4f72-b3cb-e8e305d77150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Exemplo de dados: [{'recommendationid': '106208136', 'author': {'steamid': '76561198278381555', 'num_games_owned': 218, 'num_reviews': 27, 'playtime_forever': 397, 'playtime_last_two_weeks': 0, 'playtime_at_review': 397, 'last_played': 1625863019}, 'language': 'brazilian', 'review': 'Fodda.', 'timestamp_created': 1640050749, 'timestamp_updated': 1640050749, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': False, 'received_for_free': False, 'written_during_early_access': False}, {'recommendationid': '104230164', 'author': {'steamid': '76561198424678766', 'num_games_owned': 73, 'num_reviews': 14, 'playtime_forever': 28, 'playtime_last_two_weeks': 0, 'playtime_at_review': 20, 'last_played': 1639332609}, 'language': 'brazilian', 'review': 'agora eu sei como andar de skate', 'timestamp_created': 1637972262, 'timestamp_updated': 1637972262, 'voted_up': True, 'votes_up': 1, 'votes_funny': 0, 'weighted_vote_score': '0.500652730464935303', 'comment_count': 0, 'steam_purchase': True, 'received_for_free': False, 'written_during_early_access': False}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extrair apenas os textos dos comentários\n",
        "comentarios = [review[\"review\"] for review in reviews.values()]\n",
        "\n",
        "# Exibir alguns exemplos\n",
        "print(f\"🔍 Exemplo de comentários: {comentarios[:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eEp1lSO7feg",
        "outputId": "3d41cabf-fe13-44f7-aa67-126d2e4fce82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Exemplo de comentários: ['Fodda.', 'agora eu sei como andar de skate', 'jogo pica tipo tony hawk, só que melho \\n⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⢀⡀⣼⣵⣽⣿⠄⡂⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⣴⣷⣿⣿⣿⣿⣷⣷⣷⣴⢠⣄⠄⢠⠄⠄⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⣬⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣷⣾⣷⣄⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⠃⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠛⠛⠛⠛⠛⠛⠿⣿⣿⣿⣿⢿⠛⣉⣥⣤⣀⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⢀⣤⡴⠶⠶⠶⢶⣿⣿⣿⣿⠛⢛⠛⠛⡉⠛⠄⠄⠄ ⠄⠄⠄⡀⠄⠄⠄⠄⠄⣴⣿⣡⣤⣤⣥⣿⣤⣢⠉⣿⣿⠄⣶⣶⣶⣶⣦⣦⡄⠄ ⠄⠄⠄⢋⣀⠄⠄⠄⠄⣿⣿⣿⣿⣿⣿⣿⣿⣿⣷⣿⣿⠄⣿⣿⣿⣿⣿⣿⡏⠄ ⠄⠄⠄⠈⢿⣆⠄⠄⠄⢻⣿⣿⣿⣿⣿⣿⣿⠿⠛⣿⣿⣦⡘⣿⣿⣿⣿⣿⠃⠄ ⠄⠄⠄⠄⠈⢻⣷⠄⠄⠈⣿⣿⣿⣿⣿⣿⣿⢼⣿⠿⣿⣿⣟⣽⣿⣿⣿⡟⠄⠄ ⣷⡄⠄⠄⠄⠄⠉⠄⠄⠄⣶⣿⣿⣿⣿⣿⣿⣿⣾⣿⣶⣿⣿⣿⣿⣿⣿⡇⡄⠄ ⠛⠁⠄⠄⠄⠄⠄⠄⠄⠄⠻⣿⣿⣿⣿⡛⠛⢛⣛⣟⣟⣻⣯⠍⢩⣿⣿⡏⠄⠄ ⠄⠄⠄⢠⢠⠄⠂⠄⠄⠄⠄⠙⢿⣿⣿⣿⣧⣌⣨⣯⣿⣯⠄⣤⣿⣿⡟⠃⠄⠄ ⠄⠄⠄⠋⠘⠄⠄⠄⠄⠄⠄⠄⠄⠻⣿⣿⣿⣿⣿⣿⣛⣿⣿⣿⣿⡟⠄⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠠⠄⠄⠄⠈⠿⠿⠿⠿⠿⠿⠿⠿⠿⠿⠄⠄⠄⠄⠄', 'muito mais fodastico que o primeiro', 'Jogoé um pouco difícil, mas é engraçado. Bingo clandestino é de lascar']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pré-processamento"
      ],
      "metadata": {
        "id": "VKE--L398VBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RSLPStemmer\n",
        "import string\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "stopwords_pt = set(stopwords.words('portuguese'))\n",
        "stemmer = RSLPStemmer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Aplica pré-processamento no texto: limpeza, remoção de stopwords e stemming.\"\"\"\n",
        "    # Remover pontuação e números\n",
        "    text = ''.join([char.lower() for char in text if char not in string.punctuation and not char.isdigit()])\n",
        "\n",
        "    # Tokenizar texto\n",
        "    tokens = nltk.word_tokenize(text, language='portuguese')\n",
        "\n",
        "    # Remover stopwords e aplicar stemming\n",
        "    tokens = [stemmer.stem(word) for word in tokens if word not in stopwords_pt]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Caminho dos arquivos\n",
        "caminho_dados = \"/content/drive/MyDrive/TCC/Dados/Reviews Da Steam filtradas/Action\"\n",
        "\n",
        "# Lista para armazenar os comentários pré-processados\n",
        "comentarios_processados = []\n",
        "\n",
        "# Processar cada arquivo JSON dentro do diretório escolhido\n",
        "for arquivo in os.listdir(caminho_dados):\n",
        "    if arquivo.endswith(\".json\"):\n",
        "        with open(os.path.join(caminho_dados, arquivo), \"r\", encoding=\"utf-8\") as f:\n",
        "            dados = json.load(f)\n",
        "\n",
        "            # Extraindo apenas os comentários\n",
        "            for review in dados.get('reviews', {}).values():\n",
        "                texto_processado = preprocess_text(review.get('review', ''))\n",
        "                comentarios_processados.append(texto_processado)\n",
        "\n",
        "# Exibir exemplos dos comentários processados\n",
        "print(\"🔍 Exemplos de comentários processados:\")\n",
        "print(comentarios_processados[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suvWTVo_8YIl",
        "outputId": "8c51ff76-11d9-47c1-90ad-c40f5425ea85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Exemplos de comentários processados:\n",
            "['fodd', 'agor sei and skat', 'jog pic tip tony hawk melh ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⢀⡀⣼⣵⣽⣿⠄⡂⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⣴⣷⣿⣿⣿⣿⣷⣷⣷⣴⢠⣄⠄⢠⠄⠄⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⣬⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣷⣾⣷⣄⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⠃⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠛⠛⠛⠛⠛⠛⠿⣿⣿⣿⣿⢿⠛⣉⣥⣤⣀⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⢀⣤⡴⠶⠶⠶⢶⣿⣿⣿⣿⠛⢛⠛⠛⡉⠛⠄⠄⠄ ⠄⠄⠄⡀⠄⠄⠄⠄⠄⣴⣿⣡⣤⣤⣥⣿⣤⣢⠉⣿⣿⠄⣶⣶⣶⣶⣦⣦⡄⠄ ⠄⠄⠄⢋⣀⠄⠄⠄⠄⣿⣿⣿⣿⣿⣿⣿⣿⣿⣷⣿⣿⠄⣿⣿⣿⣿⣿⣿⡏⠄ ⠄⠄⠄⠈⢿⣆⠄⠄⠄⢻⣿⣿⣿⣿⣿⣿⣿⠿⠛⣿⣿⣦⡘⣿⣿⣿⣿⣿⠃⠄ ⠄⠄⠄⠄⠈⢻⣷⠄⠄⠈⣿⣿⣿⣿⣿⣿⣿⢼⣿⠿⣿⣿⣟⣽⣿⣿⣿⡟⠄⠄ ⣷⡄⠄⠄⠄⠄⠉⠄⠄⠄⣶⣿⣿⣿⣿⣿⣿⣿⣾⣿⣶⣿⣿⣿⣿⣿⣿⡇⡄⠄ ⠛⠁⠄⠄⠄⠄⠄⠄⠄⠄⠻⣿⣿⣿⣿⡛⠛⢛⣛⣟⣟⣻⣯⠍⢩⣿⣿⡏⠄⠄ ⠄⠄⠄⢠⢠⠄⠂⠄⠄⠄⠄⠙⢿⣿⣿⣿⣧⣌⣨⣯⣿⣯⠄⣤⣿⣿⡟⠃⠄⠄ ⠄⠄⠄⠋⠘⠄⠄⠄⠄⠄⠄⠄⠄⠻⣿⣿⣿⣿⣿⣿⣛⣿⣿⣿⣿⡟⠄⠄⠄⠄ ⠄⠄⠄⠄⠄⠄⠄⠄⠄⠄⠠⠄⠄⠄⠈⠿⠿⠿⠿⠿⠿⠿⠿⠿⠿⠄⠄⠄⠄⠄', 'fodas prim', 'jogoé pouc difícil engraç bing clandestin lasc']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "# Baixar pacotes do NLTK (caso ainda não tenha baixado)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Definir stopwords em português\n",
        "stopwords_pt = set(stopwords.words('portuguese'))\n",
        "stemmer = RSLPStemmer()\n",
        "\n",
        "def limpar_texto(texto):\n",
        "    # Normalizar para remover acentos\n",
        "    texto = unicodedata.normalize(\"NFKD\", texto).encode(\"ascii\", \"ignore\").decode(\"utf-8\", \"ignore\")\n",
        "\n",
        "    # Remover arte ASCII e caracteres não alfabéticos (exceto espaços)\n",
        "    texto = re.sub(r'[^a-zA-Z\\s]', '', texto)\n",
        "\n",
        "    # Tokenizar o texto\n",
        "    tokens = word_tokenize(texto.lower())\n",
        "\n",
        "    # Remover stopwords e aplicar stemming\n",
        "    tokens = [stemmer.stem(word) for word in tokens if word not in stopwords_pt]\n",
        "\n",
        "    # Reunir tokens em uma string novamente\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Exemplo de aplicação no dataset\n",
        "comentarios_processados = [limpar_texto(comentario) for comentario in comentarios]\n",
        "\n",
        "# Visualizar os primeiros comentários processados\n",
        "print(\"🔍 Exemplos de comentários processados:\")\n",
        "print(comentarios_processados[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFWv3dYHAhtg",
        "outputId": "f29d55f9-c6c4-4aed-c941-21fa650e445c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Exemplos de comentários processados:\n",
            "['fodd', 'agor sei and skat', 'jog pic tip tony hawk so melh', 'fodas prim', 'jogo pouc dificil engrac bing clandestin lasc']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Baixar pacotes necessários do NLTK\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Definir stopwords em português\n",
        "stopwords_pt = set(stopwords.words('portuguese'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def limpar_texto(texto):\n",
        "    # Normalizar para remover acentos\n",
        "    texto = unicodedata.normalize(\"NFKD\", texto).encode(\"ascii\", \"ignore\").decode(\"utf-8\", \"ignore\")\n",
        "\n",
        "    # Remover caracteres especiais e manter apenas letras e espaços\n",
        "    texto = re.sub(r'[^a-zA-Z\\s]', '', texto)\n",
        "\n",
        "    # Tokenizar o texto\n",
        "    tokens = word_tokenize(texto.lower())\n",
        "\n",
        "    # Remover stopwords e aplicar lematização (em vez de stemming)\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stopwords_pt and len(word) > 2]\n",
        "\n",
        "    # Reunir tokens em uma string novamente\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Aplicar nos comentários\n",
        "comentarios_processados = [limpar_texto(comentario) for comentario in comentarios]\n",
        "\n",
        "# Visualizar os primeiros comentários processados\n",
        "print(\"🔍 Exemplos de comentários processados:\")\n",
        "print(comentarios_processados[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fDS6Yj16MTH",
        "outputId": "8e1ff8a0-0247-4043-f6cd-5c74a4142a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Exemplos de comentários processados:\n",
            "['fodda', 'agora sei andar skate', 'jogo pica tipo tony hawk melho', 'fodastico primeiro', 'jogoe pouco dificil engracado bingo clandestino lascar']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def limpar_texto(texto):\n",
        "    # Normalizar para remover acentos\n",
        "    texto = unicodedata.normalize(\"NFKD\", texto).encode(\"ascii\", \"ignore\").decode(\"utf-8\", \"ignore\")\n",
        "\n",
        "    # Remover caracteres especiais e manter apenas letras e espaços\n",
        "    texto = re.sub(r'[^a-zA-Z\\s]', '', texto)\n",
        "\n",
        "    # Tokenizar o texto\n",
        "    tokens = word_tokenize(texto.lower())\n",
        "\n",
        "    # Remover stopwords e aplicar lematização\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stopwords_pt and len(word) > 2]\n",
        "\n",
        "    # Remover palavras repetidas grudadas (ex: \"jogoe\" → \"jogo\")\n",
        "    tokens = [word for word in tokens if not any(c.isdigit() for c in word)]  # Remove palavras com números (se houver)\n",
        "\n",
        "    # Reunir tokens em uma string novamente e garantir espaçamento correto\n",
        "    return \" \".join(tokens).strip()\n",
        "\n",
        "# Aplicar nos comentários\n",
        "comentarios_processados = [limpar_texto(comentario) for comentario in comentarios]\n",
        "\n",
        "# Visualizar os primeiros comentários processados\n",
        "print(\"🔍 Exemplos de comentários processados:\")\n",
        "print(comentarios_processados[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML_w-hhV8nvE",
        "outputId": "28cdcb0d-9583-4fba-ae41-d759658b59c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Exemplos de comentários processados:\n",
            "['fodda', 'agora sei andar skate', 'jogo pica tipo tony hawk melho', 'fodastico primeiro', 'jogoe pouco dificil engracado bingo clandestino lascar']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_json = \"/content/drive/MyDrive/TCC/Dados/Reviews Da Steam filtradas/Action/Action_SkatemastaTcheco.json\"\n",
        "\n",
        "# Carregar JSON\n",
        "import json\n",
        "\n",
        "with open(path_json, \"r\", encoding=\"utf-8\") as f:\n",
        "    dados = json.load(f)\n",
        "\n",
        "# Extrair apenas os comentários\n",
        "comentarios = [entry[\"review\"] for entry in list(dados[\"reviews\"].values())]\n",
        "\n",
        "# Função para pré-processamento melhorado\n",
        "def preprocess_text(texto):\n",
        "    # Normalizar para remover acentos\n",
        "    texto = unicodedata.normalize(\"NFKD\", texto).encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
        "\n",
        "    # Tokenizar\n",
        "    tokens = word_tokenize(texto.lower())\n",
        "\n",
        "    # Remover stopwords\n",
        "    stop_words = set(nltk.corpus.stopwords.words(\"portuguese\"))\n",
        "    tokens = [t for t in tokens if t not in stop_words]\n",
        "\n",
        "    # Remover caracteres especiais e palavras muito curtas (1 ou 2 letras)\n",
        "    tokens = [re.sub(r'[^a-zA-Z]', '', token) for token in tokens]\n",
        "    tokens = [token for token in tokens if len(token) > 2]\n",
        "\n",
        "    # Reunir tokens em texto novamente\n",
        "    return \" \".join(tokens).strip()\n",
        "\n",
        "# Aplicar a função nos comentários\n",
        "comentarios_processados = [preprocess_text(comentario) for comentario in comentarios]\n",
        "\n",
        "# Exibir alguns exemplos processados\n",
        "print(\"Exemplos de comentários processados:\")\n",
        "print(comentarios_processados[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vndCMhBB-fHI",
        "outputId": "21bfbb85-31cf-4b2f-be33-395222af945b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemplos de comentários processados:\n",
            "['fodda', 'agora sei andar skate', 'jogo pica tipo tony hawk melho', 'fodastico primeiro', 'jogoe pouco dificil engracado bingo clandestino lascar']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import unicodedata\n",
        "import nltk\n",
        "import re\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Caminho do arquivo JSON\n",
        "path_json = \"/content/drive/MyDrive/TCC/Dados/Reviews Da Steam filtradas/Action/Action_SkatemastaTcheco.json\"\n",
        "\n",
        "# Carregar JSON\n",
        "import json\n",
        "\n",
        "with open(path_json, \"r\", encoding=\"utf-8\") as f:\n",
        "    dados = json.load(f)\n",
        "\n",
        "# Extrair os comentários do JSON\n",
        "comentarios = [entry[\"review\"] for entry in dados[\"reviews\"].values()]\n",
        "\n",
        "# Função para pré-processamento de texto\n",
        "def preprocess_text(texto):\n",
        "    # Remover acentos\n",
        "    texto = unicodedata.normalize(\"NFKD\", texto).encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
        "\n",
        "    # Transformar para minúsculas\n",
        "    texto = texto.lower()\n",
        "\n",
        "    # Tokenizar\n",
        "    tokens = word_tokenize(texto)\n",
        "\n",
        "    # Remover stopwords e palavras muito curtas\n",
        "    stop_words = set(nltk.corpus.stopwords.words(\"portuguese\"))\n",
        "    tokens = [t for t in tokens if t not in stop_words and len(t) > 2]\n",
        "\n",
        "    # Remover caracteres não alfabéticos isolados (como pontuações perdidas na tokenização)\n",
        "    tokens = [re.sub(r\"[^a-z]\", \"\", token) for token in tokens]\n",
        "    tokens = [token for token in tokens if token]  # Remove strings vazias geradas pela regex\n",
        "\n",
        "    return \" \".join(tokens)  # Reunir os tokens processados em um texto novamente\n",
        "\n",
        "# Aplicar o pré-processamento aos comentários\n",
        "comentarios_processados = [preprocess_text(comentario) for comentario in comentarios]\n",
        "\n",
        "# Exibir alguns exemplos processados\n",
        "print(\"Exemplos de comentários processados:\")\n",
        "print(list(enumerate(comentarios_processados))[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ERqRNDpB1Nf",
        "outputId": "1b546e2a-383a-4210-f6d7-34e3a770555f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemplos de comentários processados:\n",
            "[(0, 'fodda'), (1, 'agora sei andar skate'), (2, 'jogo pica tipo tony hawk melho'), (3, 'fodastico primeiro'), (4, 'jogoe pouco dificil engracado bingo clandestino lascar')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "diretorio = \"/content/drive/MyDrive/TCC/Dados/Word2Vec\"\n",
        "\n",
        "# Converter os comentários processados em listas de tokens\n",
        "comentarios_tokens = [comentario.split() for comentario in comentarios_processados]\n",
        "\n",
        "# Treinar o modelo Word2Vec\n",
        "modelo_w2v = Word2Vec(sentences=comentarios_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Caminho completo para salvar o modelo\n",
        "caminho_modelo = os.path.join(diretorio, \"word2vec_modelo.model\")\n",
        "\n",
        "# Salvar o modelo Word2Vec\n",
        "modelo_w2v.save(caminho_modelo)\n",
        "\n",
        "# Exemplo: Obter a similaridade entre palavras\n",
        "similaridade = modelo_w2v.wv.similarity('skate', 'tony')\n",
        "print(f\"Similaridade entre 'skate' e 'tony': {similaridade}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNC9jK4AgfWL",
        "outputId": "0f033b39-b3d0-40fc-f3b6-ca479ab4e8e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similaridade entre 'skate' e 'tony': 0.1346835494041443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Caminho da pasta com os JSONs\n",
        "diretorio_json = \"/content/drive/MyDrive/TCC/Dados/Reviews Da Steam filtradas/Combined/part50/\"\n",
        "\n",
        "# Percorrer todos os arquivos JSON e verificar a estrutura\n",
        "for arquivo in os.listdir(diretorio_json):\n",
        "    if arquivo.endswith(\".json\"):\n",
        "        caminho_arquivo = os.path.join(diretorio_json, arquivo)\n",
        "\n",
        "        with open(caminho_arquivo, \"r\", encoding=\"utf-8\") as f:\n",
        "            dados = json.load(f)\n",
        "\n",
        "        print(f\"\\n📂 Estrutura do arquivo: {arquivo}\")\n",
        "        print(dados.keys())  # Mostra as chaves principais do JSON\n",
        "\n",
        "        print(type(dados))  # Isso nos dirá se é uma lista ou um dicionário\n",
        "        print(dados.keys() if isinstance(dados, dict) else dados[:3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JGc_5qX_Acp",
        "outputId": "e163f33b-d6d5-45b0-81dd-94922c37dcc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📂 Estrutura do arquivo: Racing_json_part50.json\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.playtime_at_review', 'author.last_played', 'timestamp_dev_responded', 'developer_response'])\n",
            "<class 'dict'>\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.playtime_at_review', 'author.last_played', 'timestamp_dev_responded', 'developer_response'])\n",
            "\n",
            "📂 Estrutura do arquivo: Action_json_part50.json\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.playtime_at_review', 'author.last_played', 'timestamp_dev_responded', 'developer_response'])\n",
            "<class 'dict'>\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.playtime_at_review', 'author.last_played', 'timestamp_dev_responded', 'developer_response'])\n",
            "\n",
            "📂 Estrutura do arquivo: Adventure_json_part50.json\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.playtime_at_review', 'author.last_played', 'timestamp_dev_responded', 'developer_response'])\n",
            "<class 'dict'>\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.playtime_at_review', 'author.last_played', 'timestamp_dev_responded', 'developer_response'])\n",
            "\n",
            "📂 Estrutura do arquivo: FPS_json_part50.json\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.playtime_at_review', 'author.last_played', 'timestamp_dev_responded', 'developer_response'])\n",
            "<class 'dict'>\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.playtime_at_review', 'author.last_played', 'timestamp_dev_responded', 'developer_response'])\n",
            "\n",
            "📂 Estrutura do arquivo: Horror_json_part50.json\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.playtime_at_review', 'author.last_played', 'timestamp_dev_responded', 'developer_response'])\n",
            "<class 'dict'>\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.playtime_at_review', 'author.last_played', 'timestamp_dev_responded', 'developer_response'])\n",
            "\n",
            "📂 Estrutura do arquivo: Indie_json_part50.json\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.playtime_at_review', 'author.last_played', 'timestamp_dev_responded', 'developer_response'])\n",
            "<class 'dict'>\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.playtime_at_review', 'author.last_played', 'timestamp_dev_responded', 'developer_response'])\n",
            "\n",
            "📂 Estrutura do arquivo: RPG_json_part50.json\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.last_played', 'author.playtime_at_review', 'timestamp_dev_responded', 'developer_response'])\n",
            "<class 'dict'>\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.last_played', 'author.playtime_at_review', 'timestamp_dev_responded', 'developer_response'])\n",
            "\n",
            "📂 Estrutura do arquivo: Simulation_json_part50.json\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.playtime_at_review', 'author.last_played', 'timestamp_dev_responded', 'developer_response'])\n",
            "<class 'dict'>\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.playtime_at_review', 'author.last_played', 'timestamp_dev_responded', 'developer_response'])\n",
            "\n",
            "📂 Estrutura do arquivo: Sports_json_part50.json\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.playtime_at_review', 'author.last_played', 'timestamp_dev_responded', 'developer_response'])\n",
            "<class 'dict'>\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.playtime_at_review', 'author.last_played', 'timestamp_dev_responded', 'developer_response'])\n",
            "\n",
            "📂 Estrutura do arquivo: Strategy_json_part50.json\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.last_played', 'author.playtime_at_review', 'timestamp_dev_responded', 'developer_response'])\n",
            "<class 'dict'>\n",
            "dict_keys(['recommendationid', 'language', 'review', 'timestamp_created', 'timestamp_updated', 'voted_up', 'votes_up', 'votes_funny', 'weighted_vote_score', 'comment_count', 'steam_purchase', 'received_for_free', 'written_during_early_access', 'author.steamid', 'author.num_games_owned', 'author.num_reviews', 'author.playtime_forever', 'author.playtime_last_two_weeks', 'author.last_played', 'author.playtime_at_review', 'timestamp_dev_responded', 'developer_response'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "stop_words = set(stopwords.words('portuguese'))\n",
        "\n",
        "# Pasta onde os arquivos JSON estão armazenados\n",
        "pasta_dados = \"/content/drive/MyDrive/TCC/Dados/Reviews Da Steam filtradas/Combined/part50/\"  # Modifique para o caminho correto\n",
        "\n",
        "# Função para carregar os dados e extrair comentários\n",
        "def carregar_comentarios(pasta):\n",
        "    comentarios = []\n",
        "    for arquivo in tqdm(os.listdir(pasta), desc=\"Lendo arquivos\"):\n",
        "        caminho = os.path.join(pasta, arquivo)\n",
        "\n",
        "        # Ler arquivo JSON\n",
        "        with open(caminho, \"r\", encoding=\"utf-8\") as f:\n",
        "            dados = json.load(f)  # O JSON é um dicionário\n",
        "\n",
        "            # Verificar se a chave \"review\" existe e armazenar seus valores\n",
        "            if \"review\" in dados:\n",
        "                comentarios.extend(dados[\"review\"].values())  # Pegar todos os comentários\n",
        "\n",
        "    return comentarios\n",
        "\n",
        "# Testando a função\n",
        "comentarios = carregar_comentarios(pasta_dados)\n",
        "\n",
        "print(f\"Total de comentários carregados: {len(comentarios)}\")\n",
        "print(\"Exemplo de comentário:\", comentarios[:3])  # Exibe os 3 primeiros comentários\n",
        "\n",
        "# Função para pré-processar os textos\n",
        "def preprocessar_texto(texto):\n",
        "    texto = texto.lower()  # Converter para minúsculas\n",
        "    texto = re.sub(r'[^\\w\\s]', '', texto)  # Remover pontuação\n",
        "    texto = re.sub(r'[^a-záéíóúãõâêôç\\s]', '', texto)  # Remover caracteres estranhos\n",
        "    tokens = word_tokenize(texto)  # Tokenizar\n",
        "    tokens = [palavra for palavra in tokens if palavra not in stop_words and len(palavra) > 2]  # Remover stopwords e palavras curtas\n",
        "    return tokens\n",
        "\n",
        "# Carregar e processar os comentários\n",
        "comentarios = carregar_comentarios(pasta_dados)\n",
        "comentarios_tokenizados = [preprocessar_texto(comentario) for comentario in tqdm(comentarios, desc=\"Processando comentários\")]\n",
        "\n",
        "# Treinar modelo Word2Vec\n",
        "modelo_w2v = Word2Vec(sentences=comentarios_tokenizados, vector_size=1000, window=5, min_count=5, workers=4)\n",
        "\n",
        "# Salvar o modelo treinado\n",
        "modelo_w2v.save(caminho_modelo)\n",
        "print(\"Modelo Word2Vec salvo com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9ia_eTiCRh8",
        "outputId": "f7318866-e8ac-45a1-ef96-8ba5b30f6966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Lendo arquivos: 100%|██████████| 10/10 [00:01<00:00,  7.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de comentários carregados: 116910\n",
            "Exemplo de comentário: ['Pior coisa foi a EA ter comprado, o  F1-2020  nem de longe deu tanto problema quanto esse, simplesmente impossível de jogar com esse BUG  que faz o jogo dar crash, e o pior nem se pronunciam com uma previsão de correção. \\nEstava empolgado para jogar a versão nova e as pistas mas simplesmente não tem como no máximo consigo ficar 5 6 voltas em time trial.\\nNa boa enquanto não corrigirem esse problema guarde o seu dinheiro e evite passar raiva.\\n\\n', '- O jogo tem o foco mais em sobrevivência na pista, do que a própria corrida em si.\\n\\n- O estilo de música e competição no jogo é um pouco infantil, mas não deixa de ser legal de jogar com outras pessoas ou com o próprio computador. Pois acaba sendo divertido.\\n\\n- Cenário bem otimizado. \\n\\n- As vezes o computador joga bem melhor que um adulto. Não é tão fácil assim rs\\n\\n', 'Como todo simulador, indico jogar com volante/pedal pra não passar raiva.\\n\\nA sensação de velocidade é muito boa e é a melhor coisa do jogo. Correr pelo meio das árvores na Finlândia, com um Golf GTI a 80km/h, é bem mais emocionante que dirigir uma Lamborghini a 300km/h em uma pista de corrida em outros jogos.\\n\\nTem vários países e locais, cada um trazendo algo diferente pra te desafiar, o jogo é bonito pra caramba, suporte de realidade virtual, vários carros, show demais. Tem co-piloto em português também, que ajuda na imersão.\\n\\nEssa é a melhor série de simulador de corrida de todas. O primeiro jogo já era excelente, esse só melhorou em todos os aspectos.  Recomendado.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Lendo arquivos: 100%|██████████| 10/10 [00:01<00:00,  6.97it/s]\n",
            "Processando comentários: 100%|██████████| 116910/116910 [00:43<00:00, 2708.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo Word2Vec salvo com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testando o Word2Ved"
      ],
      "metadata": {
        "id": "L6B4-jxPSTKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o modelo treinado\n",
        "fword2vec = '/content/drive/MyDrive/TCC/Dados/Word2Vec/word2vec_modelo.model'\n",
        "modelo_w2v = Word2Vec.load(fword2vec)\n",
        "\n",
        "# Testar palavras similares\n",
        "#print(modelo_w2v.wv.most_similar(\"jogo\", topn=5))\n",
        "#print(modelo_w2v.wv.most_similar(\"gráficos\", topn=5))\n",
        "#print(modelo_w2v.wv.most_similar(\"história\", topn=5))\n",
        "\n",
        "print(f\"Tamanho do vocabulário: {len(modelo_w2v.wv)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1APONbdSWdp",
        "outputId": "f21aad33-f7c5-426a-e0c9-9c9cfa805704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do vocabulário: 41297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformar o Word2Vec em Embeddings"
      ],
      "metadata": {
        "id": "W4wbOV3CY0ER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pasta_dados = \"/content/drive/MyDrive/TCC/Dados/Reviews Da Steam filtradas/Combined/part50/\"  # Modifique para o caminho correto\n",
        "\n",
        "def carregar_comentarios(pasta):\n",
        "    comentarios = []\n",
        "    for arquivo in tqdm(os.listdir(pasta), desc=\"Lendo arquivos\"):\n",
        "        caminho = os.path.join(pasta, arquivo)\n",
        "\n",
        "        # Ler arquivo JSON\n",
        "        with open(caminho, \"r\", encoding=\"utf-8\") as f:\n",
        "            dados = json.load(f)  # O JSON é um dicionário\n",
        "\n",
        "            # Verificar se a chave \"review\" existe e armazenar seus valores\n",
        "            if \"review\" in dados:\n",
        "                comentarios.extend(dados[\"review\"].values())  # Pegar todos os comentários\n",
        "\n",
        "    return comentarios\n",
        "\n",
        "comentarios = carregar_comentarios(pasta_dados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX9x7-7Nlccy",
        "outputId": "62abc064-aa30-45c1-a110-fb175ae5c894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Lendo arquivos: 100%|██████████| 10/10 [00:14<00:00,  1.43s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorizar_comentario(comentario, modelo):\n",
        "    tokens = comentario.split()  # Tokenizar o texto\n",
        "    vetores = [modelo.wv[palavra] for palavra in tokens if palavra in modelo.wv]  # Buscar embeddings válidos\n",
        "    return np.mean(vetores, axis=0) if vetores else np.zeros(modelo.vector_size)  # Média dos vetores\n",
        "\n",
        "# Criar matriz de vetores para os comentários\n",
        "X_word2vec = np.array([vectorizar_comentario(c, modelo_w2v) for c in comentarios])\n",
        "\n",
        "#print(f\"Formato de X_word2vec: {X_word2vec.shape}\")  # Deve ser algo como (n_comentarios, 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "Br8yTsoNY4zW",
        "outputId": "c363c9a1-32bd-4cf1-98b1-10460a04167b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'modelo_w2v' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-bf42c668482b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Criar matriz de vetores para os comentários\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_word2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvectorizar_comentario\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelo_w2v\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomentarios\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#print(f\"Formato de X_word2vec: {X_word2vec.shape}\")  # Deve ser algo como (n_comentarios, 100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-bf42c668482b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Criar matriz de vetores para os comentários\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_word2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvectorizar_comentario\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelo_w2v\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomentarios\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#print(f\"Formato de X_word2vec: {X_word2vec.shape}\")  # Deve ser algo como (n_comentarios, 100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'modelo_w2v' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concatenar o Doc2Vec com Word2Vec"
      ],
      "metadata": {
        "id": "K13tkoncbEiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho do arquivo com os vetores Doc2Vec\n",
        "caminho_doc2vec = \"/content/drive/MyDrive/TCC/Dados/Doc2Vec/meu_doc2vec.dv.vectors.npy\"\n",
        "\n",
        "# Carregar os embeddings Doc2Vec\n",
        "X_doc2vec = np.load(caminho_doc2vec)\n",
        "\n",
        "X_combinado = np.hstack((X_word2vec, X_doc2vec))  # Une horizontalmente\n",
        "\n",
        "# Caminho para salvar no Google Drive\n",
        "caminho_concatenacao = \"/content/drive/MyDrive/TCC/Dados/X_combinado.npy\"\n",
        "\n",
        "# Salvar os embeddings combinados\n",
        "np.save(caminho_concatenacao, X_combinado)\n",
        "\n",
        "print(f\"Formato final dos embeddings combinados: {X_combinado.shape}\")  # Deve ser (n_amostras, 2000)\n"
      ],
      "metadata": {
        "id": "TTZ73ZKzbRC7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "207b521d-683a-44c5-b012-a2aeab120d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato final dos embeddings combinados: (116910, 2000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho do arquivo salvo no Google Drive\n",
        "caminho_concatenacao = \"/content/drive/MyDrive/TCC/Dados/X_combinado.npy\"\n",
        "\n",
        "# Carregar os embeddings combinados\n",
        "X_combinado = np.load(caminho_concatenacao)"
      ],
      "metadata": {
        "id": "BYRmB_tnwqO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir o número de amostras desejado\n",
        "n_amostras = 60000\n",
        "\n",
        "# Verificar se temos pelo menos 60.000 exemplos\n",
        "if len(comentarios) < n_amostras:\n",
        "    raise ValueError(f\"O conjunto de dados tem apenas {len(comentarios)} exemplos, impossível selecionar {n_amostras}.\")\n",
        "\n",
        "# Selecionar 60.000 comentários mantendo a distribuição de classes\n",
        "comentarios_selecionados, _, y_selecionado, _ = train_test_split(comentarios, y, train_size=n_amostras, stratify=y, random_state=42)\n",
        "\n",
        "print(f\"Novo número de comentários: {len(comentarios_selecionados)}\")\n",
        "print(f\"Número de rótulos selecionados: {len(y_selecionado)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCn0iAJu5ey_",
        "outputId": "1c44d6d1-60bb-4cdd-c881-763d2aad3cd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Novo número de comentários: 60000\n",
            "Número de rótulos selecionados: 60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fword2vec = '/content/drive/MyDrive/TCC/Dados/Word2Vec/word2vec_modelo.model'\n",
        "modelo_w2v = Word2Vec.load(fword2vec)\n",
        "X_word2vec = np.array([vectorizar_comentario(c, modelo_w2v) for c in comentarios_selecionados])\n",
        "print(f\"Formato de X_word2vec: {X_word2vec.shape}\")  # Deve ser (60000, 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__FpIQKx6sao",
        "outputId": "4998e5d1-8a58-4057-dfa5-628b7d335ea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato de X_word2vec: (60000, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar os embeddings completos do Doc2Vec\n",
        "X_doc2vec_total = np.load(\"/content/drive/MyDrive/TCC/Dados/Doc2Vec/meu_doc2vec.dv.vectors.npy\")\n",
        "\n",
        "# Selecionar apenas os 60.000 que correspondem aos comentários escolhidos\n",
        "X_doc2vec = X_doc2vec_total[:60000]\n",
        "\n",
        "print(f\"Formato de X_doc2vec: {X_doc2vec.shape}\")  # Deve ser (60000, 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoD5Hi4T66aT",
        "outputId": "88c2b2c9-d108-42bd-8203-a65ecdb7e192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato de X_doc2vec: (60000, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenar Word2Vec e Doc2Vec\n",
        "X_combinado = np.hstack((X_word2vec, X_doc2vec))\n",
        "\n",
        "# Caminho para salvar no Google Drive\n",
        "caminho_concatenacao_reduzida = \"/content/drive/MyDrive/TCC/Dados/X_combinado_reduzido.npy\"\n",
        "\n",
        "# Salvar os embeddings combinados\n",
        "np.save(caminho_concatenacao_reduzida, X_combinado)\n",
        "\n",
        "print(f\"Novo formato dos embeddings combinados: {X_combinado.shape}\")  # Deve ser (60000, 2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZjKLqoC7AzK",
        "outputId": "f7c04add-d595-477b-a31e-34d245804c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Novo formato dos embeddings combinados: (60000, 2000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separar modelos de Treinos e de Teste (60.000)"
      ],
      "metadata": {
        "id": "WN92GXEwfknZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gerar o Y usando o \"voted_up\""
      ],
      "metadata": {
        "id": "eZ_dzRkafvHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para armazenar os rótulos\n",
        "y = []\n",
        "\n",
        "# Pasta onde estão os arquivos JSON\n",
        "pasta_dados = \"/content/drive/MyDrive/TCC/Dados/Reviews Da Steam filtradas/Combined/part50/\"\n",
        "\n",
        "# Percorrer todos os arquivos JSON\n",
        "for arquivo in tqdm(os.listdir(pasta_dados), desc=\"Lendo arquivos\"):\n",
        "    caminho = os.path.join(pasta_dados, arquivo)\n",
        "\n",
        "    with open(caminho, \"r\", encoding=\"utf-8\") as f:\n",
        "        dados = json.load(f)  # Carrega o arquivo JSON\n",
        "\n",
        "        # Coletar o valor de \"voted_up\" e converter True → 1, False → 0\n",
        "        if \"voted_up\" in dados:\n",
        "            y.extend([int(valor) for valor in dados[\"voted_up\"].values()])  # Converte booleanos para inteiros\n",
        "\n",
        "# Converter para array NumPy\n",
        "y = np.array(y)\n",
        "\n",
        "print(f\"Total de rótulos carregados: {len(y)}\")\n",
        "print(f\"Exemplo de rótulos: {y[:10]}\")  # Mostrar alguns rótulos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-54iV4uf4Uy",
        "outputId": "f41faf02-3d74-48e7-88df-c5c8cc114439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Lendo arquivos: 100%|██████████| 10/10 [00:04<00:00,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de rótulos carregados: 116910\n",
            "Exemplo de rótulos: [0 1 1 1 1 1 1 0 1 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dados Reduzidos"
      ],
      "metadata": {
        "id": "eQwe7luygB5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho do arquivo salvo no Google Drive\n",
        "caminho_concatenacao_reduzida = \"/content/drive/MyDrive/TCC/Dados/X_combinado_reduzido.npy\"\n",
        "\n",
        "# Carregar os embeddings combinados\n",
        "X_combinado = np.load(caminho_concatenacao_reduzida)"
      ],
      "metadata": {
        "id": "QV34TgkkzQAA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "536829ee-b4b3-4177-9f79-4a0162851d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-287437c60921>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Carregar os embeddings combinados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_combinado\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaminho_concatenacao_reduzida\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    454\u001b[0m                                           max_header_size=max_header_size)\n\u001b[1;32m    455\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0m\u001b[1;32m    457\u001b[0m                                          \u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                                          max_header_size=max_header_size)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separar os dados"
      ],
      "metadata": {
        "id": "5NXBkj33g1IP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_selecionado = y[:60000]\n",
        "\n",
        "# Dividir os dados com 50% treino e 50% teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combinado, y_selecionado, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Tamanho do conjunto de treino: {len(X_train)} comentários\")\n",
        "print(f\"Tamanho do conjunto de teste: {len(X_test)} comentários\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "5WFepjZWg4Eo",
        "outputId": "1a12c4b3-d7c9-444b-c8de-d1b900b05d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_combinado' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-3edd3f63109a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Dividir os dados com 50% treino e 50% teste\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_combinado\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_selecionado\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Tamanho do conjunto de treino: {len(X_train)} comentários\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_combinado' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dados Completos"
      ],
      "metadata": {
        "id": "sEL4_qHCf-Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho do arquivo salvo no Google Drive\n",
        "caminho_concatenacao = \"/content/drive/MyDrive/TCC/Dados/X_combinado.npy\"\n",
        "\n",
        "# Carregar os embeddings combinados\n",
        "X_combinado = np.load(caminho_concatenacao)"
      ],
      "metadata": {
        "id": "K3TXyqSjf9cu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separar os dados completos"
      ],
      "metadata": {
        "id": "v2Q1fdELgzd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir os dados com 50% treino e 50% teste\n",
        "X_train, X_test = train_test_split(X_combinado, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Tamanho do conjunto de treino: {len(X_train)} comentários\")\n",
        "print(f\"Tamanho do conjunto de teste: {len(X_test)} comentários\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLWhAxaDg1Zr",
        "outputId": "c5eaed64-81e6-4017-b218-2a7ad2e41009"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treino: 58455 comentários\n",
            "Tamanho do conjunto de teste: 58455 comentários\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definir a validação cruzada"
      ],
      "metadata": {
        "id": "oeolY-jRiAzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir os hiperparâmetros a serem testados\n",
        "param_grid_svm = {\n",
        "    'kernel': ['linear', 'rbf', 'poly'],  # Testar diferentes tipos de kernel\n",
        "    'C': [0.1, 1, 10]  # Testar diferentes penalizações\n",
        "}\n",
        "\n",
        "# Configurar validação cruzada estratificada para manter equilíbrio de classes\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Criar GridSearchCV com verbose para mostrar progresso\n",
        "grid_svm = GridSearchCV(SVC(), param_grid_svm, cv=cv, scoring='f1', n_jobs=-1, verbose=3)\n",
        "\n",
        "# Mensagem de início\n",
        "print(\"🔄 Iniciando GridSearchCV para SVM...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Rodar o GridSearchCV (com logs de progresso)\n",
        "grid_svm.fit(X_combinado, y_selecionado)\n",
        "\n",
        "# Mensagem de fim\n",
        "end_time = time.time()\n",
        "tempo_total = end_time - start_time\n",
        "print(f\"✅ GridSearchCV finalizado em {tempo_total/60:.2f} minutos.\")\n",
        "\n",
        "# Melhor configuração encontrada\n",
        "print(\"🎯 Melhores parâmetros para SVM:\", grid_svm.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "4tt-h_oeiEUQ",
        "outputId": "7b761558-5f04-47c2-c136-b4d3c5e2ad9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Iniciando GridSearchCV para SVM...\n",
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-10d2317b9f60>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Rodar o GridSearchCV (com logs de progresso)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mgrid_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_combinado\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_selecionado\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Mensagem de fim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir os hiperparâmetros a serem testados\n",
        "param_grid_svm = {\n",
        "    'kernel': ['linear'],  # Apenas linear para acelerar\n",
        "    'C': [0.1, 1, 10]\n",
        "}\n",
        "\n",
        "# Configurar validação cruzada estratificada para manter equilíbrio de classes\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# Criar GridSearchCV com verbose para mostrar progresso\n",
        "grid_svm = GridSearchCV(SVC(), param_grid_svm, cv=cv, scoring='f1', n_jobs=-1, verbose=3)\n",
        "\n",
        "# Mensagem de início\n",
        "print(\"🔄 Iniciando GridSearchCV para SVM...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Rodar o GridSearchCV (com logs de progresso)\n",
        "grid_svm.fit(X_combinado, y_selecionado)\n",
        "\n",
        "# Mensagem de fim\n",
        "end_time = time.time()\n",
        "tempo_total = end_time - start_time\n",
        "print(f\"✅ GridSearchCV finalizado em {tempo_total/60:.2f} minutos.\")\n",
        "\n",
        "# Melhor configuração encontrada\n",
        "print(\"🎯 Melhores parâmetros para SVM:\", grid_svm.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Mnc38lxvP9K",
        "outputId": "4b055f49-ad92-428c-eb8e-2b063fee65a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Iniciando GridSearchCV para SVM...\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir os hiperparâmetros a serem testados\n",
        "param_grid_svm = {\n",
        "    'kernel': ['linear'],  # Apenas linear para acelerar\n",
        "    'C': [0.1, 1, 10]\n",
        "}\n",
        "\n",
        "# Configurar validação cruzada estratificada para manter equilíbrio de classes\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# Criar GridSearchCV com verbose para mostrar progresso\n",
        "grid_svm = GridSearchCV(SVC(), param_grid_svm, cv=cv, scoring='f1', n_jobs=-1, verbose=3)\n",
        "\n",
        "# Reduzir para 20.000 amostras para um teste rápido\n",
        "X_teste, _, y_teste, _ = train_test_split(X_combinado, y_selecionado, train_size=20000, stratify=y_selecionado, random_state=42)\n",
        "\n",
        "# Mensagem de início\n",
        "print(\"🔄 Iniciando GridSearchCV para SVM...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Rodar o GridSearch apenas nesse subconjunto\n",
        "grid_svm.fit(X_teste, y_teste)\n",
        "\n",
        "# Mensagem de fim\n",
        "end_time = time.time()\n",
        "tempo_total = end_time - start_time\n",
        "print(f\"✅ GridSearchCV finalizado em {tempo_total/60:.2f} minutos.\")\n",
        "\n",
        "# Melhor configuração encontrada\n",
        "print(\"🎯 Melhores parâmetros para SVM:\", grid_svm.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUsXWrNQBAiI",
        "outputId": "0a921f41-ff47-4912-bfa7-3578f8a35d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Iniciando GridSearchCV para SVM...\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "✅ GridSearchCV finalizado em 410.74 minutos.\n",
            "🎯 Melhores parâmetros para SVM: {'C': 0.1, 'kernel': 'linear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treino do SVM"
      ],
      "metadata": {
        "id": "mEqIJFmlsqCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar o modelo LinearSVC com os melhores hiperparâmetros encontrados\n",
        "svm_fast = LinearSVC(C=0.1, max_iter=5000)  # max_iter alto para garantir convergência\n",
        "\n",
        "# Reduzir para 20.000 amostras para um teste rápido\n",
        "X_teste, _, y_teste, _ = train_test_split(X_combinado, y_selecionado, train_size=20000, stratify=y_selecionado, random_state=42)\n",
        "\n",
        "# Mensagem de início\n",
        "print(\"🔄 Iniciando treinamento com LinearSVC...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Treinar o modelo com 20.000 amostras\n",
        "svm_fast.fit(X_teste, y_teste)\n",
        "\n",
        "# Mensagem de fim\n",
        "end_time = time.time()\n",
        "tempo_total = end_time - start_time\n",
        "print(f\"✅ Treinamento finalizado em {tempo_total/60:.2f} minutos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30Uk9GROwLU6",
        "outputId": "d692017b-b03a-4b47-8dd1-27531fa5ef74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Iniciando treinamento com LinearSVC...\n",
            "✅ Treinamento finalizado em 0.84 minutos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BjOcmJghz2SN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar e treinar o modelo com TODOS os dados\n",
        "svm_final = LinearSVC(C=0.1, max_iter=5000)\n",
        "\n",
        "# Mensagem de início\n",
        "print(\"🔄 Iniciando treinamento com LinearSVC...\")\n",
        "start_time = time.time()\n",
        "\n",
        "svm_final.fit(X_combinado, y_selecionado)\n",
        "\n",
        "# Mensagem de fim\n",
        "end_time = time.time()\n",
        "tempo_total = end_time - start_time\n",
        "print(f\"✅ Treinamento finalizado em {tempo_total/60:.2f} minutos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI0vbGwzz2vJ",
        "outputId": "27771a61-7e89-4e52-eeca-6abee0b0db6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Iniciando treinamento com LinearSVC...\n",
            "✅ Treinamento finalizado em 3.44 minutos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazer previsões\n",
        "y_pred = svm_final.predict(X_test)\n",
        "\n",
        "# Avaliar desempenho\n",
        "print(\"🔹 Desempenho do modelo LinearSVC:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GrVd6tm1vxc",
        "outputId": "86d12ac9-f5bd-4098-f3cb-58e558b9f538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Desempenho do modelo LinearSVC:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.01      0.02      6022\n",
            "           1       0.80      1.00      0.89     23978\n",
            "\n",
            "    accuracy                           0.80     30000\n",
            "   macro avg       0.63      0.50      0.46     30000\n",
            "weighted avg       0.73      0.80      0.71     30000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduzir o dataset para 10.000 amostras para teste rápido\n",
        "X_teste_menor, _, y_teste_menor, _ = train_test_split(X_combinado, y_selecionado, train_size=10000, stratify=y_selecionado, random_state=42)\n",
        "\n",
        "# Testar SVM com kernel 'rbf'\n",
        "print(\"🔄 Treinando SVM com kernel 'rbf'...\")\n",
        "start_time = time.time()\n",
        "svm_rbf = SVC(kernel=\"rbf\", C=0.1)\n",
        "svm_rbf.fit(X_teste_menor, y_teste_menor)\n",
        "end_time = time.time()\n",
        "print(f\"✅ Treino com 'rbf' finalizado em {(end_time - start_time)/60:.2f} minutos.\")\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred_rbf = svm_rbf.predict(X_test)\n",
        "\n",
        "# Avaliar desempenho\n",
        "print(\"🔹 Desempenho do SVM (kernel='rbf'):\")\n",
        "print(classification_report(y_test, y_pred_rbf))\n",
        "\n",
        "# Testar SVM com kernel 'poly'\n",
        "print(\"🔄 Treinando SVM com kernel 'poly'...\")\n",
        "start_time = time.time()\n",
        "svm_poly = SVC(kernel=\"poly\", C=0.1, degree=3)  # Grau 3 é um valor comum para 'poly'\n",
        "svm_poly.fit(X_teste_menor, y_teste_menor)\n",
        "end_time = time.time()\n",
        "print(f\"✅ Treino com 'poly' finalizado em {(end_time - start_time)/60:.2f} minutos.\")\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred_poly = svm_poly.predict(X_test)\n",
        "\n",
        "# Avaliar desempenho\n",
        "print(\"🔹 Desempenho do SVM (kernel='poly'):\")\n",
        "print(classification_report(y_test, y_pred_poly))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5_NugRE3S2b",
        "outputId": "377565b7-31d5-4551-fc34-3f714b56a284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Treinando SVM com kernel 'rbf'...\n",
            "✅ Treino com 'rbf' finalizado em 2.17 minutos.\n",
            "🔹 Desempenho do SVM (kernel='rbf'):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      6022\n",
            "           1       0.80      1.00      0.89     23978\n",
            "\n",
            "    accuracy                           0.80     30000\n",
            "   macro avg       0.40      0.50      0.44     30000\n",
            "weighted avg       0.64      0.80      0.71     30000\n",
            "\n",
            "🔄 Treinando SVM com kernel 'poly'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Treino com 'poly' finalizado em 2.01 minutos.\n",
            "🔹 Desempenho do SVM (kernel='poly'):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.01      0.02      6022\n",
            "           1       0.80      1.00      0.89     23978\n",
            "\n",
            "    accuracy                           0.80     30000\n",
            "   macro avg       0.62      0.50      0.45     30000\n",
            "weighted avg       0.73      0.80      0.71     30000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balanceamento dos dados"
      ],
      "metadata": {
        "id": "ZkIcDvKN8Ruj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar o modelo LinearSVC balanceado\n",
        "svm_balanced = LinearSVC(C=0.1, max_iter=5000, class_weight='balanced')\n",
        "\n",
        "print(\"🔄 Treinando LinearSVC balanceado...\")\n",
        "svm_balanced.fit(X_combinado, y_selecionado)\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "y_pred_balanced = svm_balanced.predict(X_test)\n",
        "\n",
        "# Avaliar desempenho\n",
        "print(\"🔹 Desempenho do modelo LinearSVC balanceado:\")\n",
        "print(classification_report(y_test, y_pred_balanced))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yvthj5PY8T-R",
        "outputId": "14b8a5ef-49ac-48eb-caf2-dbb32058218f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Treinando LinearSVC balanceado...\n",
            "🔹 Desempenho do modelo LinearSVC balanceado:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.61      0.39      6022\n",
            "           1       0.86      0.63      0.73     23978\n",
            "\n",
            "    accuracy                           0.63     30000\n",
            "   macro avg       0.58      0.62      0.56     30000\n",
            "weighted avg       0.75      0.63      0.66     30000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Novo teste, ajustando o valor de C"
      ],
      "metadata": {
        "id": "KoQM5x4XDLgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir os valores de C para testar\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10]}\n",
        "\n",
        "# Configurar GridSearchCV para otimizar o F1-score médio (weighted)\n",
        "grid_svm_balanced = GridSearchCV(\n",
        "    LinearSVC(class_weight='balanced', max_iter=5000),\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='f1_weighted',  # Maximizar F1-score ponderado\n",
        "    verbose=3\n",
        ")\n",
        "\n",
        "print(\"🔄 Rodando GridSearch para encontrar o melhor C...\")\n",
        "grid_svm_balanced.fit(X_combinado, y_selecionado)\n",
        "\n",
        "# Melhor configuração encontrada\n",
        "best_C = grid_svm_balanced.best_params_['C']\n",
        "print(\"🎯 Melhor parâmetro encontrado:\", best_C)\n",
        "\n",
        "# Treinar o modelo final com o melhor C\n",
        "svm_final = LinearSVC(C=best_C, class_weight='balanced', max_iter=5000)\n",
        "svm_final.fit(X_combinado, y_selecionado)\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred_final = svm_final.predict(X_test)\n",
        "\n",
        "# Avaliar desempenho final\n",
        "from sklearn.metrics import classification_report\n",
        "print(\"🔹 Desempenho do modelo otimizado:\")\n",
        "print(classification_report(y_test, y_pred_final))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDEwsVm4DLFR",
        "outputId": "2b35f62d-f926-4741-b82c-d1c082c3a2d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Rodando GridSearch para encontrar o melhor C...\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "[CV 1/3] END ............................C=0.01;, score=0.660 total time= 1.6min\n",
            "[CV 2/3] END ............................C=0.01;, score=0.642 total time= 1.1min\n",
            "[CV 3/3] END ............................C=0.01;, score=0.660 total time= 1.1min\n",
            "[CV 1/3] END .............................C=0.1;, score=0.657 total time= 3.0min\n",
            "[CV 2/3] END .............................C=0.1;, score=0.643 total time= 3.5min\n",
            "[CV 3/3] END .............................C=0.1;, score=0.659 total time= 2.7min\n",
            "[CV 1/3] END ...............................C=1;, score=0.651 total time= 9.8min\n",
            "[CV 2/3] END ...............................C=1;, score=0.639 total time=11.8min\n",
            "[CV 3/3] END ...............................C=1;, score=0.664 total time=10.0min\n",
            "[CV 1/3] END ..............................C=10;, score=0.639 total time=38.3min\n",
            "[CV 2/3] END ..............................C=10;, score=0.628 total time=46.5min\n",
            "[CV 3/3] END ..............................C=10;, score=0.666 total time=43.3min\n",
            "🎯 Melhor parâmetro encontrado: 0.01\n",
            "🔹 Desempenho do modelo otimizado:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.60      0.39      6022\n",
            "           1       0.86      0.63      0.73     23978\n",
            "\n",
            "    accuracy                           0.62     30000\n",
            "   macro avg       0.58      0.62      0.56     30000\n",
            "weighted avg       0.75      0.62      0.66     30000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisão dos dados (supondo que X e y já estejam prontos)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combinado, y_selecionado, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]}\")\n",
        "print(f\"Tamanho do conjunto de teste: {X_test.shape[0]}\")\n",
        "print(f\"Total de amostras: {X_train.shape[0] + X_test.shape[0]}\")\n",
        "\n",
        "# Modelo 1: LinearSVC sem balanceamento\n",
        "modelo_puro = LinearSVC(C=0.01, dual=False, max_iter=10000)\n",
        "modelo_puro.fit(X_train, y_train)\n",
        "pred_puro = modelo_puro.predict(X_test)\n",
        "\n",
        "# Modelo 2: LinearSVC com balanceamento\n",
        "modelo_balanceado = LinearSVC(C=0.01, class_weight='balanced', dual=False, max_iter=10000)\n",
        "modelo_balanceado.fit(X_train, y_train)\n",
        "pred_balanceado = modelo_balanceado.predict(X_test)\n",
        "\n",
        "# Exibir métricas de ambos os modelos\n",
        "print(\"Desempenho do Modelo LinearSVC sem balanceamento:\")\n",
        "print(classification_report(y_test, pred_puro))\n",
        "\n",
        "print(\"Desempenho do Modelo LinearSVC com balanceamento:\")\n",
        "print(classification_report(y_test, pred_balanceado))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNwQM89ztCfe",
        "outputId": "7f8edc4c-fd6e-45b7-9316-f3b36ab13e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treino: 30000\n",
            "Tamanho do conjunto de teste: 30000\n",
            "Total de amostras: 60000\n",
            "Desempenho do Modelo LinearSVC sem balanceamento:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      0.01      0.02      6022\n",
            "           1       0.80      1.00      0.89     23978\n",
            "\n",
            "    accuracy                           0.80     30000\n",
            "   macro avg       0.58      0.50      0.45     30000\n",
            "weighted avg       0.71      0.80      0.71     30000\n",
            "\n",
            "Desempenho do Modelo LinearSVC com balanceamento:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.58      0.37      6022\n",
            "           1       0.85      0.62      0.72     23978\n",
            "\n",
            "    accuracy                           0.61     30000\n",
            "   macro avg       0.56      0.60      0.54     30000\n",
            "weighted avg       0.74      0.61      0.65     30000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisão dos dados (supondo que X e y já estejam prontos)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combinado, y, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]}\")\n",
        "print(f\"Tamanho do conjunto de teste: {X_test.shape[0]}\")\n",
        "print(f\"Total de amostras: {X_train.shape[0] + X_test.shape[0]}\")\n",
        "\n",
        "# Modelo 1: LinearSVC sem balanceamento\n",
        "modelo_puro = LinearSVC(C=0.01, dual=False, max_iter=10000)\n",
        "modelo_puro.fit(X_train, y_train)\n",
        "pred_puro = modelo_puro.predict(X_test)\n",
        "\n",
        "# Modelo 2: LinearSVC com balanceamento\n",
        "modelo_balanceado = LinearSVC(C=0.01, class_weight='balanced', dual=False, max_iter=10000)\n",
        "modelo_balanceado.fit(X_train, y_train)\n",
        "pred_balanceado = modelo_balanceado.predict(X_test)\n",
        "\n",
        "# Exibir métricas de ambos os modelos\n",
        "print(\"Desempenho do Modelo LinearSVC sem balanceamento:\")\n",
        "print(classification_report(y_test, pred_puro))\n",
        "\n",
        "print(\"Desempenho do Modelo LinearSVC com balanceamento:\")\n",
        "print(classification_report(y_test, pred_balanceado))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUmK6pU9hIef",
        "outputId": "29ceacf5-d0bd-4985-9e8f-6050b14bb444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treino: 58455\n",
            "Tamanho do conjunto de teste: 58455\n",
            "Total de amostras: 116910\n",
            "Desempenho do Modelo LinearSVC sem balanceamento:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.26      0.38     10905\n",
            "           1       0.85      0.97      0.91     47550\n",
            "\n",
            "    accuracy                           0.84     58455\n",
            "   macro avg       0.77      0.62      0.64     58455\n",
            "weighted avg       0.82      0.84      0.81     58455\n",
            "\n",
            "Desempenho do Modelo LinearSVC com balanceamento:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.73      0.56     10905\n",
            "           1       0.93      0.79      0.86     47550\n",
            "\n",
            "    accuracy                           0.78     58455\n",
            "   macro avg       0.69      0.76      0.71     58455\n",
            "weighted avg       0.84      0.78      0.80     58455\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisão dos dados (supondo que X e y já estejam prontos)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combinado, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]}\")\n",
        "print(f\"Tamanho do conjunto de teste: {X_test.shape[0]}\")\n",
        "print(f\"Total de amostras: {X_train.shape[0] + X_test.shape[0]}\")\n",
        "\n",
        "# Modelo 1: LinearSVC sem balanceamento\n",
        "modelo_puro = LinearSVC(C=0.01, dual=False, max_iter=10000)\n",
        "modelo_puro.fit(X_train, y_train)\n",
        "pred_puro = modelo_puro.predict(X_test)\n",
        "\n",
        "# Modelo 2: LinearSVC com balanceamento\n",
        "modelo_balanceado = LinearSVC(C=0.01, class_weight='balanced', dual=False, max_iter=10000)\n",
        "modelo_balanceado.fit(X_train, y_train)\n",
        "pred_balanceado = modelo_balanceado.predict(X_test)\n",
        "\n",
        "# Exibir métricas de ambos os modelos\n",
        "print(\"Desempenho do Modelo LinearSVC sem balanceamento:\")\n",
        "print(classification_report(y_test, pred_puro))\n",
        "\n",
        "print(\"Desempenho do Modelo LinearSVC com balanceamento:\")\n",
        "print(classification_report(y_test, pred_balanceado))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9nhYefBku_1",
        "outputId": "e1f83f68-5239-40ed-a1fd-c4ed19fdf257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treino: 81837\n",
            "Tamanho do conjunto de teste: 35073\n",
            "Total de amostras: 116910\n",
            "Desempenho do Modelo LinearSVC sem balanceamento:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.25      0.37      6543\n",
            "           1       0.85      0.97      0.91     28530\n",
            "\n",
            "    accuracy                           0.84     35073\n",
            "   macro avg       0.77      0.61      0.64     35073\n",
            "weighted avg       0.82      0.84      0.81     35073\n",
            "\n",
            "Desempenho do Modelo LinearSVC com balanceamento:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.73      0.56      6543\n",
            "           1       0.93      0.80      0.86     28530\n",
            "\n",
            "    accuracy                           0.78     35073\n",
            "   macro avg       0.69      0.76      0.71     35073\n",
            "weighted avg       0.84      0.78      0.80     35073\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teste com o RBF"
      ],
      "metadata": {
        "id": "ygqRGM596_iD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Caminho do arquivo de checkpoint\n",
        "CHECKPOINT_FILE = \"checkpoint_svc.pkl\"\n",
        "\n",
        "# Função para salvar progresso\n",
        "def salvar_checkpoint(modelo, nome_arquivo):\n",
        "    with open(nome_arquivo, 'wb') as f:\n",
        "        pickle.dump(modelo, f)\n",
        "\n",
        "# Função para carregar checkpoint (se existir)\n",
        "def carregar_checkpoint(nome_arquivo):\n",
        "    if os.path.exists(nome_arquivo):\n",
        "        with open(nome_arquivo, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "    return None\n",
        "\n",
        "# Divisão dos dados (supondo que X e y já estejam prontos)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combinado, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]}\")\n",
        "print(f\"Tamanho do conjunto de teste: {X_test.shape[0]}\")\n",
        "print(f\"Total de amostras: {X_train.shape[0] + X_test.shape[0]}\")\n",
        "\n",
        "# Definir os modelos\n",
        "modelos = {\n",
        "    \"SVC (RBF) sem balanceamento\": SVC(C=0.01, kernel='rbf'),\n",
        "    \"SVC (RBF) com balanceamento\": SVC(C=0.01, kernel='rbf', class_weight='balanced')\n",
        "}\n",
        "\n",
        "# Carregar progresso salvo, se existir\n",
        "progresso_salvo = carregar_checkpoint(CHECKPOINT_FILE)\n",
        "if progresso_salvo:\n",
        "    print(\"\\n🔄 Checkpoint encontrado! Retomando do último modelo treinado...\\n\")\n",
        "    modelos = {k: v for k, v in modelos.items() if k not in progresso_salvo}\n",
        "\n",
        "# Treinar os modelos com barra de progresso\n",
        "resultados = progresso_salvo if progresso_salvo else {}\n",
        "for nome, modelo in tqdm(modelos.items(), desc=\"Treinando modelos\"):\n",
        "    print(f\"\\n▶ Treinando {nome}...\")\n",
        "    modelo.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"✅ {nome} treinado! Fazendo previsões...\")\n",
        "    pred = modelo.predict(X_test)\n",
        "\n",
        "    # Salvar resultado\n",
        "    resultados[nome] = classification_report(y_test, pred, output_dict=True)\n",
        "    salvar_checkpoint(resultados, CHECKPOINT_FILE)\n",
        "\n",
        "    print(f\"📌 Resultados de {nome} salvos!\\n\")\n",
        "\n",
        "# Exibir relatório final\n",
        "print(\"\\n📊 Relatório Final de Todos os Modelos:\")\n",
        "for nome, relatorio in resultados.items():\n",
        "    print(f\"\\n🔹 {nome}\")\n",
        "    print(classification_report(y_test, pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-dzAHilH_0n",
        "outputId": "18e79bfe-04ac-4c75-92e1-8587fa3ccd37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treino: 81837\n",
            "Tamanho do conjunto de teste: 35073\n",
            "Total de amostras: 116910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTreinando modelos:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "▶ Treinando SVC (RBF) sem balanceamento...\n",
            "✅ SVC (RBF) sem balanceamento treinado! Fazendo previsões...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTreinando modelos:  50%|█████     | 1/2 [2:24:02<2:24:02, 8642.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 Resultados de SVC (RBF) sem balanceamento salvos!\n",
            "\n",
            "\n",
            "▶ Treinando SVC (RBF) com balanceamento...\n",
            "✅ SVC (RBF) com balanceamento treinado! Fazendo previsões...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelos: 100%|██████████| 2/2 [7:47:55<00:00, 14037.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 Resultados de SVC (RBF) com balanceamento salvos!\n",
            "\n",
            "\n",
            "📊 Relatório Final de Todos os Modelos:\n",
            "\n",
            "🔹 SVC (RBF) sem balanceamento\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.69      0.53      6543\n",
            "           1       0.92      0.80      0.85     28530\n",
            "\n",
            "    accuracy                           0.78     35073\n",
            "   macro avg       0.68      0.74      0.69     35073\n",
            "weighted avg       0.83      0.78      0.79     35073\n",
            "\n",
            "\n",
            "🔹 SVC (RBF) com balanceamento\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.69      0.53      6543\n",
            "           1       0.92      0.80      0.85     28530\n",
            "\n",
            "    accuracy                           0.78     35073\n",
            "   macro avg       0.68      0.74      0.69     35073\n",
            "weighted avg       0.83      0.78      0.79     35073\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teste com o Poly"
      ],
      "metadata": {
        "id": "HCVo4Fm87DM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Caminho do diretório para salvar checkpoints\n",
        "CHECKPOINT_DIR = \"/content/drive/My Drive/TCC/checkpoints\"\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "CHECKPOINT_FILE = os.path.join(CHECKPOINT_DIR, \"checkpoint_svc_poly.pkl\")\n",
        "\n",
        "# Função para salvar progresso\n",
        "def salvar_checkpoint(modelo, nome_arquivo):\n",
        "    with open(nome_arquivo, 'wb') as f:\n",
        "        pickle.dump(modelo, f)\n",
        "\n",
        "# Função para carregar checkpoint (se existir)\n",
        "def carregar_checkpoint(nome_arquivo):\n",
        "    if os.path.exists(nome_arquivo):\n",
        "        with open(nome_arquivo, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "    return None\n",
        "\n",
        "# Divisão dos dados (supondo que X e y já estejam prontos)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combinado, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]}\")\n",
        "print(f\"Tamanho do conjunto de teste: {X_test.shape[0]}\")\n",
        "print(f\"Total de amostras: {X_train.shape[0] + X_test.shape[0]}\")\n",
        "\n",
        "# Definir os modelos\n",
        "modelos = {\n",
        "    \"SVC (Poly) sem balanceamento\": SVC(C=0.01, kernel='poly'),\n",
        "    \"SVC (Poly) com balanceamento\": SVC(C=0.01, kernel='poly', class_weight='balanced')\n",
        "}\n",
        "\n",
        "# Carregar progresso salvo, se existir\n",
        "progresso_salvo = carregar_checkpoint(CHECKPOINT_FILE)\n",
        "if progresso_salvo:\n",
        "    print(\"\\n🔄 Checkpoint encontrado! Retomando do último modelo treinado...\\n\")\n",
        "    modelos = {k: v for k, v in modelos.items() if k not in progresso_salvo}\n",
        "\n",
        "# Treinar os modelos com barra de progresso\n",
        "resultados = progresso_salvo if progresso_salvo else {}\n",
        "for nome, modelo in tqdm(modelos.items(), desc=\"Treinando modelos\"):\n",
        "    print(f\"\\n▶ Treinando {nome}...\")\n",
        "    modelo.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"✅ {nome} treinado! Fazendo previsões...\")\n",
        "    pred = modelo.predict(X_test)\n",
        "\n",
        "    # Salvar resultado\n",
        "    resultados[nome] = classification_report(y_test, pred, output_dict=True)\n",
        "    salvar_checkpoint(resultados, CHECKPOINT_FILE)\n",
        "\n",
        "    print(f\"📌 Resultados de {nome} salvos!\")\n",
        "\n",
        "# Exibir relatório final\n",
        "print(\"\\n📊 Relatório Final de Todos os Modelos:\")\n",
        "for nome, relatorio in resultados.items():\n",
        "    print(f\"\\n🔹 {nome}\")\n",
        "    print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNVVTgVm60-p",
        "outputId": "4818666c-c5ee-4af7-9da0-ec0cf2a7cdaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treino: 81837\n",
            "Tamanho do conjunto de teste: 35073\n",
            "Total de amostras: 116910\n",
            "\n",
            "🔄 Checkpoint encontrado! Retomando do último modelo treinado...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTreinando modelos:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "▶ Treinando SVC (Poly) com balanceamento...\n",
            "✅ SVC (Poly) com balanceamento treinado! Fazendo previsões...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando modelos: 100%|██████████| 1/1 [3:33:58<00:00, 12838.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 Resultados de SVC (Poly) com balanceamento salvos!\n",
            "\n",
            "📊 Relatório Final de Todos os Modelos:\n",
            "\n",
            "🔹 SVC (Poly) sem balanceamento\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.64      0.53      6543\n",
            "           1       0.91      0.82      0.86     28530\n",
            "\n",
            "    accuracy                           0.79     35073\n",
            "   macro avg       0.68      0.73      0.70     35073\n",
            "weighted avg       0.82      0.79      0.80     35073\n",
            "\n",
            "\n",
            "🔹 SVC (Poly) com balanceamento\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.64      0.53      6543\n",
            "           1       0.91      0.82      0.86     28530\n",
            "\n",
            "    accuracy                           0.79     35073\n",
            "   macro avg       0.68      0.73      0.70     35073\n",
            "weighted avg       0.82      0.79      0.80     35073\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Diretório para salvar checkpoints\n",
        "diretorio_checkpoint = \"/content/drive/My Drive/TCC/checkpoints\"\n",
        "os.makedirs(diretorio_checkpoint, exist_ok=True)\n",
        "CHECKPOINT_FILE = os.path.join(diretorio_checkpoint, \"checkpoint_svc_linear.pkl\")\n",
        "\n",
        "# Função para salvar progresso\n",
        "def salvar_checkpoint(modelo, nome_arquivo):\n",
        "    with open(nome_arquivo, 'wb') as f:\n",
        "        pickle.dump(modelo, f)\n",
        "\n",
        "# Função para carregar checkpoint (se existir)\n",
        "def carregar_checkpoint(nome_arquivo):\n",
        "    if os.path.exists(nome_arquivo):\n",
        "        with open(nome_arquivo, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "    return None\n",
        "\n",
        "# Divisão dos dados (supondo que X e y já estejam prontos)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combinado, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]}\")\n",
        "print(f\"Tamanho do conjunto de teste: {X_test.shape[0]}\")\n",
        "print(f\"Total de amostras: {X_train.shape[0] + X_test.shape[0]}\")\n",
        "\n",
        "# Definir o modelo\n",
        "modelo_nome = \"SVC (Linear)\"\n",
        "modelo = SVC(C=0.01, kernel='linear', class_weight='balanced')\n",
        "\n",
        "# Carregar progresso salvo, se existir\n",
        "progresso_salvo = carregar_checkpoint(CHECKPOINT_FILE)\n",
        "if progresso_salvo:\n",
        "    print(\"\\n🔄 Checkpoint encontrado! Retomando do último progresso...\")\n",
        "    modelo = progresso_salvo\n",
        "else:\n",
        "    print(\"\\n🚀 Iniciando o treinamento do modelo...\")\n",
        "\n",
        "# Treinar o modelo com barra de progresso\n",
        "for _ in tqdm(range(1), desc=f\"Treinando {modelo_nome}\"):\n",
        "    modelo.fit(X_train, y_train)\n",
        "    salvar_checkpoint(modelo, CHECKPOINT_FILE)\n",
        "    print(f\"✅ {modelo_nome} treinado e checkpoint salvo!\")\n",
        "\n",
        "# Fazer previsões\n",
        "print(f\"\\n▶ Fazendo previsões com {modelo_nome}...\")\n",
        "pred = modelo.predict(X_test)\n",
        "\n",
        "# Exibir relatório final\n",
        "print(\"\\n📊 Relatório Final:\")\n",
        "print(classification_report(y_test, pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8iNvU5IOrsH",
        "outputId": "7025f4f1-639e-43d0-c050-b06de839b907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treino: 81837\n",
            "Tamanho do conjunto de teste: 35073\n",
            "Total de amostras: 116910\n",
            "\n",
            "🚀 Iniciando o treinamento do modelo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Treinando SVC (Linear): 100%|██████████| 1/1 [2:48:59<00:00, 10139.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ SVC (Linear) treinado e checkpoint salvo!\n",
            "\n",
            "▶ Fazendo previsões com SVC (Linear)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Relatório Final:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.73      0.56      6543\n",
            "           1       0.93      0.80      0.86     28530\n",
            "\n",
            "    accuracy                           0.78     35073\n",
            "   macro avg       0.69      0.76      0.71     35073\n",
            "weighted avg       0.84      0.78      0.80     35073\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "#\n",
        "# Divisão dos dados (supondo que X e y já estejam prontos)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combinado, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]}\")\n",
        "print(f\"Tamanho do conjunto de teste: {X_test.shape[0]}\")\n",
        "print(f\"Total de amostras: {X_train.shape[0] + X_test.shape[0]}\")\n",
        "\n",
        "# Modelo 1: LinearSVC sem balanceamento\n",
        "modelo_puro = LinearSVC(C=0.01, dual=False, max_iter=10000)\n",
        "modelo_puro.fit(X_train, y_train)\n",
        "pred_puro = modelo_puro.predict(X_test)\n",
        "\n",
        "# Modelo 2: LinearSVC com balanceamento\n",
        "modelo_balanceado = LinearSVC(C=0.01, class_weight='balanced', dual=False, max_iter=10000)\n",
        "modelo_balanceado.fit(X_train, y_train)\n",
        "pred_balanceado = modelo_balanceado.predict(X_test)\n",
        "\n",
        "# Exibir métricas de ambos os modelos\n",
        "print(\"Desempenho do Modelo LinearSVC sem balanceamento:\")\n",
        "print(balanced_accuracy_score(y_test, pred_puro))\n",
        "\n",
        "print(\"Desempenho do Modelo LinearSVC com balanceamento:\")\n",
        "print(balanced_accuracy_score(y_test, pred_balanceado))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yve5YfAmwPn-",
        "outputId": "bfebfadd-0c92-4d8b-f492-c5322d10b3cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treino: 81837\n",
            "Tamanho do conjunto de teste: 35073\n",
            "Total de amostras: 116910\n",
            "Desempenho do Modelo LinearSVC sem balanceamento:\n",
            "0.6145930753650565\n",
            "Desempenho do Modelo LinearSVC com balanceamento:\n",
            "0.7611698586058451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "v78ZIOXHA_VA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treino do Naive Bayes"
      ],
      "metadata": {
        "id": "VWVD4ozlvC5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, CategoricalNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Diretório do checkpoint\n",
        "CHECKPOINT_DIR = \"/content/drive/My Drive/TCC/checkpoints\"\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "CHECKPOINT_FILE = os.path.join(CHECKPOINT_DIR, \"checkpoint_naive_bayes.pkl\")\n",
        "\n",
        "# Função para salvar progresso\n",
        "def salvar_checkpoint(dados, nome_arquivo):\n",
        "    with open(nome_arquivo, 'wb') as f:\n",
        "        pickle.dump(dados, f)\n",
        "\n",
        "# Função para carregar progresso\n",
        "def carregar_checkpoint(nome_arquivo):\n",
        "    if os.path.exists(nome_arquivo):\n",
        "        with open(nome_arquivo, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "    return None\n",
        "\n",
        "# Modelos a serem testados\n",
        "modelos = {\n",
        "    \"GaussianNB\": GaussianNB(),\n",
        "    \"BernoulliNB\": BernoulliNB(),\n",
        "}\n",
        "\n",
        "# Carregar progresso salvo, se existir\n",
        "progresso_salvo = carregar_checkpoint(CHECKPOINT_FILE)\n",
        "if progresso_salvo:\n",
        "    print(\"\\n🔄 Checkpoint encontrado! Retomando do último modelo treinado...\\n\")\n",
        "    modelos = {k: v for k, v in modelos.items() if k not in progresso_salvo}\n",
        "\n",
        "# Armazenar resultados\n",
        "resultados = progresso_salvo if progresso_salvo else {}\n",
        "\n",
        "# Definir métricas de validação cruzada\n",
        "metricas = [\"accuracy\", \"precision_weighted\", \"recall_weighted\", \"f1_weighted\"]\n",
        "\n",
        "# Validar cada modelo com cross-validation\n",
        "for nome, modelo in tqdm(modelos.items(), desc=\"Validando modelos Naive Bayes\"):\n",
        "    print(f\"\\n▶ Treinando e validando {nome}...\")\n",
        "\n",
        "    scores = cross_validate(modelo, X_train, y_train, cv=5, scoring=metricas)\n",
        "\n",
        "    # Salvar métricas no dicionário de resultados\n",
        "    resultados[nome] = {\n",
        "        \"accuracy\": np.mean(scores[\"test_accuracy\"]),\n",
        "        \"precision\": np.mean(scores[\"test_precision_weighted\"]),\n",
        "        \"recall\": np.mean(scores[\"test_recall_weighted\"]),\n",
        "        \"f1_score\": np.mean(scores[\"test_f1_weighted\"])\n",
        "    }\n",
        "\n",
        "    print(f\"✅ {nome} validado!\")\n",
        "    print(f\"📊 Acurácia: {resultados[nome]['accuracy']:.4f}\")\n",
        "    print(f\"🎯 Precisão: {resultados[nome]['precision']:.4f}\")\n",
        "    print(f\"🔁 Recall: {resultados[nome]['recall']:.4f}\")\n",
        "    print(f\"📌 F1-score: {resultados[nome]['f1_score']:.4f}\")\n",
        "\n",
        "    # Salvar progresso\n",
        "    salvar_checkpoint(resultados, CHECKPOINT_FILE)\n",
        "    print(f\"📌 Resultados de {nome} salvos!\\n\")\n",
        "\n",
        "# Exibir relatório final\n",
        "print(\"\\n📊 Resultados da Validação Cruzada:\")\n",
        "for nome, dados in resultados.items():\n",
        "    print(f\"\\n🔹 {nome}:\")\n",
        "    print(f\"   ✅ Acurácia: {dados['accuracy']:.4f}\")\n",
        "    print(f\"   🎯 Precisão: {dados['precision']:.4f}\")\n",
        "    print(f\"   🔁 Recall: {dados['recall']:.4f}\")\n",
        "    print(f\"   📌 F1-score: {dados['f1_score']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYdomioWvGSs",
        "outputId": "591f6187-1d2a-40a8-ccbe-0aa59317b490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidando modelos Naive Bayes:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "▶ Treinando e validando GaussianNB...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidando modelos Naive Bayes:  50%|█████     | 1/2 [00:14<00:14, 14.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GaussianNB validado!\n",
            "📊 Acurácia: 0.5810\n",
            "🎯 Precisão: 0.8002\n",
            "🔁 Recall: 0.5810\n",
            "📌 F1-score: 0.6259\n",
            "📌 Resultados de GaussianNB salvos!\n",
            "\n",
            "\n",
            "▶ Treinando e validando BernoulliNB...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validando modelos Naive Bayes: 100%|██████████| 2/2 [00:31<00:00, 15.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ BernoulliNB validado!\n",
            "📊 Acurácia: 0.7148\n",
            "🎯 Precisão: 0.8111\n",
            "🔁 Recall: 0.7148\n",
            "📌 F1-score: 0.7434\n",
            "📌 Resultados de BernoulliNB salvos!\n",
            "\n",
            "\n",
            "📊 Resultados da Validação Cruzada:\n",
            "\n",
            "🔹 GaussianNB:\n",
            "   ✅ Acurácia: 0.5810\n",
            "   🎯 Precisão: 0.8002\n",
            "   🔁 Recall: 0.5810\n",
            "   📌 F1-score: 0.6259\n",
            "\n",
            "🔹 BernoulliNB:\n",
            "   ✅ Acurácia: 0.7148\n",
            "   🎯 Precisão: 0.8111\n",
            "   🔁 Recall: 0.7148\n",
            "   📌 F1-score: 0.7434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.naive_bayes import MultinomialNB, CategoricalNB\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Caminho para salvar o checkpoint\n",
        "CHECKPOINT_FILE = \"/content/drive/My Drive/TCC/checkpoints/nb_multinomial_categorical.pkl\"\n",
        "\n",
        "# Função para salvar progresso\n",
        "def salvar_checkpoint(modelo, nome_arquivo):\n",
        "    with open(nome_arquivo, 'wb') as f:\n",
        "        pickle.dump(modelo, f)\n",
        "\n",
        "# Função para carregar checkpoint\n",
        "def carregar_checkpoint(nome_arquivo):\n",
        "    if os.path.exists(nome_arquivo):\n",
        "        with open(nome_arquivo, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "    return {}\n",
        "\n",
        "# Aplicar MinMaxScaler para garantir valores positivos\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Definir os modelos a serem testados\n",
        "modelos = {\n",
        "    \"MultinomialNB\": MultinomialNB(),\n",
        "    \"CategoricalNB\": CategoricalNB()\n",
        "}\n",
        "\n",
        "# Carregar progresso salvo, se existir\n",
        "progresso_salvo = carregar_checkpoint(CHECKPOINT_FILE)\n",
        "if progresso_salvo:\n",
        "    print(\"\\n🔄 Checkpoint encontrado! Retomando do último modelo validado...\\n\")\n",
        "    modelos = {k: v for k, v in modelos.items() if k not in progresso_salvo}\n",
        "\n",
        "# Validar os modelos com Cross-Validation\n",
        "resultados = progresso_salvo if progresso_salvo else {}\n",
        "metricas = [\"accuracy\", \"precision_weighted\", \"recall_weighted\", \"f1_weighted\"]\n",
        "\n",
        "for nome, modelo in tqdm(modelos.items(), desc=\"Validando modelos Naive Bayes\"):\n",
        "    print(f\"\\n▶ Treinando e validando {nome}...\")\n",
        "    scores = cross_validate(modelo, X_train_scaled, y_train, cv=5, scoring=metricas)\n",
        "\n",
        "    # Calcular médias das métricas\n",
        "    resultados[nome] = {\n",
        "        \"accuracy\": np.mean(scores.get(\"test_accuracy\", [0])),\n",
        "        \"precision\": np.mean(scores.get(\"test_precision_weighted\", [0])),\n",
        "        \"recall\": np.mean(scores.get(\"test_recall_weighted\", [0])),\n",
        "        \"f1_score\": np.mean(scores.get(\"test_f1_weighted\", [0]))\n",
        "    }\n",
        "\n",
        "    print(f\"✅ {nome} validado!\")\n",
        "    print(f\"📊 Acurácia: {resultados[nome]['accuracy']:.4f}\")\n",
        "    print(f\"🎯 Precisão: {resultados[nome]['precision']:.4f}\")\n",
        "    print(f\"🔁 Recall: {resultados[nome]['recall']:.4f}\")\n",
        "    print(f\"📌 F1-score: {resultados[nome]['f1_score']:.4f}\")\n",
        "\n",
        "    # Salvar progresso\n",
        "    salvar_checkpoint(resultados, CHECKPOINT_FILE)\n",
        "    print(f\"📌 Resultados de {nome} salvos!\\n\")\n",
        "\n",
        "# Exibir relatório final\n",
        "top_model = max(resultados, key=lambda k: resultados[k][\"f1_score\"])\n",
        "print(\"\\n📊 Resultados Finais:\")\n",
        "for nome, metricas in resultados.items():\n",
        "    print(f\"\\n🔹 {nome}:\")\n",
        "    print(f\"   ✅ Acurácia: {metricas['accuracy']:.4f}\")\n",
        "    print(f\"   🎯 Precisão: {metricas['precision']:.4f}\")\n",
        "    print(f\"   🔁 Recall: {metricas['recall']:.4f}\")\n",
        "    print(f\"   📌 F1-score: {metricas['f1_score']:.4f}\")\n",
        "\n",
        "print(f\"\\n🏆 Melhor modelo: {top_model} com F1-score de {resultados[top_model]['f1_score']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEpLav1CKz0m",
        "outputId": "abed1eca-9770-44c1-86d2-753c9cc8c136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidando modelos Naive Bayes:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "▶ Treinando e validando MultinomialNB...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rValidando modelos Naive Bayes:  50%|█████     | 1/2 [00:04<00:04,  4.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ MultinomialNB validado!\n",
            "📊 Acurácia: 0.8157\n",
            "🎯 Precisão: 0.7983\n",
            "🔁 Recall: 0.8157\n",
            "📌 F1-score: 0.7345\n",
            "📌 Resultados de MultinomialNB salvos!\n",
            "\n",
            "\n",
            "▶ Treinando e validando CategoricalNB...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/naive_bayes.py\", line 106, in predict\n",
            "    jll = self._joint_log_likelihood(X)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/naive_bayes.py\", line 1537, in _joint_log_likelihood\n",
            "    jll += self.feature_log_prob_[i][:, indices].T\n",
            "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/naive_bayes.py\", line 106, in predict\n",
            "    jll = self._joint_log_likelihood(X)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/naive_bayes.py\", line 1537, in _joint_log_likelihood\n",
            "    jll += self.feature_log_prob_[i][:, indices].T\n",
            "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/naive_bayes.py\", line 106, in predict\n",
            "    jll = self._joint_log_likelihood(X)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/naive_bayes.py\", line 1537, in _joint_log_likelihood\n",
            "    jll += self.feature_log_prob_[i][:, indices].T\n",
            "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/naive_bayes.py\", line 106, in predict\n",
            "    jll = self._joint_log_likelihood(X)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/naive_bayes.py\", line 1537, in _joint_log_likelihood\n",
            "    jll += self.feature_log_prob_[i][:, indices].T\n",
            "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 380, in _score\n",
            "    y_pred = method_caller(\n",
            "             ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py\", line 90, in _cached_call\n",
            "    result, _ = _get_response_values(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_response.py\", line 214, in _get_response_values\n",
            "    y_pred = prediction_method(X)\n",
            "             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/naive_bayes.py\", line 106, in predict\n",
            "    jll = self._joint_log_likelihood(X)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/naive_bayes.py\", line 1537, in _joint_log_likelihood\n",
            "    jll += self.feature_log_prob_[i][:, indices].T\n",
            "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
            "\n",
            "  warnings.warn(\n",
            "Validando modelos Naive Bayes: 100%|██████████| 2/2 [00:40<00:00, 20.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CategoricalNB validado!\n",
            "📊 Acurácia: nan\n",
            "🎯 Precisão: nan\n",
            "🔁 Recall: nan\n",
            "📌 F1-score: nan\n",
            "📌 Resultados de CategoricalNB salvos!\n",
            "\n",
            "\n",
            "📊 Resultados Finais:\n",
            "\n",
            "🔹 MultinomialNB:\n",
            "   ✅ Acurácia: 0.8157\n",
            "   🎯 Precisão: 0.7983\n",
            "   🔁 Recall: 0.8157\n",
            "   📌 F1-score: 0.7345\n",
            "\n",
            "🔹 CategoricalNB:\n",
            "   ✅ Acurácia: nan\n",
            "   🎯 Precisão: nan\n",
            "   🔁 Recall: nan\n",
            "   📌 F1-score: nan\n",
            "\n",
            "🏆 Melhor modelo: MultinomialNB com F1-score de 0.7345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_FILE = \"checkpoint_multinomial.pkl\"\n",
        "\n",
        "def salvar_checkpoint(dados, nome_arquivo):\n",
        "    with open(nome_arquivo, 'wb') as f:\n",
        "        pickle.dump(dados, f)\n",
        "\n",
        "def carregar_checkpoint(nome_arquivo):\n",
        "    if os.path.exists(nome_arquivo):\n",
        "        with open(nome_arquivo, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "    return None\n",
        "\n",
        "# 🔹 Dividir os dados na proporção 70% treino / 30% teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combinado, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# 🔹 Balanceamento\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_bal, y_train_bal = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"\\n📊 Antes do balanceamento: {Counter(y_train)}\")\n",
        "print(f\"📊 Depois do balanceamento: {Counter(y_train_bal)}\")\n",
        "\n",
        "# 🔹 Normalização\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_train_bal_scaled = scaler.fit_transform(X_train_bal)\n",
        "\n",
        "# 🔹 Modelo MultinomialNB\n",
        "modelo = MultinomialNB()\n",
        "\n",
        "# 🔹 Treino e teste (DADOS DESBALANCEADOS)\n",
        "modelo.fit(X_train_scaled, y_train)\n",
        "y_pred = modelo.predict(X_test_scaled)\n",
        "\n",
        "# 🔹 Métricas\n",
        "resultados = {\n",
        "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "    \"precision\": precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
        "    \"recall\": recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
        "    \"f1_score\": f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "}\n",
        "\n",
        "print(\"\\n🔹 MultinomialNB (DADOS DESBALANCEADOS):\")\n",
        "print(resultados)\n",
        "print(\"\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "# 🔹 Treino e teste (DADOS BALANCEADOS)\n",
        "modelo.fit(X_train_bal_scaled, y_train_bal)\n",
        "y_pred_bal = modelo.predict(X_test_scaled)\n",
        "\n",
        "# 🔹 Métricas\n",
        "resultados_bal = {\n",
        "    \"accuracy\": accuracy_score(y_test, y_pred_bal),\n",
        "    \"precision\": precision_score(y_test, y_pred_bal, average='weighted', zero_division=0),\n",
        "    \"recall\": recall_score(y_test, y_pred_bal, average='weighted', zero_division=0),\n",
        "    \"f1_score\": f1_score(y_test, y_pred_bal, average='weighted', zero_division=0)\n",
        "}\n",
        "\n",
        "print(\"\\n🔹 MultinomialNB (DADOS BALANCEADOS):\")\n",
        "print(resultados_bal)\n",
        "print(\"\\n\", classification_report(y_test, y_pred_bal, zero_division=0))\n",
        "\n",
        "# 🔹 Salvar resultados\n",
        "salvar_checkpoint({\"desbalanceado\": resultados, \"balanceado\": resultados_bal}, CHECKPOINT_FILE)\n",
        "\n",
        "# 🔹 Melhor modelo\n",
        "melhor = max(resultados, key=lambda x: resultados[x])\n",
        "print(f\"\\n🏆 Melhor abordagem: {melhor} com F1-score de {resultados[melhor]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiiHzWEwvZ4o",
        "outputId": "92407aeb-a66e-4667-c9f1-ab6381a5cbb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Antes do balanceamento: Counter({1: 66633, 0: 15204})\n",
            "📊 Depois do balanceamento: Counter({1: 66633, 0: 66633})\n",
            "\n",
            "🔹 MultinomialNB (DADOS DESBALANCEADOS):\n",
            "{'accuracy': 0.814615231089442, 'precision': 0.7823774991925648, 'recall': 0.814615231089442, 'f1_score': 0.7327612392292684}\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.00      0.01      6516\n",
            "           1       0.81      1.00      0.90     28557\n",
            "\n",
            "    accuracy                           0.81     35073\n",
            "   macro avg       0.73      0.50      0.45     35073\n",
            "weighted avg       0.78      0.81      0.73     35073\n",
            "\n",
            "\n",
            "🔹 MultinomialNB (DADOS BALANCEADOS):\n",
            "{'accuracy': 0.741596099563767, 'precision': 0.8190784943352176, 'recall': 0.741596099563767, 'f1_score': 0.7654320878535451}\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.70      0.50      6516\n",
            "           1       0.92      0.75      0.83     28557\n",
            "\n",
            "    accuracy                           0.74     35073\n",
            "   macro avg       0.65      0.73      0.66     35073\n",
            "weighted avg       0.82      0.74      0.77     35073\n",
            "\n",
            "\n",
            "🏆 Melhor abordagem: accuracy com F1-score de 0.8146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_FILE = \"checkpoint_bernoulli_desbalanceado.pkl\"\n",
        "\n",
        "def salvar_checkpoint(dados, nome_arquivo):\n",
        "    with open(nome_arquivo, 'wb') as f:\n",
        "        pickle.dump(dados, f)\n",
        "\n",
        "# 🔹 Dividir os dados na proporção 70% treino / 30% teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combinado, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# 🔹 Normalização\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 🔹 Modelo BernoulliNB\n",
        "modelo = BernoulliNB()\n",
        "\n",
        "# 🔹 Treinamento e teste com dados DESBALANCEADOS\n",
        "modelo.fit(X_train_scaled, y_train)\n",
        "y_pred = modelo.predict(X_test_scaled)\n",
        "\n",
        "# 🔹 Métricas\n",
        "resultados = {\n",
        "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "    \"precision\": precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
        "    \"recall\": recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
        "    \"f1_score\": f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "}\n",
        "\n",
        "print(\"\\n🔹 BernoulliNB (DADOS DESBALANCEADOS):\")\n",
        "print(resultados)\n",
        "print(\"\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "# 🔹 Salvar resultados\n",
        "salvar_checkpoint(resultados, CHECKPOINT_FILE)\n",
        "\n",
        "# 🔹 Melhor métrica\n",
        "melhor = max(resultados, key=lambda x: resultados[x])\n",
        "print(f\"\\n🏆 Melhor métrica: {melhor} com F1-score de {resultados[melhor]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NfKWWuJcMTj",
        "outputId": "ee97f5b5-f39e-4a9a-86af-04834bad1a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 BernoulliNB (DADOS DESBALANCEADOS):\n",
            "{'accuracy': 0.8124198101103413, 'precision': 0.7133921495809186, 'recall': 0.8124198101103413, 'f1_score': 0.7319152880941883}\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.01      0.01      6516\n",
            "           1       0.81      1.00      0.90     28557\n",
            "\n",
            "    accuracy                           0.81     35073\n",
            "   macro avg       0.54      0.50      0.45     35073\n",
            "weighted avg       0.71      0.81      0.73     35073\n",
            "\n",
            "\n",
            "🏆 Melhor métrica: accuracy com F1-score de 0.8124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_FILE = \"checkpoint_bernoulli_balanceado.pkl\"\n",
        "\n",
        "def salvar_checkpoint(dados, nome_arquivo):\n",
        "    with open(nome_arquivo, 'wb') as f:\n",
        "        pickle.dump(dados, f)\n",
        "\n",
        "# 🔹 Dividir os dados na proporção 70% treino / 30% teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combinado, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# 🔹 Balanceamento\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_bal, y_train_bal = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"\\n📊 Antes do balanceamento: {Counter(y_train)}\")\n",
        "print(f\"📊 Depois do balanceamento: {Counter(y_train_bal)}\")\n",
        "\n",
        "# 🔹 Normalização\n",
        "scaler = MinMaxScaler()\n",
        "X_train_bal_scaled = scaler.fit_transform(X_train_bal)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 🔹 Modelo BernoulliNB\n",
        "modelo = BernoulliNB()\n",
        "\n",
        "# 🔹 Treinamento e teste com dados BALANCEADOS\n",
        "modelo.fit(X_train_bal_scaled, y_train_bal)\n",
        "y_pred_bal = modelo.predict(X_test_scaled)\n",
        "\n",
        "# 🔹 Métricas\n",
        "resultados_bal = {\n",
        "    \"accuracy\": accuracy_score(y_test, y_pred_bal),\n",
        "    \"precision\": precision_score(y_test, y_pred_bal, average='weighted', zero_division=0),\n",
        "    \"recall\": recall_score(y_test, y_pred_bal, average='weighted', zero_division=0),\n",
        "    \"f1_score\": f1_score(y_test, y_pred_bal, average='weighted', zero_division=0)\n",
        "}\n",
        "\n",
        "print(\"\\n🔹 BernoulliNB (DADOS BALANCEADOS):\")\n",
        "print(resultados_bal)\n",
        "print(\"\\n\", classification_report(y_test, y_pred_bal, zero_division=0))\n",
        "\n",
        "# 🔹 Salvar resultados\n",
        "salvar_checkpoint(resultados_bal, CHECKPOINT_FILE)\n",
        "\n",
        "# 🔹 Melhor métrica\n",
        "melhor = max(resultados_bal, key=lambda x: resultados_bal[x])\n",
        "print(f\"\\n🏆 Melhor métrica: {melhor} com F1-score de {resultados_bal[melhor]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HtqYmjeHPiP",
        "outputId": "2c9c1c10-1843-4388-9bfa-270cae81c5c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Antes do balanceamento: Counter({1: 66633, 0: 15204})\n",
            "📊 Depois do balanceamento: Counter({1: 66633, 0: 66633})\n",
            "\n",
            "🔹 BernoulliNB (DADOS BALANCEADOS):\n",
            "{'accuracy': 0.1940238930231232, 'precision': 0.7789282121860173, 'recall': 0.1940238930231232, 'f1_score': 0.07640915221613886}\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      1.00      0.31      6516\n",
            "           1       0.91      0.01      0.02     28557\n",
            "\n",
            "    accuracy                           0.19     35073\n",
            "   macro avg       0.55      0.50      0.17     35073\n",
            "weighted avg       0.78      0.19      0.08     35073\n",
            "\n",
            "\n",
            "🏆 Melhor métrica: precision com F1-score de 0.7789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregando o léxico e testando"
      ],
      "metadata": {
        "id": "RsZTZThI8CDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminhos dos arquivos\n",
        "path_csv = \"/content/drive/MyDrive/TCC/OpLexicon-main/OpLexicon.csv\"\n",
        "path_txt = \"/content/drive/MyDrive/TCC/OpLexicon-main/lexico_v3.0.txt\"\n",
        "\n",
        "# Verificar se os arquivos existem\n",
        "print(f\"Arquivo OpLexicon.csv {'encontrado' if os.path.exists(path_csv) else 'NÃO encontrado'}\")\n",
        "print(f\"Arquivo lexico_v3.0.txt {'encontrado' if os.path.exists(path_txt) else 'NÃO encontrado'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNZaZUkd1iqb",
        "outputId": "6d19f7a2-118c-48cd-ce0e-501677538bde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo OpLexicon.csv encontrado\n",
            "Arquivo lexico_v3.0.txt encontrado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar linhas do CSV\n",
        "with open(path_csv, \"r\", encoding=\"utf-8\") as f:\n",
        "    num_lines_csv = sum(1 for line in f)\n",
        "\n",
        "# Contar linhas do TXT\n",
        "with open(path_txt, \"r\", encoding=\"utf-8\") as f:\n",
        "    num_lines_txt = sum(1 for line in f)\n",
        "\n",
        "print(f\"Linhas no OpLexicon.csv: {num_lines_csv}\")\n",
        "print(f\"Linhas no lexico_v3.0.txt: {num_lines_txt}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOs-tO4M1me8",
        "outputId": "6b051650-73bf-455b-cd02-10b159540f84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linhas no OpLexicon.csv: 24474\n",
            "Linhas no lexico_v3.0.txt: 32191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar as primeiras 10 linhas do CSV\n",
        "print(\"\\nPrimeiras linhas do OpLexicon.csv:\")\n",
        "with open(path_csv, \"r\", encoding=\"utf-8\") as f:\n",
        "    for _ in range(10):\n",
        "        print(f.readline().strip())\n",
        "\n",
        "# Mostrar as primeiras 10 linhas do TXT\n",
        "print(\"\\nPrimeiras linhas do lexico_v3.0.txt:\")\n",
        "with open(path_txt, \"r\", encoding=\"utf-8\") as f:\n",
        "    for _ in range(10):\n",
        "        print(f.readline().strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeDBqkuO1tDy",
        "outputId": "b15f74de-85eb-4409-e389-bafdc9fff9e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Primeiras linhas do OpLexicon.csv:\n",
            "abafada,adj,-1\n",
            "abafadas,adj,-1\n",
            "abafado,adj,-1\n",
            "abafados,adj,-1\n",
            "abafante,adj,-1\n",
            "abafantes,adj,-1\n",
            "abaixada,adj,-1\n",
            "abaixadas,adj,-1\n",
            "abaixado,adj,-1\n",
            "abaixados,adj,-1\n",
            "\n",
            "Primeiras linhas do lexico_v3.0.txt:\n",
            "=[,emot,-1,A\n",
            "=@,emot,-1,A\n",
            "=p,emot,-1,A\n",
            "=P,emot,-1,A\n",
            "=x,emot,-1,A\n",
            "=d,emot,1,A\n",
            "=D,emot,1,A\n",
            ";),emot,1,A\n",
            ";),emot,1,A\n",
            ";@,emot,-1,A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar CSV\n",
        "df_csv = pd.read_csv(path_csv, encoding=\"utf-8\", sep=\",\", header=None)\n",
        "df_csv.columns = [\"palavra\", \"classe\", \"polaridade\"]\n",
        "\n",
        "# Carregar TXT (supondo que tenha a mesma estrutura)\n",
        "df_txt = pd.read_csv(path_txt, encoding=\"utf-8\", sep=\",\", header=None)\n",
        "df_txt.columns = [\"palavra\", \"classe\", \"polaridade\", \"tipo_polaridade\"]\n",
        "\n",
        "# Verificar o número total de palavras\n",
        "print(f\"Total de palavras no CSV: {df_csv.shape[0]}\")\n",
        "print(f\"Total de palavras no TXT: {df_txt.shape[0]}\")\n",
        "\n",
        "# Verificar diferenças entre os arquivos\n",
        "palavras_txt = set(df_txt[\"palavra\"])\n",
        "palavras_csv = set(df_csv[\"palavra\"])\n",
        "\n",
        "palavras_exclusivas_txt = palavras_txt - palavras_csv\n",
        "print(f\"Palavras que estão apenas no TXT: {len(palavras_exclusivas_txt)}\")\n",
        "print(list(palavras_exclusivas_txt)[:10])  # Mostrar apenas as 10 primeiras\n",
        "\n",
        "# Palavras que mudaram de polaridade entre os arquivos\n",
        "\n",
        "df_merged = df_csv.merge(df_txt, on=\"palavra\", suffixes=(\"_csv\", \"_txt\"))\n",
        "diferenca_polaridade = df_merged[df_merged[\"polaridade_csv\"] != df_merged[\"polaridade_txt\"]]\n",
        "\n",
        "print(f\"Número de palavras com polaridade diferente: {diferenca_polaridade.shape[0]}\")\n",
        "print(diferenca_polaridade.head(10))  # Mostrar algumas diferenças"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9wJ29bY1y5i",
        "outputId": "732c36c2-4e0d-43c8-b6ee-a66d8b49e97f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de palavras no CSV: 24474\n",
            "Total de palavras no TXT: 32191\n",
            "Palavras que estão apenas no TXT: 7673\n",
            "['conformar', 'confederar-se', 'encrespar', 'descantar', 'empaçocar', 'excetuar', 'desvariar', 'alivelar', 'decodificar', 'desengranzar']\n",
            "Número de palavras com polaridade diferente: 29\n",
            "                palavra classe_csv  polaridade_csv classe_txt  polaridade_txt  \\\n",
            "2987           auxiliar        adj              -1         vb               0   \n",
            "4893   cinematográficos        adj               0        adj               1   \n",
            "4894   cinematográficos        adj               1        adj               0   \n",
            "4916           circular        adj               1         vb               0   \n",
            "6205              cruas        adj               0        adj               1   \n",
            "6206              cruas        adj               1        adj               0   \n",
            "6233            cubanos        adj               0        adj               1   \n",
            "6234            cubanos        adj               1        adj               0   \n",
            "8646             educar        adj               1         vb               0   \n",
            "10175        espanholas        adj               0        adj               1   \n",
            "\n",
            "      tipo_polaridade  \n",
            "2987                A  \n",
            "4893                A  \n",
            "4894                M  \n",
            "4916                A  \n",
            "6205                A  \n",
            "6206                M  \n",
            "6233                A  \n",
            "6234                M  \n",
            "8646                A  \n",
            "10175               A  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_polarity(word):\n",
        "    result = df_txt[df_txt[\"palavra\"] == word]\n",
        "    if not result.empty:\n",
        "        return result[\"polaridade\"].values[0]\n",
        "    return \"Neutro/Não encontrado\"\n",
        "\n",
        "# Testando a função\n",
        "print(get_polarity(\"feliz\"))\n",
        "print(get_polarity(\"chato\"))\n",
        "print(get_polarity(\"computador\"))  # Palavra neutra\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1jqtFOT7-w8",
        "outputId": "93a1a239-a314-4b47-832c-f1f248cc7d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n",
            "Neutro/Não encontrado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_"
      ],
      "metadata": {
        "id": "wPtw4oP2clS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrando o Léxico"
      ],
      "metadata": {
        "id": "YDO7SUePTNtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho para o arquivo do OpLexicon\n",
        "LEXICON_PATH = \"/content/drive/MyDrive/TCC/OpLexicon-main/lexico_v3.0.txt\"\n",
        "\n",
        "# Carregar o léxico separando os campos por vírgula\n",
        "lexico_df = pd.read_csv(LEXICON_PATH, sep=\",\", header=None, names=[\"palavra\", \"classe\", \"polaridade\", \"origem\"])\n",
        "\n",
        "# Limpar a coluna de palavra (remover o símbolo '=')\n",
        "lexico_df[\"palavra\"] = lexico_df[\"palavra\"].str.replace(\"=\", \"\", regex=False)\n",
        "\n",
        "# Visualizar\n",
        "lexico_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LXpDXm2yTQ5R",
        "outputId": "703481ee-9474-4679-e85e-ff4ded405f61"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  palavra classe  polaridade origem\n",
              "0       [   emot          -1      A\n",
              "1       @   emot          -1      A\n",
              "2       p   emot          -1      A\n",
              "3       P   emot          -1      A\n",
              "4       x   emot          -1      A"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52854c2c-e2f1-41c7-ae54-a9b898a1bca8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>palavra</th>\n",
              "      <th>classe</th>\n",
              "      <th>polaridade</th>\n",
              "      <th>origem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[</td>\n",
              "      <td>emot</td>\n",
              "      <td>-1</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@</td>\n",
              "      <td>emot</td>\n",
              "      <td>-1</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>p</td>\n",
              "      <td>emot</td>\n",
              "      <td>-1</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P</td>\n",
              "      <td>emot</td>\n",
              "      <td>-1</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>x</td>\n",
              "      <td>emot</td>\n",
              "      <td>-1</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52854c2c-e2f1-41c7-ae54-a9b898a1bca8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-52854c2c-e2f1-41c7-ae54-a9b898a1bca8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-52854c2c-e2f1-41c7-ae54-a9b898a1bca8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c8c6ce8b-f4de-4e60-9363-46c485f7f64d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c8c6ce8b-f4de-4e60-9363-46c485f7f64d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c8c6ce8b-f4de-4e60-9363-46c485f7f64d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "lexico_df",
              "summary": "{\n  \"name\": \"lexico_df\",\n  \"rows\": 32191,\n  \"fields\": [\n    {\n      \"column\": \"palavra\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 32119,\n        \"samples\": [\n          \"hermafroditas\",\n          \"desenrolar-se\",\n          \"reverenciosos\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"classe\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"htag\",\n          \"vb det n prp\",\n          \"emot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"polaridade\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": 1,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -1,\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"origem\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"M\",\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar dicionário {palavra: polaridade}\n",
        "# A polaridade será: -1 (negativa), 1 (positiva), 0 (neutra)\n",
        "lexico_dict = dict(zip(lexico_df[\"palavra\"], lexico_df[\"polaridade\"]))"
      ],
      "metadata": {
        "id": "LOugOSukUnDU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extrair pontuação de polaridade com base no léxico"
      ],
      "metadata": {
        "id": "3ZnUpDACWF8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def calcular_polaridade_lexico(texto, lexico):\n",
        "    palavras = re.findall(r'\\b\\w+\\b', texto.lower())\n",
        "    polaridade_total = sum([lexico.get(palavra, 0) for palavra in palavras])\n",
        "    return polaridade_total"
      ],
      "metadata": {
        "id": "UlkvbYaVWLB-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregando os dados originais"
      ],
      "metadata": {
        "id": "V79OW3j-YIhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "textos = []\n",
        "y = []\n",
        "\n",
        "# Pasta onde estão os arquivos JSON\n",
        "pasta_dados = \"/content/drive/MyDrive/TCC/Dados/Reviews Da Steam filtradas/Combined/part50/\"\n",
        "\n",
        "# Percorrer todos os arquivos JSON\n",
        "for arquivo in tqdm(os.listdir(pasta_dados), desc=\"Lendo arquivos\"):\n",
        "    caminho = os.path.join(pasta_dados, arquivo)\n",
        "\n",
        "    with open(caminho, \"r\", encoding=\"utf-8\") as f:\n",
        "        dados = json.load(f)\n",
        "\n",
        "        # Garante que todas as chaves existem\n",
        "        if \"review\" in dados and \"voted_up\" in dados:\n",
        "            reviews_dict = dados[\"review\"]\n",
        "            votos_dict = dados[\"voted_up\"]\n",
        "\n",
        "            # Interseção para garantir que review e voted_up existem para o mesmo ID\n",
        "            ids_validos = set(reviews_dict.keys()) & set(votos_dict.keys())\n",
        "\n",
        "            for id_ in ids_validos:\n",
        "                texto = reviews_dict[id_]\n",
        "                rotulo = int(votos_dict[id_])  # True → 1, False → 0\n",
        "\n",
        "                textos.append(texto)\n",
        "                y.append(rotulo)\n",
        "\n",
        "# Converter para NumPy array\n",
        "y = np.array(y)\n",
        "\n",
        "# Exibir resultado\n",
        "print(f\"Total de textos carregados: {len(textos)}\")\n",
        "print(f\"Exemplo de texto: {textos[0][:100]}...\")\n",
        "print(f\"Exemplo de rótulo: {y[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb7tny38YM93",
        "outputId": "e44e2030-c52c-45d1-9263-452b231efc73"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Lendo arquivos: 100%|██████████| 10/10 [00:02<00:00,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de textos carregados: 116910\n",
            "Exemplo de texto: Bom jogo para passar o tempo, divertido e viciante....\n",
            "Exemplo de rótulo: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textos = []\n",
        "\n",
        "# Pasta onde estão os arquivos JSON\n",
        "pasta_dados = \"/content/drive/MyDrive/TCC/Dados/Reviews Da Steam filtradas/Combined/part50/\"\n",
        "\n",
        "# Percorrer todos os arquivos JSON\n",
        "for arquivo in tqdm(os.listdir(pasta_dados), desc=\"Lendo arquivos\"):\n",
        "    caminho = os.path.join(pasta_dados, arquivo)\n",
        "\n",
        "    with open(caminho, \"r\", encoding=\"utf-8\") as f:\n",
        "        dados = json.load(f)\n",
        "\n",
        "        # Garante que todas as chaves existem\n",
        "        if \"review\" in dados and \"voted_up\" in dados:\n",
        "            reviews_dict = dados[\"review\"]\n",
        "\n",
        "            # Interseção para garantir que review e voted_up existem para o mesmo ID\n",
        "            ids_validos = set(reviews_dict.keys())\n",
        "\n",
        "            for id_ in ids_validos:\n",
        "                texto = reviews_dict[id_]\n",
        "\n",
        "                textos.append(texto)\n",
        "\n",
        "# Exibir resultado\n",
        "print(f\"Total de textos carregados: {len(textos)}\")\n",
        "print(f\"Exemplo de texto: {textos[0][:100]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTTK0zuy0doT",
        "outputId": "aa335b10-c3e9-4236-8adf-559d69b5020d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Lendo arquivos: 100%|██████████| 10/10 [00:11<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de textos carregados: 116910\n",
            "Exemplo de texto: Péssimo....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicando o léxico aos textos:"
      ],
      "metadata": {
        "id": "jqMWOFaEbN1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "#Esse código:\n",
        "#Faz a tokenização simples dos textos.\n",
        "#Soma as polaridades das palavras encontradas no léxico.\n",
        "#Retorna um valor numérico por texto.\n",
        "\n",
        "# Função para calcular a polaridade de um texto com base no léxico\n",
        "def calcular_polaridade_lexico(texto, lexico):\n",
        "    # Tokenização simples (palavras minúsculas sem pontuação)\n",
        "    palavras = re.findall(r'\\b\\w+\\b', texto.lower())\n",
        "\n",
        "    polaridade_total = 0\n",
        "    for palavra in palavras:\n",
        "        if palavra in lexico:\n",
        "            polaridade_total += lexico[palavra]\n",
        "\n",
        "    return polaridade_total\n",
        "\n",
        "# Aplicar a função a todos os textos\n",
        "polaridades_lexico = [calcular_polaridade_lexico(texto, lexico_dict) for texto in textos]\n",
        "\n",
        "# Exibir exemplo\n",
        "for i in range(5):\n",
        "    print(f\"Texto {i+1} - Polaridade: {polaridades_lexico[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yQ9O1TpbROq",
        "outputId": "a33f8a1f-5535-4267-ba6a-fe498db3dba2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto 1 - Polaridade: 2\n",
            "Texto 2 - Polaridade: 2\n",
            "Texto 3 - Polaridade: 7\n",
            "Texto 4 - Polaridade: 0\n",
            "Texto 5 - Polaridade: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separando em duas features (psoitivos e negativos)"
      ],
      "metadata": {
        "id": "ROOUAK_YiN67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter a lista de textos para uma Series\n",
        "textos_series = pd.Series(textos)\n",
        "\n",
        "# Função que retorna duas features: número de palavras positivas e negativas\n",
        "def calcular_polaridade_dupla(texto, lexico):\n",
        "    palavras = re.findall(r'\\b\\w+\\b', texto.lower())\n",
        "    positivos = sum(1 for p in palavras if p in lexico and lexico[p] == 1)\n",
        "    negativos = sum(1 for p in palavras if p in lexico and lexico[p] == -1)\n",
        "    return pd.Series([positivos, negativos])\n",
        "\n",
        "# Aplicar a função aos textos\n",
        "X_lexico_df = textos_series.apply(lambda x: calcular_polaridade_dupla(x, lexico_dict))\n",
        "\n",
        "# Renomear as colunas para deixar claro\n",
        "X_lexico_df.columns = ['n_positivas', 'n_negativas']\n",
        "\n",
        "# Visualizar resultado\n",
        "print(X_lexico_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcIowcIYdprH",
        "outputId": "549292d5-8eb2-4a0a-9adb-ffd30b10a165"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   n_positivas  n_negativas\n",
            "0            2            0\n",
            "1            2            0\n",
            "2            7            0\n",
            "3            0            0\n",
            "4            1            0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concatenar o léxico com embeddings"
      ],
      "metadata": {
        "id": "w5rYuCrMiW4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho para salvar o novo arquivo\n",
        "caminho_saida = \"/content/drive/MyDrive/TCC/Dados/X_completo_com_lexico.npy\"\n",
        "\n",
        "# Concatenar embeddings com as duas features do léxico\n",
        "X_completo = np.concatenate([X_combinado, X_lexico_df.values], axis=1)\n",
        "\n",
        "# Salvar o array concatenado\n",
        "np.save(caminho_saida, X_completo)\n",
        "\n",
        "print(f\"Arquivo salvo com sucesso em: {caminho_saida}\")\n",
        "print(f\"Formato do array salvo: {X_completo.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7pWvoqaiakn",
        "outputId": "5ae0b1d5-9b88-4a60-c2ce-1f1121046baa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo salvo com sucesso em: /content/drive/MyDrive/TCC/Dados/X_completo_com_lexico.npy\n",
            "Formato do array salvo: (116910, 2002)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregando o arquivo completo"
      ],
      "metadata": {
        "id": "dnM56xqTjpnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_completo = np.load(\"/content/drive/MyDrive/TCC/Dados/X_completo_com_lexico.npy\")"
      ],
      "metadata": {
        "id": "GdKbNDYnjnUx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Salvar o Y"
      ],
      "metadata": {
        "id": "oyGSCfha2S2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar os rótulos no formato .npy\n",
        "np.save(\"/content/drive/MyDrive/TCC/Dados/y.npy\", y)\n",
        "\n",
        "print(\"Rótulos salvos com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8sxCxv22UOK",
        "outputId": "65f91f77-4be0-4b3c-ddcf-91ee14d137c1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rótulos salvos com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregar o Y"
      ],
      "metadata": {
        "id": "54uWv0RO2Wl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.load(\"/content/drive/MyDrive/TCC/Dados/y.npy\")"
      ],
      "metadata": {
        "id": "BElc75ad2YLi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separar dado de teste e dado de treino com o Léxico"
      ],
      "metadata": {
        "id": "_4MFwJHK2z1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_completo, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "ceLkHExc2-YJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treino e teste SVM"
      ],
      "metadata": {
        "id": "rUR7_8uL3JiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisão dos dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_completo, y, test_size=0.4, random_state=42)\n",
        "\n",
        "# Verificar tamanhos\n",
        "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]}\")\n",
        "print(f\"Tamanho do conjunto de teste: {X_test.shape[0]}\")\n",
        "print(f\"Total de amostras: {X_train.shape[0] + X_test.shape[0]}\")\n",
        "\n",
        "# Modelo 1: LinearSVC sem balanceamento\n",
        "modelo_lexico = LinearSVC(C=0.01, dual=False, max_iter=10000)\n",
        "modelo_lexico.fit(X_train, y_train)\n",
        "pred_lexico = modelo_lexico.predict(X_test)\n",
        "\n",
        "# Modelo 2: LinearSVC com balanceamento\n",
        "modelo_lexico_bal = LinearSVC(C=0.01, class_weight='balanced', dual=False, max_iter=10000)\n",
        "modelo_lexico_bal.fit(X_train, y_train)\n",
        "pred_lexico_bal = modelo_lexico_bal.predict(X_test)\n",
        "\n",
        "# Exibir métricas de ambos os modelos\n",
        "print(\"🔸 Desempenho do Modelo LinearSVC com léxico (sem balanceamento):\")\n",
        "print(classification_report(y_test, pred_lexico))\n",
        "\n",
        "print(\"🔸 Desempenho do Modelo LinearSVC com léxico (com balanceamento):\")\n",
        "print(classification_report(y_test, pred_lexico_bal))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W31efJma3N92",
        "outputId": "b5c13bbd-b169-4ff5-9cd8-877a7486033d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treino: 70146\n",
            "Tamanho do conjunto de teste: 46764\n",
            "Total de amostras: 116910\n",
            "🔸 Desempenho do Modelo LinearSVC com léxico (sem balanceamento):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.00      0.00      8695\n",
            "           1       0.81      1.00      0.90     38069\n",
            "\n",
            "    accuracy                           0.81     46764\n",
            "   macro avg       0.57      0.50      0.45     46764\n",
            "weighted avg       0.72      0.81      0.73     46764\n",
            "\n",
            "🔸 Desempenho do Modelo LinearSVC com léxico (com balanceamento):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.63      0.36      8695\n",
            "           1       0.87      0.57      0.69     38069\n",
            "\n",
            "    accuracy                           0.58     46764\n",
            "   macro avg       0.56      0.60      0.52     46764\n",
            "weighted avg       0.76      0.58      0.63     46764\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPiDtr2oPjQP",
        "outputId": "f51d9593-c7e7-4705-c078-d9cef57151c7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Dividir os dados em treino e teste (60/40, como antes)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_completo, y, test_size=0.4, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]}\")\n",
        "print(f\"Tamanho do conjunto de teste: {X_test.shape[0]}\")\n",
        "print(f\"Total de amostras: {X_train.shape[0] + X_test.shape[0]}\")\n",
        "\n",
        "# Aplicar SMOTE APENAS no conjunto de treino\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"\\n🔄 Após SMOTE:\")\n",
        "print(f\"Amostras de treino após balanceamento: {X_train_res.shape[0]}\")\n",
        "print(f\"Distribuição das classes: {np.bincount(y_train_res)}\")\n",
        "\n",
        "# Treinar o modelo com os dados balanceados\n",
        "modelo_smote = LinearSVC(C=0.01, dual=False, max_iter=10000)\n",
        "modelo_smote.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Avaliar no conjunto de teste original\n",
        "pred_smote = modelo_smote.predict(X_test)\n",
        "\n",
        "print(\"\\n🔸 Desempenho do Modelo LinearSVC com SMOTE:\")\n",
        "print(classification_report(y_test, pred_smote))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrEZuS4lSV3v",
        "outputId": "55139b4f-0a62-4b4c-d194-e694c35a5048"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treino: 70146\n",
            "Tamanho do conjunto de teste: 46764\n",
            "Total de amostras: 116910\n",
            "\n",
            "🔄 Após SMOTE:\n",
            "Amostras de treino após balanceamento: 114258\n",
            "Distribuição das classes: [57129 57129]\n",
            "\n",
            "🔸 Desempenho do Modelo LinearSVC com SMOTE:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      0.50      0.28      8703\n",
            "           1       0.82      0.52      0.63     38061\n",
            "\n",
            "    accuracy                           0.51     46764\n",
            "   macro avg       0.51      0.51      0.46     46764\n",
            "weighted avg       0.70      0.51      0.57     46764\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib\n",
        "\n",
        "# 🔹 Diretório para salvar os checkpoints\n",
        "checkpoint_dir = \"/content/drive/My Drive/TCC/checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# 🔹 Divisão dos dados\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_completo, y, test_size=0.4, random_state=42\n",
        ")\n",
        "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]}\")\n",
        "print(f\"Tamanho do conjunto de teste: {X_test.shape[0]}\")\n",
        "print(f\"Total de amostras: {X_train.shape[0] + X_test.shape[0]}\")\n",
        "\n",
        "# 🔹 Pipeline com oversampling\n",
        "pipeline = ImbPipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"smote\", SMOTE(random_state=42)),\n",
        "    (\"clf\", LinearSVC(dual=False, max_iter=10000))\n",
        "])\n",
        "\n",
        "# 🔹 Parâmetros para ajustar\n",
        "param_grid = {\n",
        "    \"clf__C\": [0.001, 0.01, 0.1, 1]\n",
        "}\n",
        "\n",
        "# 🔹 GridSearch com validação cruzada\n",
        "grid = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"f1_macro\",\n",
        "    cv=3,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 🔹 Ajuste com barra de progresso\n",
        "print(\"🔁 Iniciando GridSearch com SMOTE...\\n\")\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# 🔹 Melhor modelo\n",
        "melhor_modelo = grid.best_estimator_\n",
        "melhor_C = grid.best_params_[\"clf__C\"]\n",
        "print(f\"\\n✅ Melhor valor de C: {melhor_C}\")\n",
        "\n",
        "# 🔹 Previsão e relatório\n",
        "y_pred = melhor_modelo.predict(X_test)\n",
        "print(\"\\n🔸 Desempenho do Modelo LinearSVC com SMOTE e melhor C:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# 🔹 Salvar checkpoint do modelo treinado\n",
        "checkpoint_path = os.path.join(checkpoint_dir, f\"modelo_SVM_C{melhor_C}.joblib\")\n",
        "joblib.dump(melhor_modelo, checkpoint_path)\n",
        "print(f\"\\n💾 Modelo salvo em: {checkpoint_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "okc5ykX5VTps",
        "outputId": "b5918946-51af-4e57-be16-39c8e287223a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treino: 70146\n",
            "Tamanho do conjunto de teste: 46764\n",
            "Total de amostras: 116910\n",
            "🔁 Iniciando GridSearch com SMOTE...\n",
            "\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TerminatedWorkerError",
          "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a19ae6ab3237>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# 🔹 Ajuste com barra de progresso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🔁 Iniciando GridSearch com SMOTE...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# 🔹 Melhor modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1752\u001b[0m             \u001b[0;31m# worker traceback.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aborting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1754\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_error_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1755\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1787\u001b[0m         \u001b[0;31m# called directly or if the generator is gc'ed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_job\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m             \u001b[0merror_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_warn_exit_early\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;31m# callback thread, and is stored internally. It's just waiting to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m             \u001b[0;31m# be returned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_or_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# For other backends, the main thread needs to run the retrieval step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_ERROR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}"
          ]
        }
      ]
    }
  ]
}